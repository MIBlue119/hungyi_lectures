<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Explainable ML (2/8)</h2><a href=https://www.youtube.com/watch?v=pNpk6DPYUh8><img src=https://i.ytimg.com/vi_webp/pNpk6DPYUh8/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=0">00:00.000</a></div>
        <div class="t">好,那我們今天就分別來講一下Local Explanation跟Global Explanation,那我們就先從Local Explanation開始講起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:11.000" id=00:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=11">00:11.000</a></div>
        <div class="t">我們要先講說,假設今天繼續看他那張圖片,他判斷說他是一隻貓,那他到底是看到圖片中的什麼部分,讓他覺得說他看到一隻貓。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:23.000" id=00:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=23">00:23.000</a></div>
        <div class="t">那這個Local Explanation他的基本精神就是你現在有一個object,那這個object叫做X,那這個object裡面他有很多小的component,這邊用XY到X大根來表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:38.000" id=00:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=38">00:38.000</a></div>
        <div class="t">我們想要知道說這大根的component裡面有哪些對於機器判斷現在這個objectX是屬於什麼類別是比較重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:48.000" id=00:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=48">00:48.000</a></div>
        <div class="t">那這樣講可能有點抽象,這邊所謂的component指的是什麼呢?如果今天是影像的話,那所謂的每一個component,XY到X大根,每一個X下標N,他可能指的就是一個pixel。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02.000" id=01:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=62">01:02.000</a></div>
        <div class="t">或者是假設你覺得一個pixel太小的話,有人也會用一個segment來表示這個image裡面的component。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12.000" id=01:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=72">01:12.000</a></div>
        <div class="t">就是你可以先把一個image,那有一些這個toolkey可以幫你把一個image把它切成一小塊一小塊的,那可以說每一小塊就叫做一個component。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:23.000" id=01:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=83">01:23.000</a></div>
        <div class="t">那什麼是一個component取決於你現在想要分析到多細。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:27.000" id=01:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=87">01:27.000</a></div>
        <div class="t">假設你想以pixel作為成績來分析的話,那這邊每一個component就是一個pixel,假設你想以segment為成績來分析的話,那這邊所謂的每一個component就是一個segment。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:37.000" id=01:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=97">01:37.000</a></div>
        <div class="t">那等一下在講這個explainable的machine learning的時候,我們所有的例子都是影像。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:45.000" id=01:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=105">01:45.000</a></div>
        <div class="t">但是其實通的技術不是只能用在影像上,他還可以用在其他領域,舉例來說讓機器理解人類的語言。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:53.000" id=01:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=113">01:53.000</a></div>
        <div class="t">那如果今天我們要做得上機器理解人類的語言,你的object是一個句子的話,那他的每一個component可能就是一個詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:03.000" id=02:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=123">02:03.000</a></div>
        <div class="t">好,那這個local的explanation,我們想要達成的目標是,我們希望機器可以告訴我們說,在這個input的object裡面,這些component裡面,哪一個component對他判斷出現在的結果是重要的,哪一個component對他判斷出現在的結果其實是不重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:24.000" id=02:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=144">02:24.000</a></div>
        <div class="t">好,那我們要怎麼知道說一個component對機器來說,對他判斷最終的結果而言到底是重要的還是不重要的呢?那背後的觀念其實非常的簡單,背後的概念其實非常的簡單。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:38.000" id=02:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=158">02:38.000</a></div>
        <div class="t">背後的概念就是我們把某一個component把它拿掉,或者是把它做一些改動。如果把某一個component拿掉或做一些改動以後,你發現對機器的判斷,對他分類的結果造成非常大的影響的話,那顯然這個component就是一個重要的component,概念就這麼簡單。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:02.000" id=03:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=182">03:02.000</a></div>
        <div class="t">舉例來說,這邊有一張圖片,然後你把這張圖片丟到一個network裡面,它告訴你說這張圖片裡面有一隻博美狗,接下來你在這個圖片上貼上一個灰色的方塊,這個灰色的方塊可以貼在圖片上所有的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:24.000" id=03:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=204">03:24.000</a></div>
        <div class="t">你可以想像說,如果把這個灰色的方塊移到這個狗的臉上,那機器可能就會判斷說它是博美狗,它就會產生其他高分的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:35.000" id=03:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=215">03:35.000</a></div>
        <div class="t">下面這張圖想要顯示的事情就是說,藍色的部分代表機器現在辨識出來是博美狗的機率是很低的,它給博美狗的分數、給博美狗的confidence是很低的。紅色的部分代表機器很確定說這張圖片裡面是博美狗。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:53.000" id=03:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=233">03:53.000</a></div>
        <div class="t">當你把這個灰色的方塊放在周圍的時候,機器就很確定說它看到的是一隻博美狗。當你把這個灰色的方塊挪到這個位置,機器就無法判斷,它就不覺得這張圖片是一隻博美狗。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:11.000" id=04:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=251">04:11.000</a></div>
        <div class="t">所以講對機器來說,這個藍色區域對它判斷這張圖片是不是博美狗而言就是很重要的,可以藉此知道說機器在想些什麼樣的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:24.000" id=04:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=264">04:24.000</a></div>
        <div class="t">我這邊是另外一個例子,機器看到這張圖片,它說它看到一個車輪,當你把車輪的位置用這個灰色的方塊擋起來的時候,機器就會覺得說它沒有看到車輪。所以顯然機器是看到這個區域,它覺得它有看到車輪。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:41.000" id=04:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=281">04:41.000</a></div>
        <div class="t">或者是你給機器看這張圖片,然後它說它看到一隻狗,那這個是什麼貧肉狗,其實我也不知道。機器看到這張圖片,它覺得它看到一隻狗,但是搞不好它並不是看到這個狗,是看到這個地方才覺得它是狗,而是看到這個人覺得是狗,看到這個人覺得是狗,這是有可能的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:58.000" id=04:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=298">04:58.000</a></div>
        <div class="t">所以怎麼辦?我們把這個灰色的方塊在這個圖上移動,它挪到哪裡的時候,機器會覺得它沒有看到狗。還好機器是把灰色方塊挪到這個地方,挪到這個地方的時候,它覺得它沒有看到狗。所以它並不是把這兩個人誤認為狗,它是真的有看到狗。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:17.000" id=05:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=317">05:17.000</a></div>
        <div class="t">其實你在使用這樣的技術的時候,有一些地方你是要小心的,你要小心什麼地方呢?你要自己選一下這個灰色方塊的大小。你可以想像說假設你把灰色方塊選得很小,比如說一個pixel,那你就會發現說不管你把灰色方塊挪到哪裡,結果可能都是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:35.000" id=05:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=335">05:35.000</a></div>
        <div class="t">那你的機器開出來的輸出都不會改變,你就會得到結論說所有的pixel都不重要,但其實不是這樣。或是你把灰色方塊挪得很大,跟整張圖片一樣大,不管放在哪裡都無法得到正確的辨識結果,那這個也不是我們要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:50.500" id=05:50.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=350">05:50.500</a></div>
        <div class="t">所以就變成說你必須要注意一些細節,你必須要注意一下說你這個方塊到底應該要多大。而且這個方塊為什麼一定是灰色的,為什麼不是白色或黑色的呢?因為我用別的顏色,你其實也會問同樣的問題。所以到底是哪一個顏色也是你需要決定的,那可能不同的顏色你會得到不同的解釋的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:12.000" id=06:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=372">06:12.000</a></div>
        <div class="t">所以今天其實等一下你會看到也有很多這樣的例子,就是你在用這個Explainable AI的技術的時候,往往裡面會有一些參數要調,然後你調那些參數還會給你帶來不同的解釋的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:31.000" id=06:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=391">06:31.000</a></div>
        <div class="t">所以你今天用Explainable AI的技術,但有時候你要小心,就是當你選擇不同的參數的時候,你其實會得到不同的解釋的結果。好,那剛才講的是直接把一個東西,直接把一個灰色方塊貼到圖片上,然後看看機器辨識的結果會有什麼樣的不同。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:50.000" id=06:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=410">06:50.000</a></div>
        <div class="t">那這邊講的是另外一個方法,這邊是說,假設現在有一張圖片,這張圖片裡面的Pixel是XY到XR,那我們把這張圖片丟到一個影像的辨識系統裡面,它會給我們一個答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:03.500" id=07:03.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=423">07:03.500</a></div>
        <div class="t">舉例來說,我們把這張圖片丟到影像辨識系統裡面,它會告訴我們說它看到一隻狗。那我們把機器的輸出,我們知道說影像辨識系統它的輸出其實是一個向量,其實是一個distribution,它會給每一個pass都給一個機率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:19.500" id=07:19.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=439">07:19.500</a></div>
        <div class="t">那假設我們現在把這張圖片,這張圖片被辨識成狗,我們把狗的機率拿出來,這個拿出來的機率我們寫作YK。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:32.500" id=07:32.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=452">07:32.500</a></div>
        <div class="t">那我們想現在知道說,對機器而言,這張圖片為什麼是一隻狗的話,那怎麼做呢?我們就把input的某一個Pixel加上一個deltaX,加上一個小小的擾動,然後看看這個小小的擾動對我們的輸出YK造成多大的影響。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:54.000" id=07:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=474">07:54.000</a></div>
        <div class="t">那如果今天這個小小的擾動deltaX對我們的輸出deltaY造成很大的影響,那我們就知道說,現在我們進行擾動的那一個PixelXn,它是一個很重要的Pixel,它對我們判斷現在這個圖片裡面,有是不是一隻狗,是一個很重要的關鍵的角色。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:15.500" id=08:15.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=495">08:15.500</a></div>
        <div class="t">那怎麼算這個deltaX分之deltaY呢?怎麼計算一個小小的擾動對輸出所造成的影響呢?其實你真正做的事情就是計算它的規點,你會計算Xn這個Pixel對你現在的outputYK的偏微分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:32.000" id=08:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=512">08:32.000</a></div>
        <div class="t">你會把Xn對YK做偏微分,然後你取它的絕對值,讓你知道說這個偏微分後的大小,然後你可以根據這個偏微分的絕對值,知道說某一個PixelXn對現在判斷YK而言是重要的還是不重要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:47.500" id=08:47.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=527">08:47.500</a></div>
        <div class="t">那有這個技術以後呢,你就可以畫一個saliency的map,saliency的map就是下排的這樣子的圖,那這個saliency的map就會告訴我們說在這個圖上面,到底哪一些Pixel是比較重要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:04.500" id=09:04.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=544">09:04.500</a></div>
        <div class="t">那在這個saliency的map上面呢,每一個點的這個亮度就代表了我們把Xn對YK做偏微分以後的絕對值,亮度越大就代表說這個絕對值的數值越大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:19.000" id=09:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=559">09:19.000</a></div>
        <div class="t">那所以我們就可以知道說機器怎麼判斷說這張圖片裡面有一隻狗呢?它是看到狗的位置才覺得它看到一隻狗。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:26.500" id=09:26.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=566">09:26.500</a></div>
        <div class="t">或者說它怎麼知道這邊有猴子呢?它並不是因為看到旁邊的綠葉覺得有猴子,它是真的看到這隻猴子,才真的看到這個位置覺得說看到一隻猴子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:36.000" id=09:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=576">09:36.000</a></div>
        <div class="t">或者說它看到這張圖片說裡面有牛,那牛在哪裡呢?牛並不是旁邊的樹,它知道說牛落在圖片的這個位置,落在圖片的這個位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:45.500" id=09:45.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=585">09:45.500</a></div>
        <div class="t">所以我們可以畫saliency map,你可以計算每一個pixel對level輸出的規點,然後計算規點以後就可以畫出一個saliency map,根據saliency map你就可以知道說現在一張圖片裡面的哪些pixel對機器判斷結果是什麼是重要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:01.500" id=10:01.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=601">10:01.500</a></div>
        <div class="t">那其實這種用規點來判斷說哪些pixel重要哪些pixel不重要的方法有很多不同的變形,那我就這邊列一些reference給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:12.500" id=10:12.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=612">10:12.500</a></div>
        <div class="t">那其實我們的作業室就是要做這個explainable的machine learning,那你其中一個要專家指定做的事情就是畫這個saliency map。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:23.000" id=10:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=623">10:23.000</a></div>
        <div class="t">那除了教大家畫saliency map以外,在題目裡面也有提示自由發揮,你可以拿任何你喜歡的方法來自己做一下explanation,那你就可以看看這邊有寫reference,就可以選一篇reference做一個你看興趣的方法就是了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:37.000" id=10:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=637">10:37.000</a></div>
        <div class="t">那剛才講的是用規點的方法來告訴我們說每一個pixel或者每一個feature到底是重要還是不重要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:47.500" id=10:47.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=647">10:47.500</a></div>
        <div class="t">那這種用規點的方法有一個潛在的問題是規點的saturation,那假設我們這邊舉一個很簡單的例子,表示橫軸代表的是現在圖片中的那隻生物牠鼻子的長度。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:03.500" id=11:03.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=663">11:03.500</a></div>
        <div class="t">縱軸代表說現在classify判斷說這隻生物是大象的機率有多少。大象雖然我們知道說牠有長鼻子,但是只要鼻子長到一定的程度,我們其實就會很肯定牠是一個大象。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:18.500" id=11:18.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=678">11:18.500</a></div>
        <div class="t">牠的鼻子再長,我們對牠覺得牠是大象的信心分數也不會再增加了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:23.500" id=11:23.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=683">11:23.500</a></div>
        <div class="t">牠鼻子長到一定程度,我們對牠是大象的信心分數可能就封頂了,覺得是1,那現在再把牠的鼻子長度增長,你也不會覺得牠變得更像是一隻大象。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:33.500" id=11:33.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=693">11:33.500</a></div>
        <div class="t">所以如果今天有一隻大象進來,然後你去計算一下鼻子的長度對牠是大象的信心分數的偏微分,你會發現說在這個區域,在這個信心分數已經封頂的區域,你算出來偏微分的值可能是0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:51.500" id=11:51.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=711">11:51.500</a></div>
        <div class="t">可是這個就跟我們想要的結果不太一樣,因為鼻子的長度顯然對我們判斷牠是不是大象是一個很重要的關鍵的指標。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:00.500" id=12:00.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=720">12:00.500</a></div>
        <div class="t">但是如果你給這張圖片計算鼻子長度的變化對是大象的信心分數的影響,你會發現說沒有影響。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:08.500" id=12:08.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=728">12:08.500</a></div>
        <div class="t">所以對我們來說,你用剛才那種規定的方法,你得到的結論可能是鼻子的長度對牠的數字大象是沒有影響的,但是實際上很有可能是有。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:18.500" id=12:18.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=738">12:18.500</a></div>
        <div class="t">那怎麼解這個問題呢?那今天我們就不細講,就列一些reference在這邊給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:24.500" id=12:24.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=744">12:24.500</a></div>
        <div class="t">舉例來說,interpreter的gradient或bit rate就是一個解決這種問題的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:31.500" id=12:31.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=751">12:31.500</a></div>
        <div class="t">所以除了用gradient以外,還有其他的方法可以讓我們知道說一張圖片裡面每個component的重要性。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:38.500" id=12:38.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=758">12:38.500</a></div>
        <div class="t">那其實interpretation這件事情居然可以被attack,我們上週有講過怎麼attack一張圖片讓機器完全做出誤判,其實你也可以讓機器做出錯誤的explanation。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:53.500" id=12:53.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=773">12:53.500</a></div>
        <div class="t">舉例來說,現在給機器看一張圖片,這張圖片機器正確的辨識說牠看到一台卡車。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:01.500" id=13:01.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=781">13:01.500</a></div>
        <div class="t">那我們用不同的方法來畫一下CNC map,這樣畫一下CNC map讓人知道說圖片裡面哪些地方是重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:11.500" id=13:11.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=791">13:11.500</a></div>
        <div class="t">那對這兩個不同的方法而言,這就是兩個不同的畫CNC map的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:16.500" id=13:16.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=796">13:16.500</a></div>
        <div class="t">對這兩個不同的方法而言,都是大概這個區域,也就是這個卡車的側面的地方是重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:25.500" id=13:25.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=805">13:25.500</a></div>
        <div class="t">讓機器確實看到了對卡車的位置,知道說牠看到了一台卡車。但是你可以加上一些神奇的noise,這些神奇的noise人看不出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:36.500" id=13:36.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=816">13:36.500</a></div>
        <div class="t">而且加上神奇的noise,丟到network以後,pacify的結果也沒有不同,但是interpretation的結果卻變了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:44.500" id=13:44.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=824">13:44.500</a></div>
        <div class="t">你可以加一些神奇的noise,讓機器覺得說牠是因為看到這朵雲,才覺得說牠看到卡車,但是interpretation的結果居然沒有變,人也看不出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:56.500" id=13:56.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&t=836">13:56.500</a></div>
        <div class="t">所以今天我們的未來在使用explanation這樣的技術的時候,也是要小心的,explanation這樣的技術也是有可能被惡意的攻擊的。</div>
    </div>
    
</body>
</html>   