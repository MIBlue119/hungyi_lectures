<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>More about Auto-encoder (1/4)</h2><a href=https://www.youtube.com/watch?v=6ZWu4L7XOiQ><img src=https://i.ytimg.com/vi_webp/6ZWu4L7XOiQ/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=0">00:00.000</a></div>
        <div class="t">我們第七個作業是要做Unsupervised Learning,其中一個很重要的技術就是做Autoencoder。上課的錄影裡面已經有講過Autoencoder了,今天這堂課要講的是Autoencoder進門來,請一些過去沒有講過的新的技術。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:23.360" id=00:23.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=23">00:23.360</a></div>
        <div class="t">那我相信大家對Autoencoder應該都已經非常非常的熟悉,所以我就不需要再多做描述,大家都知道Autoencoder裡面就是有一個encoder,然後這個encoder是一個input,然後就要output一個vector,有時候我們叫這個vector叫做embedding,有時候我們叫它latent representation,或是叫它latent code。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:48.800" id=00:48.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=48">00:48.800</a></div>
        <div class="t">那你會有一個decoder,這個decoder把這個vector吃進去,然後試圖還原原來的輸出。在訓練的時候,你就是要minimize reconstruction error,也就是你要讓encoder的輸入跟decoder的輸出越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07.040" id=01:07.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=67">01:07.040</a></div>
        <div class="t">那我今天要講的內容分成兩個部分,第一個部分是為什麼一定是minimize reconstruction error,有沒有其他的做法呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:20.080" id=01:20.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=80">01:20.080</a></div>
        <div class="t">那第二部分講的是怎麼讓,因為通常encoder的output就是一個vector,這個vector我們都不知道裡面發生什麼事,我們希望能夠讓encoder自動output出來的東西能夠更容易的被解讀。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:35.360" id=01:35.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=95">01:35.360</a></div>
        <div class="t">好,那我們就先從第一個部分開始講起,第一個部分我要講的是說,為什麼是minimize reconstruction error,有沒有其他做法呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:45.440" id=01:45.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=105">01:45.440</a></div>
        <div class="t">那我們現在想想看,我們先來回歸一開始的初衷,為什麼我們要做這個embedding?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:53.840" id=01:53.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=113">01:53.840</a></div>
        <div class="t">我們期待這個embedding可以做到什麼樣的事情呢?我們期待這個embedding它是具有代表性的,它可以代表原來encoder輸入的那個object,看到那個embedding,你就可以想到原來的object。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:11.280" id=02:11.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=131">02:11.280</a></div>
        <div class="t">舉例來說,今天如果你看到耳機,你就會想到三九,你不會想到其他人,你去商店跟店員說我要買三九的耳機,他就知道要拿哪一款給你,所以今天你看到耳機,你就想到三九,你會知道耳機跟三九是一對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:32.920" id=02:32.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=152">02:32.920</a></div>
        <div class="t">不知道三九的人,我還是解釋一下好了,三九最近在學做麵包,後來他也學做了披薩,然後他就開一個披薩店,電話就是三九三九八八九這樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:48.880" id=02:48.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=168">02:48.880</a></div>
        <div class="t">所以這個是三九,三九跟耳機就是一對,所以你看到耳機,你就不會想到一花。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:55.720" id=02:55.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=175">02:55.720</a></div>
        <div class="t">所以我們今天有一個encoder,這個encoder吃一張圖片,它就拗出一個embedding,比如說吃三九的圖片,它就拗出一個藍色的embedding,吃梁功順的圖片,它就拗出一個黃色的embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:10.080" id=03:10.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=190">03:10.080</a></div>
        <div class="t">因為三九耳機藍色的,所以它代表它的embedding就是藍色的,然後梁功順的髮帶是黃色的,所以代表它的embedding就是黃色的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:20.200" id=03:20.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=200">03:20.200</a></div>
        <div class="t">好,那我們現在有一個encoder,給它image就可以產生embedding,我們如何知道一個encoder它是好還是不好呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:29.880" id=03:29.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=209">03:29.880</a></div>
        <div class="t">我們如何知道這個encoder它輸掉的embedding對這個圖片是有代表性的還是沒有代表性的呢?我們這邊要訓練一個discriminator。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:41.400" id=03:41.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=221">03:41.400</a></div>
        <div class="t">假設你不熟悉generative adversarial network,假設你不熟悉gain這個技術的話,因為我這堂課還沒有講過gain,假設你不熟悉gain這個技術的話,也許discriminator這個詞彙對你來說有點陌生。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:53.080" id=03:53.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=233">03:53.080</a></div>
        <div class="t">但你這邊就想成說我們訓練了一個binary的classifier,我們確實就是訓練了一個binary的classifier,跟我們之前在課堂非常開始的時候講的什麼logistic regression是一樣的,這個binary classifier它吃一張圖片,吃一個embedding當作輸入。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:13.320" id=04:13.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=253">04:13.320</a></div>
        <div class="t">它的輸出就是這張圖片跟這個embedding,它們是一對的還是不是一對的?那你在訓練的時候,當然這是一個binary classifier,所以你要提供給它訓練資料,去訓練這個binary classifier。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:29.720" id=04:29.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=269">04:29.720</a></div>
        <div class="t">你把這個encoder,它原來的圖片跟它輸出的embedding湊起來,就說這樣是一對的。然後告訴這個binary classifier說,看到圖片跟它原來的embedding當作input,看到這樣子的一組東西,你就要回答yes,它們是一對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:49.880" id=04:49.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=289">04:49.880</a></div>
        <div class="t">那我們現在把圖片任意配其它圖片的embedding,就三九它本來output的embedding是藍色的,現在我們故意給它配兩公尺的embedding,兩公尺任意給它配三九的embedding,來跟機器說,這些是negative example,你看到這些東西,你就要說no,你就要說它們不是一對。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:12.600" id=05:12.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=312">05:12.600</a></div>
        <div class="t">然後你有這些訓練資料,你就可以訓練一個binary classifier,看到一張圖片,看到一個embedding,它告訴你說它們是一對的,還是不是一對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:23.640" id=05:23.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=323">05:23.640</a></div>
        <div class="t">那也知道說要訓練一個binary classifier,你要頂一個loss function,對不對?那我們之前講說binary classifier常用的loss function,就是這個binary的loss entropy,所以我們有了訓練資料,你就可以寫出一個loss function,接下來就訓練你的binary classifier,去minimize你的loss function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:45.720" id=05:45.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=345">05:45.720</a></div>
        <div class="t">那假設現在這個binary classifier它的參數,我們用phi來表示,也許有同學會突然想到一個不相干的問題,就是為什麼我突然有牙齒了呢?就是我看大家都突然頭抬起來了,這個就是裝了一個臨時的假牙啦。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:09.400" id=06:09.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=369">06:09.400</a></div>
        <div class="t">我覺得裝臨時的假牙講話有點不方便,希望牙不要掉下來。binary classifier它的參數叫做phi,那我們訓練binary classifier的時候,我們做什麼事呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:19.480" id=06:19.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=379">06:19.480</a></div>
        <div class="t">我們就是先訂好一個loss function,這邊寫做LD,然後我們去調phi的參數,希望可以minimize這個loss function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:27.240" id=06:27.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=387">06:27.240</a></div>
        <div class="t">那我們假設訓練完之後,我們找到的那個最好的phi,它可以達到的最低的loss function,我們叫做LD star。好,那我們有了這些訓練資料以後,我們就用phi去minimize loss function,得到LD star。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:42.760" id=06:42.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=402">06:42.760</a></div>
        <div class="t">如果今天LD star得出來的值很小,也就是你這個訓練的結果很好,那就代表說這個embedding它非常具有代表性,machine可以輕易地判斷出這些embedding就是一對,這些embedding就是一對,這些embedding不該是一對,這些embedding不該是一對,這個任務非常容易,所以你的binary classifier輕易地就可以得到很低的loss,那這個就是一個好的encoder。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:08.120" id=07:08.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=428">07:08.120</a></div>
        <div class="t">那反過來說,如果今天有一個很差的encoder,它output出來的vector都是灰色的,那三久的embedding跟良工村的embedding看起來沒有什麼不同,所以你把三久的embedding跟良工村的embedding做一個交換,對discriminator來說,對你的binary classifier來說,這些positive example應該說yes,是一對的example,跟這些negative example應該說不是一對的example,看起來根本沒有什麼不同。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:35.800" id=07:35.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=455">07:35.800</a></div>
        <div class="t">所以你訓練以後,機器就發現這個問題非常的難,所以它的loss function的值就很大,所以它的LD star就很大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:45.160" id=07:45.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=465">07:45.160</a></div>
        <div class="t">可是那LD star很大,LD star這個值很大意味著什麼呢?這個意味著說你產生出來的這個embedding它不具有代表性,機器很難判斷說一個embedding跟一個image,它們到底應該是一對的,還是不是一對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:03.640" id=08:03.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=483">08:03.640</a></div>
        <div class="t">那藉由這樣的想法,你就可以訓練一個新的訓練這個encoder的方法,就我們過去訓練encoder的時候,你是要去minimize reconstruction error,但今天我們已經知道說我們可以訓練一個binary classifier去評估一個encoder是好還是不好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:23.080" id=08:23.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=503">08:23.080</a></div>
        <div class="t">那接下來我們要做的事情就是去調encoder的參數,去讓這個encoder進行學習,使得它用我們現在評估一個encoder好壞的方法,在這個評估的標準下,它可以得到好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:37.560" id=08:37.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=517">08:37.560</a></div>
        <div class="t">那我們今天既然評估的標準是看LD star,我們說LD star越小代表這個encoder它越好,那我們今天訓練encoder的目標就變成要去minimize LD star,假設encoder的參數是setup,我們今天就是把LD star當作是我們要去minimize的對象,然後我們去找一個setup,讓LD star的值可以越小越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:06.920" id=09:06.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=546">09:06.920</a></div>
        <div class="t">那LD star又是什麼呢?我們說LD star其實是我們先定義好一個loss function LD以後,找一個fine,看能夠讓LD star小到什麼程度,這個結果就是LD star。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:23.560" id=09:23.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=563">09:23.560</a></div>
        <div class="t">所以LD star它是找一個fine去minimize LD,這邊有一個LD star,我們知道它是找一個fine去minimize LD,所以我們可以把這一下拿下來取代LD star就變成這樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:38.280" id=09:38.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=578">09:38.280</a></div>
        <div class="t">那我們要同時找出一個最好的encoder跟一個最好的discriminator,他們一起去minimize LD這個loss function。那這一招其實被用在這個DeepInfoMax,被用在Dyne這篇paper裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:57.320" id=09:57.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=597">09:57.320</a></div>
        <div class="t">Dyne這個技術它是這個iClear 2019的一篇paper,那這個discriminator也可以任意設計,這個discriminator可以給它不同的loss function,那訓練出來的結果會不太一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:09.320" id=10:09.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=609">10:09.320</a></div>
        <div class="t">好,那我們這邊說呢,當我們要訓練encoder的時候,我們是一起train encoder跟discriminator去minimize LD這個loss function,那其實這件事啊,就好像是我們一般在train一般的autoencoder的時候,我們一起同時train encoder跟decoder去minimize reconstruction error。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:33.320" id=10:33.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=633">10:33.320</a></div>
        <div class="t">原來我們所熟悉的autoencoder,它其實就是我們剛才講的那個framework,就我們說我們其實去訓練一個binary classifier,這個binary classifier去看說這個encoder好還是不好,其實autoencoder可以看作是剛才那個敘述的一個special case。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:55.560" id=10:55.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=655">10:55.560</a></div>
        <div class="t">怎麼說它是一個special case呢?今天在一般的autoencoder裡面,我們的discriminator在哪裡呢?我們說我們的discriminator,也就是binary classifier,它就是吃一張圖片,吃一個向量,然後拋出一個分數,代表說這個圖片跟這個向量,它們應該是一組的,還是不應該是一組。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:19.560" id=11:19.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=679">11:19.560</a></div>
        <div class="t">其實我們如果把discriminator裡面的network架構,把discriminator的運作過程做一下設計,我們剛才講的加上binary classifier的訓練方式,其實你可以說過去的autoencoder其實就是我們剛才講的訓練binary classifier的一種特例。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:44.040" id=11:44.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=704">11:44.040</a></div>
        <div class="t">怎麼說呢?我們的discriminator假設它的運作方式是這個樣子,我們有一個decoder,有一個network,我們把它叫做decoder,它先把這個vector吃進去,然後它會output一個跟這張input image大小一樣的metric,然後接下來你再把這兩張圖片做相減,計算它們之間的差異。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:09.480" id=12:09.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=729">12:09.480</a></div>
        <div class="t">你會發現說這個discriminator做的事情,這個discriminator的輸出其實就是這個reconstruction的error,也就是說在原來typical的autoencoder裡面,我們其實可以把這一段就當作是一個binary classifier,而reconstruction的error其實就是那個binary classifier它輸出的數字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:35.560" id=12:35.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=755">12:35.560</a></div>
        <div class="t">在訓練的時候,我們給它image跟它的一個vector,跟它輸出來的這個embedding,然後我們說這個image配上這個embedding,它output的reconstruction error應該要越小越好,不過在typical的autoencoder裡面,我們就沒有考慮negative的example。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:56.040" id=12:56.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=776">12:56.040</a></div>
        <div class="t">在我們剛才講的更general的模式裡面,我們有positive example,有negative example,在typical的autoencoder裡面,我們只考慮positive example,我們希望positive example output的reconstruction error,這個positive example丟進我們今天所謂的特別的discriminator裡面,output的這個分數,也就是reconstruction error的值,越小越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:26.200" id=13:26.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=806">13:26.200</a></div>
        <div class="t">然後這邊大家有問題要問嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:28.440" id=13:28.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&t=808">13:28.440</a></div>
        <div class="t">這個就是在autoencoder這個面向上一些新的想法。</div>
    </div>
    
</body>
</html>   