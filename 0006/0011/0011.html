<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Attack ML Models (4/8)</h2><a href=https://www.youtube.com/watch?v=qjnMoWmn1FQ><img src=https://i.ytimg.com/vi_webp/qjnMoWmn1FQ/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=0">00:00.000</a></div>
        <div class="t">好,那接下來我們就是實際上試試看說,因為剛才講的方法聽起來還蠻簡單的,這麼簡單的方法真的可以產生出一些image來騙過network嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:16.200" id=00:16.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=16">00:16.200</a></div>
        <div class="t">所以我就實際上做了一下。這個是我們的loss function,我們今天希望把一張image丟到network裏面,它不止不可以說那張image是小虎白貓,而且它要說那張image是starfish,就是海星。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:33.600" id=00:33.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=33">00:33.600</a></div>
        <div class="t">我這邊用的network是50層的residual net,它並不是一個很弱的隨便自己亂圈的network,它是一個pretend好的,極限層的,網路上載得到的network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:44.560" id=00:44.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=44">00:44.560</a></div>
        <div class="t">把這張圖片丟進去,它說它是小虎白貓,它的confidence是64%,那經過一輪攻擊以後,就是我把這張圖片當作initialize,然後用剛才我們前一頁圖片講的演算法去update參數,如果沒記錯的話就是update了50次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01.760" id=01:01.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=61">01:01.760</a></div>
        <div class="t">那最後得到的結果呢,這個圖片是長這個樣子的,那你想說這左右兩張圖片看起來應該是一模一樣,好不好,我其實根本沒有做這個實驗,我只是把他們的圖片update一次而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:18.000" id=01:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=78">01:18.000</a></div>
        <div class="t">但是我把這張圖片丟到residual network裡面,它就跟我說它是starfish,而且它的信心分數是100%,它非常非常肯定這是一隻海星。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:32.240" id=01:32.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=92">01:32.240</a></div>
        <div class="t">那有人可能會想說,會不會左右兩張圖片其實是一模一樣的呢?所以我們就把這左右兩張圖片進行相減,看看它們的差。但是如果你只是把它們相減,你會發現你根本看不出差異來,為什麼這兩張圖片實在是太像。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:49.360" id=01:49.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=109">01:49.360</a></div>
        <div class="t">所以你要相減以後乘上50倍,那你就會發現你得到的圖片像是這個樣子。所以這兩張圖片確實有一些非常非常微小的差異,而這些微小的差異就足以騙過Machine,讓它覺得說右邊這張圖片變成了一隻海星。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:08.560" id=02:08.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=128">02:08.560</a></div>
        <div class="t">那有人可能會想說,也許貓跟海星還是有某些相似之處,因為它們都是生物,所以我就另外做了一個把貓變成鍵盤。那得到的結果也是一樣,這隻貓輕易的就變成了鍵盤,那機器覺得說這張圖片是鍵盤的component的時候就是它了,雖然你左右兩張圖片你看起來根本就是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:30.560" id=02:30.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=150">02:30.560</a></div>
        <div class="t">那有人會想說,會不會是這個network很弱呢?我們剛才在上課一開頭的時候就有強調過說,我們今天做攻擊的時候,這個加上去的雜訊並不是一般的雜訊,它是用規點所算出來的一個信號,而那個信號加上去可以讓辨識的結果壞掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:48.320" id=02:48.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=168">02:48.320</a></div>
        <div class="t">如果你只是隨機加一些雜訊,是騙不了今天的network的。舉例來說,左邊這張圖片,我加了一些雜訊,那些雜訊很微小,跟剛才在做adversarial attack的時候加的那個雜訊的scale差不多大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:01.960" id=03:01.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=181">03:01.960</a></div>
        <div class="t">那你會發現說,對機器來說,這張圖片仍然是一隻小虎斑貓。那我們現在把這個雜訊加大一點,其實你在這張圖片就可以有點看出來說,好像加了一些雜訊進去,它跟原來的圖片有點不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:17.680" id=03:17.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=197">03:17.680</a></div>
        <div class="t">這時候機器確實得到了一個不一樣的辨識結果,它說它是虎斑貓。Teddy Cat應該是虎斑貓,不過它是虎斑貓。上面這個是小虎斑貓,這個是虎斑貓。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:30.680" id=03:30.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=210">03:30.680</a></div>
        <div class="t">你可能會說它們有什麼不同,其實我也不是很確定,總之因為現在就是這個樣子,它裡面的貓就是要有各種不同的品種就對了。所以這個結果你也不會說它辨識很差。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:41.860" id=03:41.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=221">03:41.860</a></div>
        <div class="t">如果我們加更多的雜訊,現在明顯地加了雜訊,圖片跟原來的圖片不同了,覺得有點毛茸茸的,所以機器說這是一隻波斯貓。它還是覺得它是貓,只是它毛茸茸,所以是波斯貓。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:57.440" id=03:57.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=237">03:57.440</a></div>
        <div class="t">我們今天再加更多的雜訊,加到這個地步,你已經覺得有點看不出來說這是什麼東西了,雜訊加得很大。機器終於辨識錯誤了,它說這個是一個Fire Screen。Fire Screen是什麼東西呢?我本來其實也不知道,我Google了一下。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:13.740" id=04:13.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=253">04:13.740</a></div>
        <div class="t">Fire Screen是這樣子一個東西,就在火爐前面放著一個屏風,用來不要讓房間太熱的這樣,就是火爐跟房間中間放了一個屏風。所以機器來說,它可能覺得說這個雜訊就是屏風上的網子,後面這個貓就是火焰,所以它覺得這個是Fire Screen,其實是還蠻有道理的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:38.720" id=04:38.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=278">04:38.720</a></div>
        <div class="t">所以我們今天學到說,Network其實可以輕易的被attack。至於這件事情到底為什麼會發生,我們可以這樣子來解釋。你可以想像說,今天你的X0,它是在一個高危平面上的一個點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:01.120" id=05:01.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=301">05:01.120</a></div>
        <div class="t">如果你把這個點隨機的移動,你把這個點根據某一個隨機的方向移動,你會發現多數的時候,這個TigerCat就代表說是TigerCat的信心分數,Model output出來是TigerCat的信心分數,Model output出來是波斯貓的信心分數,Model output出來是埃及貓的信心分數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:24.760" id=05:24.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=324">05:24.760</a></div>
        <div class="t">你會發現說,如果你把這個點隨機的移動,多數的時候,在這個點附近,它是TigerCat的信心分數都是非常高的。如果你把這個點移動的多一點,它可能就會變成是波斯貓的信心分數高,或者變成是埃及貓的信心分數高,但它們都仍然還是高。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:46.780" id=05:46.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=346">05:46.780</a></div>
        <div class="t">但是這個是隨機的方向。你知道說,今天一個S0,它是高危空間中的一個點,非常非常高危空間中的一個點,像我剛才的例子裡面,每張圖片是有225乘以225的解析度,所以每張圖片是在四萬危的空間中的一個點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:10.140" id=06:10.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=370">06:10.140</a></div>
        <div class="t">在這些非常高危的空間中,有某一些神奇的方向。在這些神奇的方向裡面,小虎斑貓是信心分數高的範圍,非常的狹窄。你只要把你的S0稍微推理一點,稍微改變一點,它是另外一個完全不相干的東西的信心分數,就會突然變得很高。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:35.760" id=06:35.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=395">06:35.760</a></div>
        <div class="t">當然這個只是試圖去解釋剛才的現象,為什麼剛才我們會說,如果加了一般的雜訊,攻擊沒有什麼效果,但是加了什麼歸零算盾的雜訊,會讓小虎斑貓瞬間變成鍵盤。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:53.300" id=06:53.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=413">06:53.300</a></div>
        <div class="t">在現象的解釋上是這個樣子的。你也可以在文獻上找到有人試圖去分析Network,確實發現說,在你的歸零所算出來的那個方向上,你所要攻擊的那個class,它的範圍非常的小,非常的狹窄,在其他方向上,它的範圍就比較寬廣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:18.520" id=07:18.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=438">07:18.520</a></div>
        <div class="t">不過這個只是描述了現象而已,這個現象究竟是怎麼出現的,為什麼訓練Network以後會導致這樣的現象,目前其實還沒有非常完整的解釋,所以我這邊也不多做說明,只告訴你說,這樣子的原因會造成攻擊非常容易成功,為什麼訓練Network以後會出現這樣的原因,這仍然是一個可以研究的方向。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:43.980" id=07:43.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ&t=463">07:43.980</a></div>
        <div class="t">有人可能會認為說,這個會不會來自於,比如說因為deep network就是不work,講到deep就是不work,所以應該用一些傳統的方法,其實傳統的decision tree跟SDN,它們也可以被attack,也可以跟deep learning一樣被attack,所以並不是只有CNN或deep的model會被attack,其他的model也可以做出非常類似的attack,所以不見得是deep的原因。</div>
    </div>
    
</body>
</html>   