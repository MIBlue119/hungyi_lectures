<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Meta Learning - Train+Test as RNN</h2><a href=https://www.youtube.com/watch?v=ePimv_k-H24><img src=https://i.ytimg.com/vi_webp/ePimv_k-H24/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=0">00:00.000</a></div>
        <div class="t">好,那其實有關meta learning的部分呢,還有非常小一段是還沒有講到的。是什麼呢?我們之前有講過了這個Science Network,那我們在講Science Network的時候,我們說你可以把Science Network或其他metric-based approach講成是meta learning,但是你其實有其他更容易的方法來理解這些metric-based approach。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:28.760" id=00:28.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=28">00:28.760</a></div>
        <div class="t">那我們之前在講那個Science Network的時候呢,我們開場白有說,我們想要做的事情是一個瘋狂的想法,我們想要找一個function,這個function它可以同時做到learning跟testing這兩件事,我們把train跟test放在同一個function裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:50.520" id=00:50.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=50">00:50.520</a></div>
        <div class="t">我們期待我們可以學出一個function,這個function可以做到說,把訓練資料丟進去,把測試資料丟進去,它直接吐出來的就是測試資料的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02.240" id=01:02.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=62">01:02.240</a></div>
        <div class="t">然後之前我們有講過說這個聽起來很瘋狂,那實際上我們使用的方法是Science Network跟它的種種變形,比如說Machine Network,比如說Prototypical Network等等,而這些變形你可以想成它們是特別設計了Network的架構來做到這邊我們要說的這件事,因為這件事聽起來很複雜,你直接用一個generalize的Network恐怕是做不到的,所以必須要設計一下Network的架構。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:32.000" id=01:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=92">01:32.000</a></div>
        <div class="t">才能夠達成我們的目標,但是我們這邊要說有沒有人嘗試過直接用一個general的Network來完成這件事呢?直接弄一個general的Network,input就是training data跟testing data,output就是testing data的label是有的,希望機器可以學到說看到這張圖片它是哪一個動畫的角色,然後你給它一個測試資料,希望它就可以直接output正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:59.640" id=01:59.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=119">01:59.640</a></div>
        <div class="t">那這個東西你可以把它想成是一個RNN可以解的問題,因為它input的東西就是一個sequence,先把訓練資料的每一筆資料一個一個的餵進去,再餵進去測試資料,然後希望你的RNN就可以output正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:16.680" id=02:16.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=136">02:16.680</a></div>
        <div class="t">所以你完全可以用一個RNN局來做LSTM來解這個問題,你希望這個LSTM把training data當作一個sequence讀進去,再讀進去測試資料的時候,output直接就是測試資料的答案,然後就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:31.960" id=02:31.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=151">02:31.960</a></div>
        <div class="t">我們在input的部分,因為這是一個影像分類的問題,所以每一筆訓練資料裡面都包含了一張圖片跟這張圖片屬於哪一個類別的label。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:47.000" id=02:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=167">02:47.000</a></div>
        <div class="t">你需要把這張圖片跟這個label做一下embedding,舉例來說,你可能會有一個CNN,然後把這張圖片讀進去,然後輸出一個embedding,然後你可能會把每一個類別用一個one-hot vector來表示,你把CNN的output跟類別的one-hot vector做concatenate,變成一個feature vector丟到LSTM裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:11.120" id=03:11.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=191">03:11.120</a></div>
        <div class="t">在測試的時候,因為測試資料的類別我們不知道,訓練資料每張圖片的類別我們知道,測試資料的類別我們不知道,訓練資料的類別我們可以用一個one-hot vector來表示,測試資料因為它的類別我們不知道,我們就用zero vector來表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:26.240" id=03:26.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=206">03:26.240</a></div>
        <div class="t">然後我們就把訓練資料跟測試資料合起來,看作是一個sequence丟到LSTM,然後訓練它的output,測試資料的label,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:35.880" id=03:35.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=215">03:35.880</a></div>
        <div class="t">那前人有試過這件事嗎?前人有試過這件事,果然勸不起來這樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:43.080" id=03:43.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=223">03:43.080</a></div>
        <div class="t">那怎麼辦呢?因為一般的LSTM是勸不起來的,所以就有人嘗試著去修改LSTM的架構。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:51.560" id=03:51.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=231">03:51.560</a></div>
        <div class="t">如果我們general的,一般的,我們常用的LSTM勸下去,在meta倫理上看起來做不起來的,就有人就試著更改neural的架構。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:01.080" id=04:01.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=241">04:01.080</a></div>
        <div class="t">其中比較知名的兩個例子,一個是NANN,它用的是neural turing machine,這個我們上課沒有講過,如果你有興趣再自己去查一下neural turing machine是什麼。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:12.480" id=04:12.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=252">04:12.480</a></div>
        <div class="t">還有另外一個東西叫做SNAIL,它裡面用的就是attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:16.800" id=04:16.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=256">04:16.800</a></div>
        <div class="t">而它們的neural架構,我們就不細講,我們這邊就把文獻放在這邊給大家參考。那SNAIL這個東西,你如果看它的neural架構圖,你可以很輕易地了解它在做什麼。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:32.120" id=04:32.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=272">04:32.120</a></div>
        <div class="t">那SNAIL是Simple Neural Attentive Meta Learner的縮寫,然後我不知道為什麼M不見了,總之它的縮寫就是SNAIL,就是蝸牛的意思。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:45.000" id=04:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=285">04:45.000</a></div>
        <div class="t">那另外一個可能是它的形狀長得像蝸牛,所以我們叫它蝸牛。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:50.200" id=04:50.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=290">04:50.200</a></div>
        <div class="t">然後它要怎麼做呢?它就是跟剛才我們講的東西是完全一樣的,我們就是把訓練資料跟它的label丟到network裡面去,丟到這個RN裡面去,把測試資料再丟進去。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:01.480" id=05:01.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=301">05:01.480</a></div>
        <div class="t">那唯一不同的地方是,它不是一個單純的RN,它裡面有attention,就很像是我們之前講transformer的時候講過的attention一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:10.720" id=05:10.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=310">05:10.720</a></div>
        <div class="t">當你把第二筆訓練資料丟進去的時候,它會去attent之前已經丟進來的東西,當你把第三筆資料丟進來的時候,它會去attent第一筆跟第二筆,當你把測試資料丟進來的時候,它會去attent過去所有的訓練資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:25.200" id=05:25.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=325">05:25.200</a></div>
        <div class="t">當我們把測試資料丟進去,它會attent過去所有的訓練資料的時候,這件事情你仔細想想看,它做的事情是不是跟什麼prototypical network或者是matching network非常像呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:36.640" id=05:36.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=336">05:36.640</a></div>
        <div class="t">我們說matching network做的事情是,丟一張圖片進來,然後你去計算這張圖片跟你的訓練資料的每張圖片的相似度,看誰最像,就拿那張最像的圖片的level出來當作正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:50.880" id=05:50.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=350">05:50.880</a></div>
        <div class="t">今天我們用一般的LSTM,train剛才講的那個瘋狂的想法,train跟test加在一起的想法做不起來,所以他們做了一下修改說,現在當我們把測試資料丟進來的時候,我們要回頭去對過去已經輸入進來的訓練資料做attent。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:08.360" id=06:08.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=368">06:08.360</a></div>
        <div class="t">這個行為其實就很像是matching network說,它把測試資料跟訓練資料去計算他們embedded的相似度,他們的道理是非常類似的,簡單來說殊途同歸。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:21.280" id=06:21.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=381">06:21.280</a></div>
        <div class="t">本來是想要用一個最general的方法來解meta類的問題,但是做到最後你還是需要改一下network架構,會變成matching network那一套的想法,其實是差不多的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:34.840" id=06:34.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=394">06:34.840</a></div>
        <div class="t">不過在文件上看起來,剛才介紹的Snail的performance看起來是蠻厲害的,上面這邊的實驗是Omega的實驗,這個是Snail的performance,它做了5-way跟20-way,1-shot跟5-shot。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:51.160" id=06:51.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=411">06:51.160</a></div>
        <div class="t">它的baseline多數我們都在課堂上講過了,這邊總共有6個baseline,我把這6個baseline他們是用什麼方法就寫在這邊,NANN是用Neural Touring Machine的方法,我們剛才在前幾頁的快門片大家有看到。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:06.720" id=07:06.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=426">07:06.720</a></div>
        <div class="t">Sanvis Network我們之前講過了,Matching Network我們之前講過了,NAML就是Memo我們之前講過了,Prototypical Network我們之前講過了,沒有講過的是Meta Network,沒有講過的是Meta Network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:19.000" id=07:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=439">07:19.000</a></div>
        <div class="t">總之Snail跟6個方法比一比,它的結果都是最好的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:25.480" id=07:25.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ePimv_k-H24&t=445">07:25.480</a></div>
        <div class="t">它也做了Mini ImageNet,做5-way,1-shot跟5-shot,這邊比的baseline是Matching Network,Memo,然後把LSTM當作歸顛Descent,這個我們也是之前講過了,然後Prototypical Network跟Meta Network,Snail看起來performance都是最好的。</div>
    </div>
    
</body>
</html>   