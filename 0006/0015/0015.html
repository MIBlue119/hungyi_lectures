<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Attack ML Models (8/8)</h2><a href=https://www.youtube.com/watch?v=ah_Ttx6cIVU><img src=https://i.ytimg.com/vi_webp/ah_Ttx6cIVU/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=0">00:00.000</a></div>
        <div class="t">好,那接下來我們就進入防禦的部分,那其實啊,有人會覺得說,今天network之所以會被攻擊,是因為他太overfeed你的training data。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:12.760" id=00:12.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=12">00:12.760</a></div>
        <div class="t">那其實這個答案並不完全正確,因為你會發現說,就算是你對你的network做了種種防制overfeeding的手段,比如說你做regularization,你做dropout,你做model的ensemble,aggressive attack還是可以成功的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:30.240" id=00:30.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=30">00:30.240</a></div>
        <div class="t">尤其是多數人會想像說,model的ensemble會成功,可以擋住aggressive attack,但其實並不是這樣,因為有人會想像說,也許attack只能對某一個model生效,那其他model就可以擋住那個attack,所以model的ensemble可以擋住attack這件事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:44.800" id=00:44.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=44">00:44.800</a></div>
        <div class="t">但其實並不然,因為我們剛才已經看到說attack這件事情是可以跨model的,你可以成功攻擊Amodel就可以成功攻擊Bmodel,所以model的ensemble組一個model的團來辨識同一個東西,不見得非常有用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:58.560" id=00:58.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=58">00:58.560</a></div>
        <div class="t">今天的防禦手段分成兩大類,第一大類是被動的防禦手段,也就是說你不對你的network做任何的改變,network就是這樣,已經訓練好就在那邊,但是你再另外幫它加一層防護罩,幫它阻擋來自外界的攻擊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:17.560" id=01:17.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=77">01:17.560</a></div>
        <div class="t">其實這個問題可以被看作是我們上周所講的anonymous detection的一個特例,因為我們可以說,今天這是一個anonymous detection的問題,machine要找出那些有加入攻擊效果的圖片,這是奇怪的圖片,machine要找出那些奇怪的圖片。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:34.360" id=01:34.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=94">01:34.360</a></div>
        <div class="t">但它又不是一個一般的anonymous detection的攻擊,因為那些訊號是特別被藏起來的,它是非常難被找到的。這個是被動的攻擊,還有主動的攻擊。主動的攻擊就是,我們在訓練模型的時候,我們就要把防禦這件事情加到訓練模型的過程中。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:52.960" id=01:52.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=112">01:52.960</a></div>
        <div class="t">我們來看被動的攻擊的例子。怎麼做被動的攻擊呢?這邊就舉兩個例子。被動的攻擊,它通常的概念是這個樣子。我們現在有一個network,它看到這張有被攻擊的圖片,它會把這隻貓看作是鍵盤。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:10.560" id=02:10.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=130">02:10.560</a></div>
        <div class="t">我們在這個network前面加一個filter,這個filter它就是一個防護罩。今天你一般的圖片通過這個filter,沒發生什麼事,但是如果是雜訊通過這個filter,希望它的傷害就可以被減輕。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:26.560" id=02:26.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=146">02:26.560</a></div>
        <div class="t">那怎麼樣的filter可以做到這種事情呢?其實你不需要太複雜的filter就可以做到這樣的事情。舉例來說,你把你的image稍微做一下平滑化,它就是一個有用的filter。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:41.560" id=02:41.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=161">02:41.560</a></div>
        <div class="t">那我就實際做了一下實驗,我們現在把原來的image,它被機器認為是虎斑貓的image,加入這個filter,把它做平滑化以後,機器仍然覺得它是虎斑貓。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:56.560" id=02:56.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=176">02:56.560</a></div>
        <div class="t">但是假如我們把剛才那張有被攻擊的image,加上filter以後,機器就回去覺得它是虎斑貓,而不覺得它是鍵盤。為什麼這樣子的加filter的方法可以成功呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:13.060" id=03:13.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=193">03:13.060</a></div>
        <div class="t">你可以想像說,今天這個攻擊的信號只有在某個方向上的信號,只有某一種的信號可以讓攻擊的成功。雖然這種信號可以同時讓很多各種不同的微訊、門鈴、麥克風都失效,但是其實只有某幾個方向上的信號,只有某幾種信號可以讓攻擊成功。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:35.060" id=03:35.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=215">03:35.060</a></div>
        <div class="t">我們今天一旦加上了一個filter,比如說做smoothing這件事,你把那個訊號改變了,那攻擊就失效了。而同時加上smoothing這件事,並不會傷害原來的圖片,所以你仍然可以得到正確的辨識結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:51.220" id=03:51.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=231">03:51.220</a></div>
        <div class="t">所以根據這樣子的想法,有一個方法叫做feature squeezing,它這邊所謂的squeezer指的就是不同的filter,你可以設計不只一個filter來保護你的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:03.100" id=04:03.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=243">04:03.100</a></div>
        <div class="t">這個feature squeeze的想法是說,我們現在有一張image進來,那你先把這個image原封不動地用你的model做一下prediction,得到第一個prediction的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:14.420" id=04:14.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=254">04:14.420</a></div>
        <div class="t">接下來你把這張圖片通過squeezer1得到一個prediction的結果,通過squeezer2得到一個prediction的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:22.460" id=04:22.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=262">04:22.460</a></div>
        <div class="t">如果今天有做squeeze以後,你發現有做squeeze前跟有做squeeze後,今天你的model辨識的結果差很多,那你就可以知道說這張圖片可能是有被攻擊過的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:36.060" id=04:36.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=276">04:36.060</a></div>
        <div class="t">還有另外一個方法,也是在你的model前面加一個防護罩的方法,今天一張圖片進來,你對這張圖片做一些random的改動,比如說你把這張圖片稍微進行一點縮放,然後在它旁邊加上一些像是雜訊一樣的東西,比如說加上一些零。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:04.620" id=05:04.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=304">05:04.620</a></div>
        <div class="t">但是你這個random縮放的程度,還有旁邊加的東西當然不能太多,因為如果你多到說會讓你原來的影像被辨識錯誤的話,那這個就得不償失了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:14.740" id=05:14.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=314">05:14.740</a></div>
        <div class="t">所以你希望做一些小小的縮放,在旁邊加上一些小小的padding,然後讓你原來的雜訊跟原來不太一樣,我們說這些雜訊的攻擊只有在某個方向上可以成功。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:29.060" id=05:29.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=329">05:29.060</a></div>
        <div class="t">如果你今天稍微做了一些縮放,那個方向就改變了,攻擊就很有可能失效。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:35.140" id=05:35.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=335">05:35.140</a></div>
        <div class="t">不過這些防禦的方法,就是你在你的model前面加一個盾牌的方法,他們會害怕的就是,你如果盾牌的防禦機制被洩漏出去,那攻擊就很有可能仍然會是成功的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:50.140" id=05:50.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=350">05:50.140</a></div>
        <div class="t">舉例來說,以剛才那個filter為例,你可以把filter想像成是network的第一個layer,所以假設有人知道那個filter是怎麼運作的,那他完全就可以把filter想像成是network的第一個layer,然後用傳統的type方法去攻擊你的network,仍然是有可能會成功的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:09.180" id=06:09.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=369">06:09.180</a></div>
        <div class="t">或者是說,加上一些random的縮放的這件事情,如果你是怎麼做random的縮放這件事情被洩漏出去的話,攻擊也有可能是成功的,因為我們剛才講說,其實今天可以做到universal attack,所以有人可能可以創造出一個雜訊,這個雜訊對所有不同的縮放通通都是成功的,那他仍然可以成功的攻擊你的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:33.660" id=06:33.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=393">06:33.660</a></div>
        <div class="t">那這邊講的是被動的防禦方式,那接下來講一個主動的防禦方式,那這個主動的防禦方式它的精神就是今天在訓練network的時候,我們去把network的漏洞找出來,把漏洞找出來以後,接下來把它補起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:52.580" id=06:52.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=412">06:52.580</a></div>
        <div class="t">一般訓練network的時候,你的訓練過程是這樣子的,你有一筆訓練的資料,你有一大堆訓練的資料,你把這堆訓練的資料叫做x,那每一筆訓練的資料,你都有一個label y hat,然後接下來你用這個訓練資料去訓練你的模型,那一般訓練network這樣子就訓練完了,那接下來我們要把這個network的漏洞找出來,然後把找出來的漏洞補起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:21.140" id=07:21.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=441">07:21.140</a></div>
        <div class="t">怎麼把找出來的漏洞補起來呢?你要在train大T一個iteration,在每一個iteration裡面,你對每一張圖片都找出它的attack的image,就是你把train data裡面的每一個圖片xn通通倒出來,然後用某一個attack的algorithm,找出可以attack你現有的model的input,我們這邊的寫作xn,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:49.460" id=07:49.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=469">07:49.460</a></div>
        <div class="t">然後再把這些可以attack成功的image當作你的training data,你先把漏洞找出來,找出這些可以attack成功的image x tilde,然後把這些x tilde標上跟原來image一樣的label,然後再把這些新的資料拿去訓練你的network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:10.900" id=08:10.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=490">08:10.900</a></div>
        <div class="t">你可以想像這個過程其實有點像是data augmentation,有點像是增加data的這種做法,就是你用adversarial attack的方法去找到更多的data,把這些data加到你的訓練資料裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:25.620" id=08:25.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=505">08:25.620</a></div>
        <div class="t">你可以想像說,本來如果x tilde可能會被辨識錯誤,但是我們現在把x tilde加到你的訓練資料裡面,給它一個正確的label,希望我們就可以把洞補起來。這邊為什麼要採取大T的iteration呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:41.140" id=08:41.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=521">08:41.140</a></div>
        <div class="t">為什麼不是找出漏洞,補起來以後就結束了呢?因為你今天找出漏洞以後,你找出這些x tilde,再重新訓練你的network以後,你的network參數就變了。network參數變了以後,它可能就會有新的漏洞,所以你要重新再去找漏洞。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:58.660" id=08:58.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=538">08:58.660</a></div>
        <div class="t">也就是你把你的network參數update以後,你要重頭再去找出漏洞,然後找出新的可以attack成功的image,再把這些新的可以attack成功的image,再加到你的訓練資料裡面,再重新做訓練。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:11.460" id=09:11.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=551">09:11.460</a></div>
        <div class="t">這樣的process,找漏洞,然後把洞補起來,但它可能會有新的洞,這種process要反覆很多次,就跟你在訓練network一樣,你要iterative地去做這件事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:23.300" id=09:23.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=563">09:23.300</a></div>
        <div class="t">這邊有另外一個要注意的事情就是,今天假設你在找漏洞的時候,你用的attack algorithm是A方法,但是實際上人家採用B方法來攻擊你的時候,你往往還是會防守不住的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:39.620" id=09:39.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=579">09:39.620</a></div>
        <div class="t">如果你用A方法來找漏洞,然後你用A方法來攻擊,你確實會發現說,今天network確實可以防住A方法了,但是如果別人用B方法來攻擊的時候,這個攻擊仍然是會被突破的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:51.620" id=09:51.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=591">09:51.620</a></div>
        <div class="t">所以這邊的問題就是,假設你在找漏洞的時候,你找漏洞的方法被洩漏出去,別人只要用其他找漏洞的方法,就仍然可以製造出成功的攻擊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:02.820" id=10:02.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU&t=602">10:02.820</a></div>
        <div class="t">所以defense今天仍然是一個困難而尚待解決的問題。</div>
    </div>
    
</body>
</html>   