<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Life Long Learning (4/7)</h2><a href=https://www.youtube.com/watch?v=UgLx4rjcCO8><img src=https://i.ytimg.com/vi_webp/UgLx4rjcCO8/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:01.000" id=00:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=1">00:01.000</a></div>
        <div class="t">剛才我們講到multi-task learning,我們講說multi-task learning其實對解決遺忘這件事情是非常強的方法,雖然說它在實際的應用上可能會有一些問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:15.540" id=00:15.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=15">00:15.540</a></div>
        <div class="t">所以在做live-long learning的時候,我們不能說我們用multi-task的這個解法就解決了災難性遺忘這樣子的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:24.000" id=00:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=24">00:24.000</a></div>
        <div class="t">但是如果你看這種live-long learning的paper的話,它通常都會把這種multi-task learning當作是live-long learning的upper bound,因為你其實用multi-task learning就可以解決遺忘性的問題,所以multi-task learning通常是live-long learning的upper bound,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:40.400" id=00:40.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=40">00:40.400</a></div>
        <div class="t">你就告訴你說,我現在apply這個live-long learning的技術,離multi-task learning還有多接近。既然multi-task learning這麼好用,有人就想了一個奇招,就是你既然不能夠記過去的資料,因為你的memory有限,你能不能夠認一個model,這個model它可以產生過去的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:58.880" id=00:58.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=58">00:58.880</a></div>
        <div class="t">你知道,要存這種資料需要比較大的memory,比如說image內那個focus裡面有超過百萬張的image,大概有上百G、兩百G那麼大,但是你把它訓練成一個generator,訓練成一個可以產生image的network,那它可能只有幾百MB而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:17.240" id=01:17.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=77">01:17.240</a></div>
        <div class="t">所以存整個data set可能有困難,但能不能夠存一個model,這個model很厲害,它可以generate出那個data set裡面的data。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:28.160" id=01:28.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=88">01:28.160</a></div>
        <div class="t">所以你就想了這個非常特別的方法,我們現在先用機器去學task 1,過去你就是我先在task 1上學一個task 1的,比如說它是分類的問題,你就是學一個task 1的classifier,然後讓它再去學task 2,那它可能就會有遺忘的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:45.560" id=01:45.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=105">01:45.560</a></div>
        <div class="t">我們現在訓練一個generator,這個generator它可以generate task 1的data,因為這個generator它可以學會產生task 1的data,但是這個generator怎麼訓練,我們今天就不講了,之後我們在課程錄影裡面是有關generative model的課程的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:04.640" id=02:04.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=124">02:04.640</a></div>
        <div class="t">我們會告訴大家說,比如說generative model裡面,大家最耳熟能詳的就是建這個技術是怎麼被訓練出來的。這個generator它可以generate task 1的data,這個generator可以學會generate task 1的data,所以你就可以把task 1的data丟掉,反正這個generator你叫它生一些task 1的data,它就會生出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:25.820" id=02:25.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=145">02:25.820</a></div>
        <div class="t">反正這個generator就生一些task 1的data出來,然後就可以把它跟task 2的data倒在一起,一起去訓練task 2的model,去訓練task 2的classifier。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:37.340" id=02:37.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=157">02:37.340</a></div>
        <div class="t">接下來,你把task 2的data拿出來,你把可以generate task 1的data的generator拿出來,把它的data,叫它生一些task 1的data,把task 1的data跟task 2的data加在一起,以後可以訓練一個新的generative model,它可以產生task 1跟task 2的data。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:55.940" id=02:55.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=175">02:55.940</a></div>
        <div class="t">這樣你就可以做multi-task learning,但是你不需要存過去的資料。當然這種方法,我這邊列了一些reference,這些都是發表在很好的conference上,第一篇這個是發表在NIPS 2017,這個發表在iClear 2018。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:10.700" id=03:10.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=190">03:10.700</a></div>
        <div class="t">這種方法在實際的應用上有多強,是一個尚待研究的問題,因為要讓機器學會生成並沒有那麼容易。你說要生成一些at least裡面的data,生成一些數字,也許也還罷了。要讓機器生成非常高清的影像,其實並不是一件那麼容易的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:29.780" id=03:29.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=209">03:29.780</a></div>
        <div class="t">所以這個方法在實用上到底做不做得起來,是一個仍然需要尚待研究的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:36.220" id=03:36.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=216">03:36.220</a></div>
        <div class="t">在我們剛才的討論裡面,我們其實都假設說不同的任務用的network structure就是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:46.340" id=03:46.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=226">03:46.340</a></div>
        <div class="t">舉例來說,我們的任務,剛才在講這個手寫數字辨識的時候,任務1跟任務2都是手寫數字辨識,只是一個有加noise,一個沒有加noise。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:55.260" id=03:55.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=235">03:55.260</a></div>
        <div class="t">所以你可以完全用同樣的network structure來解這兩個任務。但是有時候你會遇到的問題是,假設今天第一個任務跟第二個任務需要用不同的network structure來解,怎麼辦?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:09.020" id=04:09.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=249">04:09.020</a></div>
        <div class="t">第一個任務它可能是十個類別的分類的問題,第二個任務是二十個類別的分類的問題,那這十個類別跟二十個類別它們是不同的類別,那你需要改一下你的network structure,在live learning裡面應該要怎麼做呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:24.500" id=04:24.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=UgLx4rjcCO8&t=264">04:24.500</a></div>
        <div class="t">在這邊就是列一些reference給大家參考。有一個方法叫LWF,還有一個方法叫ICIL,就把這個reference列在這邊給大家參考。</div>
    </div>
    
</body>
</html>   