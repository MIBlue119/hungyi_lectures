<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Life Long Learning (2/7)</h2><a href=https://www.youtube.com/watch?v=X7aWP6LngEs><img src=https://i.ytimg.com/vi_webp/X7aWP6LngEs/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.520" id=00:00.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=0">00:00.520</a></div>
        <div class="t">主持人說的,災難性遺忘的問題很容易解決,因為你剛才不是已經示範了怎麼解決災難性遺忘的問題嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:10.600" id=00:10.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=10">00:10.600</a></div>
        <div class="t">你剛才示範說,我們如果讓機器同時學很多的task,叫做multitask learning,我們把很多的task的內涵統統倒在一起,讓機器同時去學,它不就統統都可以學得會了嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:24.200" id=00:24.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=24">00:24.200</a></div>
        <div class="t">你只要這樣做,就可以解決機器會遺忘過去的任務的問題。但是以舊常人而言,這招最終會是行不通的,因為假設我們今天要學的任務有一千個,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:37.960" id=00:37.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=37">00:37.960</a></div>
        <div class="t">那機器要學第一千個任務的時候,你必須要確保說過去第一個到第999個任務的那些資料統統都還在,然後你把第一千個任務的資料跟第一個到第999個任務的資料統統都倒在一起,然後讓機器去學。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:55.440" id=00:55.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=55">00:55.440</a></div>
        <div class="t">這樣的問題就是,你必須要讓機器背負著它整個人生,它過去所有學過的資料,它統統必須要存在記憶體裡面,帶在身上,之後有新的任務的時候,它必須要把舊的資料跟新的資料統統倒在一起,它才能夠去學。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09.440" id=01:09.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=69">01:09.440</a></div>
        <div class="t">首先,你要把所有舊的資料統統都存起來,在memory上,在storage上,它就是一個issue,就好像你不可能背著你這一生都讀過的教科書在路上行走一樣,機器也不可能把所有它過去統統學過的資料統統都存在記憶體裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:26.800" id=01:26.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=86">01:26.800</a></div>
        <div class="t">再來就是,今天如果它每次要學一個新的任務,都要把所有舊的資料統統都倒來學的話,你在運算上也會有問題。本來你學一個任務可能要一天,那你現在要同時把一千個任務的資料統統倒在一起,那豈不是學一個新的任務要花一千天的時間嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:44.800" id=01:44.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=104">01:44.800</a></div>
        <div class="t">這樣子也是行不通的。所以我們期待的事情是,能不能在不做multi-task training的情況下,不把過去的資料拿來做multi-task learning,不把過去的資料倒拿出來跟新的資料混在一起training的情況下,讓機器不要忘記過去已經學過的技能。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:06.560" id=02:06.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=126">02:06.560</a></div>
        <div class="t">這個就是Lifelong Learning主要要探討的一個問題。有什麼樣的解法呢?這就跟大家介紹一個經典的解法,叫做Elastic Way Consolidation EWC。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:20.320" id=02:20.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=140">02:20.320</a></div>
        <div class="t">Elastic是有彈性的意思,Consolidation是保護、鞏固的意思。這個EWC的基本想法就是說,今天當機器在學完過去的任務以後,它學完以後,有一些Navigation,然後有一些Wait,它是重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:44.480" id=02:44.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=164">02:44.480</a></div>
        <div class="t">改掉以後,過去的任務它就會忘記怎麼做,那有一些Wait是不重要的。我們把過去學過的重要的那些Wait,那些Wait裡面重要的參數,把它鞏固起來,不要再做太大的更動,只調那些對過去的任務沒有太大影響的那些Wait。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:04.800" id=03:04.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=184">03:04.800</a></div>
        <div class="t">所以今天在EWC這個類型的方法裡面,這是一系列的方法,有好多篇論文都是使用了非常類似的方法。在EWC這個系列的方法裡面,假設你在過去的任務學完以後,你得到的model參數叫做SETA B,SETA B是一個network,裡面包含了一大堆的Wait跟Bias。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:26.160" id=03:26.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=206">03:26.160</a></div>
        <div class="t">現在SETA B裡面的每一個參數都會有一個守衛,這個守衛它是一個數值,我們用Bi來表示。每一個參數SETA下標i,代表SETA B這個model裡面的第i的參數,每一個第i的參數會有一個守衛叫做Bi,告訴我們說這個參數有多重要,我們有多不應該更改這個參數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:55.680" id=03:55.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=235">03:55.680</a></div>
        <div class="t">所以當你在使用EWC這樣的想法的時候,你原來的Loss Function叫做Loss SETA,我們一般在做training的時候,你就是要去找一個參數SETA,這個SETA可以minimize Loss SETA,但是今天在做EWC的時候,我們原來的Loss後面再多加一項,這一項是什麼呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:17.000" id=04:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=257">04:17.000</a></div>
        <div class="t">這一項是Summation over所有network裡面的參數,把每一個參數SETA i拿出來,然後把計算這個SETA i跟之前的任務所學到的參數SETA i之間的距離,然後在這個距離前面乘上我們的守衛Bi。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:44.000" id=04:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=284">04:44.000</a></div>
        <div class="t">乘上這個代表參數有多重要的守衛Bi,然後把所有的參數通通都加起來,那這個東西是我們的新的Loss Function,也就是說我們今天要找一個新的SETA的時候,我們在我們的新的任務,現在跑在任務上面,要訓練我們的model的時候,我們不只希望我們可以把新的任務做好,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:06.840" id=05:06.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=306">05:06.840</a></div>
        <div class="t">但同時我們又希望說,今天我們新學出來的參數跟舊的參數它的差別不要太大,但是這個差別不要太大,它是對每一個參數而言都是不同的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:21.200" id=05:21.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=321">05:21.200</a></div>
        <div class="t">舉例來說,我們舉一個具體的例子,假設今天Bi設為0,那等於SETA i就沒有任何的限制,SETA i可以是任何的值都不會影響我們Optimization的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:37.280" id=05:37.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=337">05:37.280</a></div>
        <div class="t">假設Bi等於0,代表說今天這個SETA i是沒有被保護起來的,你今天在學這個新的任務的時候,你可以任意調整SETA i的值。但今天假設Bi是無限大,代表說SETA i是非常強烈的被保護起來的,你今天在訓練的過程中,你不可以動到SETA i的值。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:58.720" id=05:58.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=358">05:58.720</a></div>
        <div class="t">你一定要讓SETA i的值跟之前學出來的、在過去的任務上學出來的SETA i的值一模一樣。你在學習的過程中,你不能夠去動到SETA i的值。你要讓SETA i的值跟過去學出來的結果是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:16.600" id=06:16.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=376">06:16.600</a></div>
        <div class="t">好,那這個第二項呢,我們可以把它想成是一個regularization term,但它不是一般的regularization term。那我們之前的課程裡面呢,有講過這個L1、L2的regularization,你希望你學出來的參數不要距離這個zero vector太遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:39.480" id=06:39.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=399">06:39.480</a></div>
        <div class="t">那今天這個regularization,它是我們希望我們新學出來的參數SETA,在新的任務上學出來的參數SETA不要跟之前在舊的任務上學出來的參數SETA b距離太遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:53.920" id=06:53.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=413">06:53.920</a></div>
        <div class="t">但是這邊特別的地方是,我們對於這個SETA裡面的每一個不同的參數有不同的考量。有的參數需要跟之前在過去的任務上學出來的參數距離很近。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:08.640" id=07:08.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=X7aWP6LngEs&t=428">07:08.640</a></div>
        <div class="t">有的參數跟之前學出來的參數距離很遠,也沒有關係。那至於距離要遠還是近,取決於我們的這個守衛bi。那至於bi怎麼決定,我們等一下會說到。</div>
    </div>
    
</body>
</html>   