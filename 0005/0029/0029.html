<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>[DLHLP 2020] Deep Learning for Question Answering (2/2)</h2><a href=https://www.youtube.com/watch?v=h_Lptoq8spQ><img src=https://i.ytimg.com/vi_webp/h_Lptoq8spQ/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=0">00:00.000</a></div>
        <div class="t">我們上次呢,講到這個地方。那接下來呢,要跟大家講各式各樣的問題,還有這些不同類型,它們可能的解法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:14.000" id=00:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=14">00:14.000</a></div>
        <div class="t">那等一下呢,我們會講三大類的問題。第一類的問題我叫做Simple Question,第二類的問題叫做Complex Question,第三類的問題叫做Dialogue Question。那由上到下呢,分別是由簡單到越來越難。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:37.000" id=00:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=37">00:37.000</a></div>
        <div class="t">那什麼是Simple Question呢?在這邊所謂的Simple的意思是說,這些問題只需要兩步就可以解決了。第一步是Match,第二步是Extract。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:52.000" id=00:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=52">00:52.000</a></div>
        <div class="t">那這邊舉一個具體的例子。舉例來說呢,右邊這邊是Square非常標準的題型。Square的Compass裡面,通常它的文章跟問題就長得像右邊舉的範例差不多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07.000" id=01:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=67">01:07.000</a></div>
        <div class="t">那機器在讀完這篇文章以後,你問機器一個問題,What caused precipitation to fall?那假設你不知道什麼是Precipitation,也沒有關係,反正你可以把文章裡面有提到這個你根本不知道的單字的位置把它先圈出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:28.000" id=01:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=88">01:28.000</a></div>
        <div class="t">這個Precipitation出現在這個地方,出現在這個地方。那你再看這個問題裡面還有哪些比較重要的詞彙呢?比如說Fall可能是一個重要的詞彙,Fall有沒有出現在文章裡呢?有的,它出現在文章裡的這個地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:44.000" id=01:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=104">01:44.000</a></div>
        <div class="t">那現在看起來這個句子Question裡面兩個比較重要的詞彙在這個句子裡面都有出現,那答案就從這個句子裡面找,我們這邊可能就抽出Gravity作為答案,那這可能就是正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:59.000" id=01:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=119">01:59.000</a></div>
        <div class="t">所以像Squat這個Compass裡面很多問題都是做Match,然後你就可以把答案抽取出來。所謂做Match的意思就是找找看說文章裡面有沒有哪些段落,有沒有哪些句子,它裡面有出現問題裡面的關鍵詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:17.000" id=02:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=137">02:17.000</a></div>
        <div class="t">然後接下來在這個句子裡面找出某一個詞彙當作你的答案,你先做Match這件事,找出重要的句子,然後再做Extract這件事,把詞彙抽出來就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:33.000" id=02:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=153">02:33.000</a></div>
        <div class="t">好,那這類Simple的Question怎麼用Neural Network來實踐呢?這個經典的做法就是使用Question到Context的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:47.000" id=02:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=167">02:47.000</a></div>
        <div class="t">好,那這個Question到Context的Attention是怎麼實作的呢?首先,你有一個Knowledge Source,通常它是一篇文章,你把這篇文章丟到一個Source的Module裡面,然後文章裡面的每一個Token,或者是每一個Word,或者是每一個Sentence,取決於你現在想要使用的單位是什麼。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:09.000" id=03:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=189">03:09.000</a></div>
        <div class="t">文章裡面的比如說每一個Token,它就會變成一個Embedding。好,那問題的部分也如法炮製,把一個問題丟到這個問題的Module裡面,然後這個問題的Module就Output一個向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:24.000" id=03:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=204">03:24.000</a></div>
        <div class="t">那這個向量代表了問題裡面的整個問題完整的資訊。好,那如果是在過去還沒有BERT的年代,這邊你可能就用一個Bidirectional的LSTM,這邊你可能就用一個LSTM把問題讀過去,把最後一個Time Step的Embedding抽出來,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:45.000" id=03:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=225">03:45.000</a></div>
        <div class="t">那當然如果是今天,你可能就會選擇用BERT,每一個Token都可以得到一個BERT的Embedding。那Question,如果你只要一個Embedding的話,也許你會選擇抽個CLS那個Token的Embedding等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:59.000" id=03:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=239">03:59.000</a></div>
        <div class="t">好,總之現在你的Knowledge Source變成一排Vector,你的Question變成一個Vector。好,那接下來怎麼實踐Match這件事呢?你就用Attention。那你發現Attention這件事情,其實就是在做Match這件事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:17.000" id=04:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=257">04:17.000</a></div>
        <div class="t">因為我們在做Attention的時候,其實就是把這個Query的Vector跟這邊的每一個Embedding都去計算一個相似度,得到一個Attention的Weight。這邊α1到α5就是Attention的Weight,代表了這些Embedding跟這個問題的相似度。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:35.000" id=04:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=275">04:35.000</a></div>
        <div class="t">而計算相似度這件事情,其實就是Match。我們想要找出跟這個問題有關係的這些詞彙,出現在文章裡的哪些部分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:48.000" id=04:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=288">04:48.000</a></div>
        <div class="t">那接下來我們要做Extract這件事情,我們要把答案抽取出來。那怎麼把答案抽取出來呢?你可以用的做法就是把這些Weight對這些Vector做WeightedSum,得到一個新的Vector,再把這個新的Vector丟到Answer的Module,讓Answer的Module去做Process。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:15.000" id=05:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=315">05:15.000</a></div>
        <div class="t">而你在做WeightedSum的時候,你在把這些α對某些Vector做WeightedSum的時候,不見得要使用這些拿來計算Matching的Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:28.000" id=05:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=328">05:28.000</a></div>
        <div class="t">常見的做法是說,你的這個Source Module會產生另外一組Vector,這一組Vector也是每一個Token有一個Vector。那今天呢,這個α是用藍色的Vector算出來的,但是在做WeightedSum,在把某些Vector用α做WeightedSum的時候,是對綠色的這些Vector做WeightedSum。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:55.000" id=05:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=355">05:55.000</a></div>
        <div class="t">你就得到這個藍色的向量,那有這個藍色的向量以後,你把這個藍色的向量丟到Answer Module裡面,再看Answer Module要怎麼把答案找出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:06.000" id=06:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=366">06:06.000</a></div>
        <div class="t">舉例來說,如果今天是像Baby那種Corpus,你的答案只是一個單詞,那你的Answer Module就是一個Classifier,這個Classifier根據這個向量可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:20.000" id=06:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=380">06:20.000</a></div>
        <div class="t">那如果今天你是像Squad這種題型,你的Answer Module必須要找出一個Time Step,舉例來說,在還沒有Birth的年代,你的Answer Module可能是一個LSTM,那也許這個Vector就是LSTM的Initial State。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:38.000" id=06:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=398">06:38.000</a></div>
        <div class="t">所以接下來就看這個Answer Module拿這個藍色的向量做什麼事,然後期待說Answer Module可以根據這個藍色的向量,抽取出正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:50.000" id=06:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=410">06:50.000</a></div>
        <div class="t">所以發現說,用Query to Context的Attention,我們就可以做到Match,然後Extract這樣的Process,那你就有機會用這樣子的Network架構來簡單的,只要Match跟Extract就可以解。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:08.000" id=07:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=428">07:08.000</a></div>
        <div class="t">那像這樣子的QA的Model,它的起源非常非常的早。第一個使用Query to Context的Attention的Model,就是鼎鼎大名的End-to-End的Memory Network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:23.000" id=07:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=443">07:23.000</a></div>
        <div class="t">你會發現它是一個非常早的上古神獸,它是發表在15年的News,五年前的東西,在Deep Learning的這個領域看來就是不可思議的古老神獸。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:38.000" id=07:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=458">07:38.000</a></div>
        <div class="t">你畫得差不多,你有一個問題進來,你有一篇文章,那個時候並不是拿Token當作單位來做Embedding,也不是拿Word當作單位來做Embedding,那個時候是拿Sentence當作單位來做Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:54.000" id=07:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=474">07:54.000</a></div>
        <div class="t">每一個Sentence它會有一個向量,然後接下來你有兩個Transform,一個Transform製造那些拿來算Matching的Vector,另外一個Transform製造拿來算Weighted sum的那些Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:10.000" id=08:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=490">08:10.000</a></div>
        <div class="t">接下來,你有這些拿來做Matching的Vector以後,根據這個Question,你就可以計算出一組Attention的Weight,跟這組Attention的Weight,跟這些拿來做Weighted sum的Vector做Weighted sum,得到一個新的Vector叫做O.</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:24.000" id=08:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=504">08:24.000</a></div>
        <div class="t">你把這個O跟原來的Q加起來,一起丟到Answer的Module裡面,然後就可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:32.000" id=08:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=512">08:32.000</a></div>
        <div class="t">因為Answer Memory Network最早是被用在Baby上面,所以它會把QA當作是一個Classification的問題,所以這邊只需要解一個Classification的問題,預測出正確的答案是哪一個詞彙,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:47.000" id=08:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=527">08:47.000</a></div>
        <div class="t">那你可能會問說,也許我們今天並不是用一個Vector來表示一個Question,也許今天Question的表示方式跟Multisource一樣,也是一排向量,Question裡面的每一個Token,我們也給它一個Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:07.000" id=09:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=547">09:07.000</a></div>
        <div class="t">那這個時候,怎麼使用Query to Context的Attention呢?那這邊其實有不同的做法,那我就舉一個常見的Typical的做法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:18.000" id=09:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=558">09:18.000</a></div>
        <div class="t">怎麼做呢?把這邊的每一個Vector都分別去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:24.000" id=09:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=564">09:24.000</a></div>
        <div class="t">你把第一個Vector做一下Attention,得到一排Attention的Weight。你把第二個Vector去做Attention,得到另外一排Attention的Weight。你再把第三個Vector去做Attention,又得到另外一排Attention的Weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:42.000" id=09:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=582">09:42.000</a></div>
        <div class="t">那接下來呢,現在每一個Embedding,每一個Knowledge Source裡面的Embedding,都已經有三個Attention的Weight。要用哪一個才是對的呢?也許你做個Max,你就取一個Max,看這三個Alpha裡面,哪一個值最大,就出來代表全體。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:04.000" id=10:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=604">10:04.000</a></div>
        <div class="t">那你現在從每一個Column裡面呢,都找出一個最大的Alpha出來代表全體以後,你就每一個位置,每一個Embedding都有一個Alpha。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:16.000" id=10:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=616">10:16.000</a></div>
        <div class="t">然後接下來呢,你一樣可以做Weighted Sum,抽出一個Vector,再把這個Vector丟到Answer的Module裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:24.000" id=10:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=624">10:24.000</a></div>
        <div class="t">這是另外一種做Query to Context的Attention的方法。那如果你今天你的Question是用Super Vector來表示的時候,也許你會用這樣的方法來做Query to Context的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:38.000" id=10:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=638">10:38.000</a></div>
        <div class="t">那這邊呢,再舉一個文獻上的例子,讓你知道說這種方法是真的有被廣泛使用的。那這邊舉的是VQA的例子,也就是說給機器看一張圖片,再問它一個問題,問它說貓呢,有沒有在籃子裡面,希望它可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:01.000" id=11:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=661">11:01.000</a></div>
        <div class="t">那怎麼做呢?這張圖片呢,可能先通過CNN,通過CNN以後呢,這張圖片的每一個位置都會被一個向量表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:15.000" id=11:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=675">11:15.000</a></div>
        <div class="t">接下來呢,你再把每一個位置的向量做兩種不同的Transform,一種Transform的結果是要拿來做Matching,另外一種Transform的結果是要拿來做Weighted Sum,是要拿來Extract資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:33.000" id=11:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=693">11:33.000</a></div>
        <div class="t">那在這個問題的部分呢,問題的部分是一排文字,那每一個文字它其實都可以被表示成一個Embedded,所以一個問題進來,它其實是一個Vector的Sequence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:47.000" id=11:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=707">11:47.000</a></div>
        <div class="t">那在這個圖上就很簡單的告訴你說,這邊有一個Vector的Sequence,這邊有一群拿來算Matching的向量,這個拿來算Matching的向量是這個圖片上的每一個小區域都有一個向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:03.000" id=12:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=723">12:03.000</a></div>
        <div class="t">接下來你就可以計算出Attention,然後告訴Machine說,現在右下角這個位置是特別需要關注的,右下角這個位置它的Attention Weight是比較大的,那你再根據這個Attention的Weight去做Weighted Sum。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:18.000" id=12:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=738">12:18.000</a></div>
        <div class="t">把這個Attention的Weight拿來跟正面的Vector做Weighted Sum,那就抽出一個向量出來,再把這個向量跟Q相加,然後通過Answer的Prediction Model就會得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:30.000" id=12:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=750">12:30.000</a></div>
        <div class="t">那VQA通常也是被當作是一個分類的問題,所以Machine就直接Output一個詞彙,Output一個詞彙作為正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:38.000" id=12:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=758">12:38.000</a></div>
        <div class="t">比如說這邊要Output的詞彙就是No,輸出No就是正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:43.000" id=12:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=763">12:43.000</a></div>
        <div class="t">那這個部分有一堆的向量,要怎麼做Query to Context的Attention呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:50.000" id=12:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=770">12:50.000</a></div>
        <div class="t">那在這篇CVPR16的Paper裡面,它用的做法就是我剛才講的Query to Context的Attention V2,也就是說這邊有一堆的Vector,你的問題是被表示成一堆的Vector,總共有大T一個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:06.000" id=13:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=786">13:06.000</a></div>
        <div class="t">那怎麼辦?就把大T一個Vector,每一個Vector都去計算Attention的Weight,所以我們得到大T組Attention的Weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:16.000" id=13:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=796">13:16.000</a></div>
        <div class="t">但是有大T組Attention的Weight,我們應該要用哪一組才好呢?那就取Max,把這大T一個Matrix,它們同一個位置的Element都取Max出來,就得到最終的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:34.000" id=13:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=814">13:34.000</a></div>
        <div class="t">所以你可以想像說,如果用這個做法,今天輸入的問題是Is there a cat in the basket? 所以裡面可能Cat是一個關鍵的詞彙,Basket是一個關鍵的詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:46.000" id=13:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=826">13:46.000</a></div>
        <div class="t">當你輸入Cat的時候,應該這邊會有比較大的Attention Weight,當你輸入Basket的時候,籃子的地方會有Attention Weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:55.000" id=13:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=835">13:55.000</a></div>
        <div class="t">那如果你做這個Max的Operation,那應該就是Cat的地方跟籃子的地方都會被Attent到。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:05.000" id=14:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=845">14:05.000</a></div>
        <div class="t">所以今天機器會知道貓在哪一個位置,也會知道籃子在哪一個位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:11.000" id=14:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=851">14:11.000</a></div>
        <div class="t">這是另外一種Query to Context的Attention的變形。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:16.000" id=14:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=856">14:16.000</a></div>
        <div class="t">那還可以反過來做,我們剛才是用Query to Context,也就是對我們的Knowledge Source去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:28.000" id=14:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=868">14:28.000</a></div>
        <div class="t">那反過來也可以用Context去對Query做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:34.000" id=14:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=874">14:34.000</a></div>
        <div class="t">同學們有問題就可以隨時提出來,我們現在繼續講怎麼拿Context對Query做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:47.000" id=14:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=887">14:47.000</a></div>
        <div class="t">那這個Context裡面,每一個Token都會用一個Embedding來表示,然後我們用這個Embedding來對Question裡面的每一個Embedding做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:00.000" id=15:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=900">15:00.000</a></div>
        <div class="t">所以剛才我們是拿Question的Embedding去對Context,也就是我們的Knowledge Source裡面的每一個Embedding做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:10.000" id=15:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=910">15:10.000</a></div>
        <div class="t">那現在反過來,拿Source裡面的每一個Embedding去對Question裡面的每一個Embedding做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:17.000" id=15:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=917">15:17.000</a></div>
        <div class="t">一樣得到一組Attention的Weight,那一樣會對Attention的Weight做Weighted sum,得到一個黃色的Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:25.000" id=15:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=925">15:25.000</a></div>
        <div class="t">那接下來呢,你再把這個黃色的Vector跟這個Embedding拿來做Attention的這個Embedding,做某一種程度的Integration,做某一種程度的結合。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:39.000" id=15:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=939">15:39.000</a></div>
        <div class="t">那要怎麼結合呢?這個文獻上就有各式各樣的花式做法,比較簡單的就是把它們相加。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:48.000" id=15:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=948">15:48.000</a></div>
        <div class="t">可是為什麼要相加呢?你可以用很多其他的方法,你可以做Element wise的相乘,你可以把它直接接起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:58.000" id=15:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=958">15:58.000</a></div>
        <div class="t">你可以把剛才上述所有的方法通通都用上,然後拼成一個很巨大的Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:03.000" id=16:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=963">16:03.000</a></div>
        <div class="t">你可以用各式各樣的方法,把從Query這邊得到的資訊跟從Source這邊得到的資訊,把它Integrate起來,把它結合起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:13.000" id=16:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=973">16:13.000</a></div>
        <div class="t">那這個要如何結合,這塊位置要如何結合,有千千百百種的做法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:19.000" id=16:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=979">16:19.000</a></div>
        <div class="t">那我們就經過結合以後呢,我們就把這個藍色的向量變成這個綠色的向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:27.000" id=16:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=987">16:27.000</a></div>
        <div class="t">那這個綠色的向量裡面是有來自Question的資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:32.000" id=16:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=992">16:32.000</a></div>
        <div class="t">那這邊每一個藍色的Vector都會對Question去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:39.000" id=16:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=999">16:39.000</a></div>
        <div class="t">不過因為這邊每一個藍色的Vector都不一樣,所以這邊算出來的Attention weight都不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:46.000" id=16:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1006">16:46.000</a></div>
        <div class="t">每一個藍色的Vector都不一樣,雖然Question的這一排Vector是一樣的,但是因為這邊Source的每一個Vector都不一樣,所以這邊每一個Vector都會得到不同的Attention weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:58.000" id=16:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1018">16:58.000</a></div>
        <div class="t">那所以你做Weighted Sign後結果也不一樣,然後你把藍色的Vector跟這個黃色的Vector做Integration以後的結果也會不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:07.000" id=17:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1027">17:07.000</a></div>
        <div class="t">總之做Context to Query的Attention就是把Query的資訊加到這些Embedding裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:14.000" id=17:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1034">17:14.000</a></div>
        <div class="t">那每一個Query每一個這邊的Embedding會被加什麼東西都是不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:20.000" id=17:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1040">17:20.000</a></div>
        <div class="t">這邊每一個Embedding從Question這邊取出來的資訊都是不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:25.000" id=17:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1045">17:25.000</a></div>
        <div class="t">這一排Embedding加上Question的資訊以後就變成綠色的這一排Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:32.000" id=17:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1052">17:32.000</a></div>
        <div class="t">然後接下來你再把綠色的這一排Embedding丟到Answer的Module,看Answer的Module要怎麼把答案找出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:40.000" id=17:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1060">17:40.000</a></div>
        <div class="t">那這個就是Context to Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:44.000" id=17:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1064">17:44.000</a></div>
        <div class="t">那像在Square這種Compose上Context to Query的Attention是在有Birds之前蠻主流的一種解法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:54.000" id=17:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1074">17:54.000</a></div>
        <div class="t">那以下就舉幾個經典的Network給大家看。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:58.000" id=17:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1078">17:58.000</a></div>
        <div class="t">那這些經典的Network我們就不會詳細解釋它的架構,因為一個一個解釋就非常的流水帳,你一定不會覺得特別有趣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:06.000" id=18:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1086">18:06.000</a></div>
        <div class="t">那我們就是提一下這些經典的架構,提一下它的名字,讓你知道說過去在有Birds之前還有這些Model曾經存在過。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:18.000" id=18:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1098">18:18.000</a></div>
        <div class="t">我們今天就是把它的化石拿出來給大家看一下。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:22.000" id=18:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1102">18:22.000</a></div>
        <div class="t">有一個東西叫做RNet,RNet它就做了剛才我們有看到的Context to Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:31.000" id=18:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1111">18:31.000</a></div>
        <div class="t">它的Query放在左邊,它的Context放在右邊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:36.000" id=18:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1116">18:36.000</a></div>
        <div class="t">它有用Word Embedding,也有用Character Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:41.000" id=18:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1121">18:41.000</a></div>
        <div class="t">那現在每一個Word都會變成一個Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:46.000" id=18:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1126">18:46.000</a></div>
        <div class="t">接下來每一個這個Passage,也就是每一個這個Knowledge Source裡面的Embedding,都會拿去對Question做Attention,抽出一些資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:02.000" id=19:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1142">19:02.000</a></div>
        <div class="t">那在RNet裡面呢,我們就把來自Question的資訊跟來自Passage、來自Knowledge Source的資訊把它Concatenate起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:12.000" id=19:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1152">19:12.000</a></div>
        <div class="t">那接下來呢,它做了另外一件事情,這件事情它叫做Self-Matching。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:19.000" id=19:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1159">19:19.000</a></div>
        <div class="t">Self-Matching做的事情是什麼呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:21.000" id=19:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1161">19:21.000</a></div>
        <div class="t">Self-Matching是說,我們在這個Knowledge Source裡面的每一個Vector,兩兩間,互相都要做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:29.000" id=19:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1169">19:29.000</a></div>
        <div class="t">每一個Vector都去跟其他人做Attention,抽出一些資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:33.000" id=19:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1173">19:33.000</a></div>
        <div class="t">每一個Vector都跟其他人做Attention,抽出一些資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:36.000" id=19:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1176">19:36.000</a></div>
        <div class="t">每一個Vector都跟其他人做Attention,抽出一些資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:40.000" id=19:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1180">19:40.000</a></div>
        <div class="t">為什麼要這麼做呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:42.000" id=19:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1182">19:42.000</a></div>
        <div class="t">當年RNet的說法就是,因為一篇文章太長了,這邊輸入是一篇完整的文章,太長了,也許Machine會不知道整篇文章的內容。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:53.000" id=19:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1193">19:53.000</a></div>
        <div class="t">所以怎麼辦?我們把每一個Token都對其他人去做Attention,讓文章在,讓這個Model在Process每一個Token的時候,它都了解整篇文章的資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:04.000" id=20:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1204">20:04.000</a></div>
        <div class="t">那個時候RNet把這招叫做Self-Matching。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:09.000" id=20:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1209">20:09.000</a></div>
        <div class="t">但是你從現在的觀點來看,這個Self-Matching是什麼呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:13.000" id=20:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1213">20:13.000</a></div>
        <div class="t">它就是Self-Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:16.000" id=20:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1216">20:16.000</a></div>
        <div class="t">不過RNet是發表在17年的ACL,那個時候甚至都還沒有Attention is All You Need那篇文章。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:26.000" id=20:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1226">20:26.000</a></div>
        <div class="t">那個時候人們還不知道Self-Attention這個東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:29.000" id=20:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1229">20:29.000</a></div>
        <div class="t">所以RNet裡面雖然有一個跟Self-Attention一樣的機制,但它不到Self-Attention這個詞彙,那個時候叫做Self-Matching。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:38.000" id=20:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1238">20:38.000</a></div>
        <div class="t">有了Self-Matching以後,最終Input的Source每一個Token都有一個向量了,然後你就有一個Answer的Module。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:45.000" id=20:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1245">20:45.000</a></div>
        <div class="t">Answer的Module其實也會看Question這邊的資訊,也會看Question的Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:50.000" id=20:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1250">20:50.000</a></div>
        <div class="t">最終就得到初始的每一個詞彙、每一個Token是Begin的機率跟每一個Token是End的機率,就可以把答案抽出來了,這個叫RNet。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:03.000" id=21:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1263">21:03.000</a></div>
        <div class="t">還有另外一個知名的Network叫做FusionNet。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:08.000" id=21:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1268">21:08.000</a></div>
        <div class="t">這個FusionNet是台大的一位同學去微軟實習的時候做的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:13.000" id=21:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1273">21:13.000</a></div>
        <div class="t">這個FusionNet它是怎麼做的呢?它也有Context Question的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:20.000" id=21:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1280">21:20.000</a></div>
        <div class="t">就Question的Embedding進來,通過很多很多層,有很多層不同Level的Question的Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:27.000" id=21:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1287">21:27.000</a></div>
        <div class="t">Context的部分就會去對Question做Attention,而且Context不會只對一種Question的Embedding做Attention,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:37.000" id=21:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1297">21:37.000</a></div>
        <div class="t">它會對多種不同的Question、不同Level的Embedding都去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:44.000" id=21:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1304">21:44.000</a></div>
        <div class="t">得到很多種不同層級的Attention以後,再把不同層級的Attention的結果通通綜合起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:50.000" id=21:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1310">21:50.000</a></div>
        <div class="t">接下來FusionNet在得到答案之前,還有一個Network架構,它叫做Self-Boosting的Fusion。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:59.000" id=21:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1319">21:59.000</a></div>
        <div class="t">這個所謂Self-Boosting的Fusion是什麼呢?這個Self-Boosting的Fusion就是Self-Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:06.000" id=22:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1326">22:06.000</a></div>
        <div class="t">那個時候還不知道什麼是Self-Attention,還不知道Self-Attention那個詞彙,所以類似的機制有各式各樣的名字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:13.000" id=22:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1333">22:13.000</a></div>
        <div class="t">在FusionNet裡面把這個Self-Attention叫做Self-Boosting的Fusion。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:21.000" id=22:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1341">22:21.000</a></div>
        <div class="t">詳細的內容我們就不細看,大家可以自己再去找文件來看。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:27.000" id=22:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1347">22:27.000</a></div>
        <div class="t">我們剛才講了Query to Context的Attention,也講了Context to Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:35.000" id=22:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1355">22:35.000</a></div>
        <div class="t">那哪一種比較好呢?你其實不需要比哪一種比較好,你不就兩種都用就好了嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:42.000" id=22:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1362">22:42.000</a></div>
        <div class="t">所以有一個Network叫做Bidirectional的Attention Flow,縮寫叫做Bidef,它就是兩種Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:50.000" id=22:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1370">22:50.000</a></div>
        <div class="t">不管是Query to Context,還是Context to Query,兩種Attention通通來用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:57.000" id=22:57.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1377">22:57.000</a></div>
        <div class="t">那我們可以簡單的看一下這個Bidef裡面的圖啦。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:01.000" id=23:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1381">23:01.000</a></div>
        <div class="t">Bidef裡面的圖有這樣子,這邊h1到hT代表的是Context,也就是Knowledge Source。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:08.000" id=23:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1388">23:08.000</a></div>
        <div class="t">這邊u1到uJ代表的是Query。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:12.000" id=23:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1392">23:12.000</a></div>
        <div class="t">那Query如果有多個Vector的時候,它就是這個Query to Context的第二個型態。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:19.000" id=23:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1399">23:19.000</a></div>
        <div class="t">你就把這邊的Query的每一個Vector都去跟Context的每一個Vector計算Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:26.000" id=23:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1406">23:26.000</a></div>
        <div class="t">所以Context裡面的每一個Vector都得到了一排Attention的weight,但到底要哪一個weight呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:33.000" id=23:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1413">23:33.000</a></div>
        <div class="t">選對方,就這樣。Context to Query的Attention,就是說我們把每一個Context的Vector都去跟Query的每一個Vector去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:44.000" id=23:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1424">23:44.000</a></div>
        <div class="t">算Attention後,weighted sum,你就可以把Query的資訊跟Context裡面每一個Embedded資訊把它併在一起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:52.000" id=23:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1432">23:52.000</a></div>
        <div class="t">這是Context to Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:55.000" id=23:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1435">23:55.000</a></div>
        <div class="t">整個Bidef是怎麼運作的呢?這是Bidef的Network架構,這個輸入的地方,每一個詞彙都會抽它的Word Embedding跟它的Character Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:07.000" id=24:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1447">24:07.000</a></div>
        <div class="t">你會把Character Sequence通過一個CNN加Max Boolean得到Character Embedding,再把它們併起來,當作是Model的Input。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:15.000" id=24:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1455">24:15.000</a></div>
        <div class="t">你可以想見說這個是在BERT時代之前的Work,這個給人一種很有歷史感的這種感覺。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:24.000" id=24:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1464">24:24.000</a></div>
        <div class="t">接下來就使用Query to Context和Context to Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:31.000" id=24:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1471">24:31.000</a></div>
        <div class="t">做完這種Attention以後,這個Query to Context的Attention會給你一個Vector,然後把這個Vector丟給LSTM。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:40.000" id=24:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1480">24:40.000</a></div>
        <div class="t">Context to Query的Attention會在Context的每一個Embedding都有一個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:47.000" id=24:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1487">24:47.000</a></div>
        <div class="t">Context的每一個Embedding都有一個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:50.000" id=24:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1490">24:50.000</a></div>
        <div class="t">再把這個結果都丟到LSTM裡面去,LSTM就可以幫我們找出初始的位置跟結束的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:59.000" id=24:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1499">24:59.000</a></div>
        <div class="t">其實在Bidef裡面它還有一個小設計是,先找出初始的位置,再根據初始的位置找出結束的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:09.000" id=25:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1509">25:09.000</a></div>
        <div class="t">這個設計其實也是蠻合理的啦,因為你可以想見說這個初始的位置跟結束的位置,它們可能會出現在非常靠近的區域。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:18.000" id=25:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1518">25:18.000</a></div>
        <div class="t">尤其是在Square裡面,它的Answer通常不會超過五個詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:22.000" id=25:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1522">25:22.000</a></div>
        <div class="t">所以如果你已經identify出初始的位置,那結束的位置就在初始的位置之後的五個詞彙之內。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:30.000" id=25:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1530">25:30.000</a></div>
        <div class="t">所以你會看到蠻多過去的QA Model在設計的時候都是先找出初始的位置,再找出結束的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:39.000" id=25:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1539">25:39.000</a></div>
        <div class="t">這個是Bidef的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:46.000" id=25:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1546">25:46.000</a></div>
        <div class="t">還有一種也同時使用Query-to-Context跟Context-to-Query的做法,叫做Dynamic Co-Attention Network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:58.000" id=25:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1558">25:58.000</a></div>
        <div class="t">Dynamic Co-Attention Network是怎麼運作的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:02.000" id=26:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1562">26:02.000</a></div>
        <div class="t">那我們這邊就很快的帶大家看過這個圖,那如果你沒有聽得很懂,或看這個圖覺得密密麻麻的,好多線在搞什麼,也沒有關係。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:12.000" id=26:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1572">26:12.000</a></div>
        <div class="t">我只是想要告訴你說Query-to-Context、Context-to-Query除了Bidef以外,其實還是有不同的用法的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:19.000" id=26:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1579">26:19.000</a></div>
        <div class="t">那我們來看一下這個是怎麼用的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:22.000" id=26:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1582">26:22.000</a></div>
        <div class="t">Query這邊是用三個向量來表示,文章這邊也就是Context也就是Dolly Source,它是用五個向量來表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:30.000" id=26:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1590">26:30.000</a></div>
        <div class="t">那Query的三個向量就會去對Document的五個向量去做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:38.000" id=26:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1598">26:38.000</a></div>
        <div class="t">然後你就會得到一個新的Query,就Query這邊的每一個Vector都去跟Document做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:45.000" id=26:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1605">26:45.000</a></div>
        <div class="t">所以Query這邊的每一個Vector都會得到一組Attention的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:50.000" id=26:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1610">26:50.000</a></div>
        <div class="t">Query這邊的每一個Vector都會從Document這邊做Weighted sum,抽出一個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:58.000" id=26:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1618">26:58.000</a></div>
        <div class="t">Query有三個Vector表示,那用Attention就抽出三個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:03.000" id=27:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1623">27:03.000</a></div>
        <div class="t">這邊等於就是先做Query-to-Document的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:08.000" id=27:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1628">27:08.000</a></div>
        <div class="t">那這邊的這個Query-to-Document的Attention的方法,跟我們剛才講的兩種Query-to-Document的Attention的方法都不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:15.000" id=27:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1635">27:15.000</a></div>
        <div class="t">這等於是第三種Attention的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:18.000" id=27:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1638">27:18.000</a></div>
        <div class="t">那接下來呢,它先做完Query-to-Document的Attention,再做Document-to-Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:26.000" id=27:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1646">27:26.000</a></div>
        <div class="t">所以這邊就有一個Document-to-Query-Attention的步驟。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:30.000" id=27:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1650">27:30.000</a></div>
        <div class="t">就是說,我們把這邊的這五個Vector,分別去對這三個Vector做Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:38.000" id=27:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1658">27:38.000</a></div>
        <div class="t">所以這邊這五個Vector,從這三個Vector去做Weighted sum,又得到另外五個Vector。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:45.000" id=27:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1665">27:45.000</a></div>
        <div class="t">然後呢,再把這個資訊跟舊的資訊呢,把它拼起來,然後呢,得到新的Document的Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:54.000" id=27:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1674">27:54.000</a></div>
        <div class="t">所以Document有五個Token,這邊就有五個Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:58.000" id=27:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1678">27:58.000</a></div>
        <div class="t">然後再用Attention的Module,這邊是Bidirectional的LSTM,去找出最終的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:04.000" id=28:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1684">28:04.000</a></div>
        <div class="t">好,那這個部分如果你聽得沒有很懂也沒有關係,你只需要知道說,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:08.000" id=28:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1688">28:08.000</a></div>
        <div class="t">這個Context-to-Query、Query-to-Context的這種Attention呢,用起來其實是有各式各樣的變化的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:15.000" id=28:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1695">28:15.000</a></div>
        <div class="t">好,接下來呢,有一個東西叫做QnA。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:21.000" id=28:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1701">28:21.000</a></div>
        <div class="t">那QnA跟剛才講的Network其實沒有太大的差異。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:25.000" id=28:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1705">28:25.000</a></div>
        <div class="t">一樣是把文章讀進來,一樣是把問題讀進來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:29.000" id=28:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1709">28:29.000</a></div>
        <div class="t">文章跟問題呢,都會稍微先各自做一下Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:33.000" id=28:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1713">28:33.000</a></div>
        <div class="t">然後接下來呢,再做Context-to-Question的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:38.000" id=28:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1718">28:38.000</a></div>
        <div class="t">它這邊沒有放to,為什麼?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:40.000" id=28:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1720">28:40.000</a></div>
        <div class="t">因為這邊也是Context-to-Query跟Query-to-Context兩個方向都有使用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:47.000" id=28:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1727">28:47.000</a></div>
        <div class="t">這邊也是兩個方向的Attention都有使用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:51.000" id=28:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1731">28:51.000</a></div>
        <div class="t">好,那使用完兩個方向的Attention以後呢,接下來再通過幾層Network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:55.000" id=28:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1735">28:55.000</a></div>
        <div class="t">這邊的這個Answer的Module呢,是比較複雜的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:58.000" id=28:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1738">28:58.000</a></div>
        <div class="t">有很多層的Network,再找出Start的每一個Token,它的Start的機率跟End的機率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:05.000" id=29:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1745">29:05.000</a></div>
        <div class="t">QnA它一個跟過去的Model都不一樣的地方是,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:10.000" id=29:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1750">29:10.000</a></div>
        <div class="t">它已經進入了18年,那個時候已經知道了Self-Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:17.000" id=29:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1757">29:17.000</a></div>
        <div class="t">所以QnA是沒有RNN的,它裡面就是憑藉著Self-Attention來考慮整篇文章或整個問題的資訊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:29.000" id=29:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1769">29:29.000</a></div>
        <div class="t">而QnA呢,我認為它應該是BERT家族之外的最後一道榮光。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:37.000" id=29:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1777">29:37.000</a></div>
        <div class="t">QnA它在SQUAD上得到了很好的結果,接下來有了BERT以後,就再也沒有人提過去的Model了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:46.000" id=29:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1786">29:46.000</a></div>
        <div class="t">所以QnA是最後一個沒有使用BERT的知名的Model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:51.000" id=29:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1791">29:51.000</a></div>
        <div class="t">那個時候BERT一出來以後,如果你手上的研究還沒有投國際會議,就直接就放棄吧。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:58.000" id=29:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1798">29:58.000</a></div>
        <div class="t">你不用做了,只要不是BERT的work,投稿都不會上了,都不必再做了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:04.000" id=30:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1804">30:04.000</a></div>
        <div class="t">所以QnA是BERT家族之外的最後一道榮光,接下來就進入大家都熟悉的BERT的時代。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:13.000" id=30:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1813">30:13.000</a></div>
        <div class="t">BERT怎麼解QA的問題呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:16.000" id=30:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1816">30:16.000</a></div>
        <div class="t">你就把Knowledge Source跟Question中間放一個Special的Token,代表它們的分隔。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:23.000" id=30:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1823">30:23.000</a></div>
        <div class="t">然後把Knowledge Source跟Question都一股腦的丟到BERT裡面去。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:28.000" id=30:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1828">30:28.000</a></div>
        <div class="t">然後Knowledge Source會得到一排Embedding,Question也會得到一排Embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:32.000" id=30:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1832">30:32.000</a></div>
        <div class="t">接下來你的Answer Module會在這些Knowledge Source的Embedding裡面找出Start跟End的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:40.000" id=30:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1840">30:40.000</a></div>
        <div class="t">如果你今天是做這種Square的這種類型的問題的話,那你的Answer Module裡面就有Start跟End,然後可以找出Answer的Time span在哪裡。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:52.000" id=30:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1852">30:52.000</a></div>
        <div class="t">那為什麼BERT的Performance會好呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:55.000" id=30:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1855">30:55.000</a></div>
        <div class="t">前面之所以要鋪成這麼長,講了那麼多的歷史的遺跡,拿了那麼多化石出來給大家看,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:01.000" id=31:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1861">31:01.000</a></div>
        <div class="t">就是為了要顯示告訴大家說為什麼BERT今天會好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:06.000" id=31:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1866">31:06.000</a></div>
        <div class="t">你想想看,在BERT裡面有非常大量的Self-Attention的Layer。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:12.000" id=31:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1872">31:12.000</a></div>
        <div class="t">這些Self-Attention的Layer,它可以做到Context-to-Query的Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:18.000" id=31:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1878">31:18.000</a></div>
        <div class="t">我們在做Self-Attention的時候,把這些Context的內容會去Add這些Question的內容。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:24.000" id=31:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1884">31:24.000</a></div>
        <div class="t">你也做了Query-to-Context的Attention,因為這些Question裡面的內容,你也會去Attend這個Context裡面的內容。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:34.000" id=31:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1894">31:34.000</a></div>
        <div class="t">而你也做了過去很多Paper有做的Self-Matching跟Self-Boosting這樣子的東西,那過去不知道什麼叫做Self-Attention,所以叫Self-Matching或Self-Boosting,其實就是Self-Attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:46.000" id=31:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1906">31:46.000</a></div>
        <div class="t">在BERT裡面,當然有一大堆,BERT裡面做了好多好多次的Self-Matching或者是Self-Boosting。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:54.000" id=31:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1914">31:54.000</a></div>
        <div class="t">所以你會發現說,過去Model裡面的東西,過去這些各式各樣的Module,可能不是無死線在一個Model裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:05.000" id=32:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1925">32:05.000</a></div>
        <div class="t">但是在BERT裡面,這些你可以想像到的Attention,通通都有。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:12.000" id=32:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1932">32:12.000</a></div>
        <div class="t">所以我們拿過去的這些化石出來給大家看,就是要讓大家了解說,QA的這個問題一路走來,是怎麼演化到今天BERT的這個樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:24.000" id=32:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1944">32:24.000</a></div>
        <div class="t">而你從BERT再去看過去的Model,你就會發現說BERT裡面,有著過去Model裡面都有的這些東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:33.000" id=32:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1953">32:33.000</a></div>
        <div class="t">BERT是一個全新的Model,但是它裡面的機制,它是過去QA Model所流淌的血脈。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:41.000" id=32:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1961">32:41.000</a></div>
        <div class="t">而它結合了過去所有QA Model有的機制,所以難怪它可以得到最好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:53.000" id=32:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1973">32:53.000</a></div>
        <div class="t">今天這種Simple Question已經不能滿足人類的需求。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:58.000" id=32:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1978">32:58.000</a></div>
        <div class="t">我們期待機器可以解更複雜的問題,也就是期待機器可以做到推論。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:07.000" id=33:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1987">33:07.000</a></div>
        <div class="t">簡單來說,所謂的更複雜的問題,就是你沒辦法直接用Match and Extract來解的那些問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:14.000" id=33:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=1994">33:14.000</a></div>
        <div class="t">那有幾個知名的Corpus,我們先來講有哪些Corpus裡面有這種比較複雜的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:21.000" id=33:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2001">33:21.000</a></div>
        <div class="t">一個例子叫做Crangeroo,那Crangeroo這個Corpus是這樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:26.000" id=33:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2006">33:26.000</a></div>
        <div class="t">你有好幾段文章,然後有一個問題是問你,舉例來說,在孟買的Heming Garden,它是在哪一個國家?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:40.000" id=33:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2020">33:40.000</a></div>
        <div class="t">孟買不是國家,所以你不能回答孟買,這是錯誤的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:46.000" id=33:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2026">33:46.000</a></div>
        <div class="t">你要回答說,孟買的這個花園到底在哪一個國家呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:52.000" id=33:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2032">33:52.000</a></div>
        <div class="t">如果你今天是用Extract and Match的方法,你沒有辦法找到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:58.000" id=33:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2038">33:58.000</a></div>
        <div class="t">因為在這些文章裡面,在你的Knowledge Source裡面,沒有任何一個Source,它直接告訴你說,這個花園到底在哪一個國家裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:08.000" id=34:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2048">34:08.000</a></div>
        <div class="t">我特別Google了這個Heming Garden的樣子,它大概長這個樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:13.000" id=34:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2053">34:13.000</a></div>
        <div class="t">據說它的特色就是,裡面有很多很有藝術感的植物,它把植物修剪得很有藝術感。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:23.000" id=34:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2063">34:23.000</a></div>
        <div class="t">像這個東西到底是什麼呢?我其實也看不出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:27.000" id=34:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2067">34:27.000</a></div>
        <div class="t">不知道這是一個人嗎?他拿著吉他嗎?還是這是一隻鯨魚嗎?還是這是一個蜻蜓,停在一個彎曲的枝幹上嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:38.000" id=34:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2078">34:38.000</a></div>
        <div class="t">不知道,反正據說裡面就是有很多這樣子的造景。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:44.000" id=34:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2084">34:44.000</a></div>
        <div class="t">那要怎麼解這種問題呢?機器必須要先知道說,這個花園它在孟買。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:54.000" id=34:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2094">34:54.000</a></div>
        <div class="t">機器先讀這篇文章,知道花園在孟買。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:57.000" id=34:57.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2097">34:57.000</a></div>
        <div class="t">接下來,它要再去讀另外一篇跟孟買有關的文章,知道說孟買其實是在印度裡面,然後期待它可以選出正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:07.000" id=35:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2107">35:07.000</a></div>
        <div class="t">那其實Kunguru這個Corpus它是選擇題,所以除了印度這個選項以外,它會故意出一些其他的國家作為選項來誤導。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:17.000" id=35:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2117">35:17.000</a></div>
        <div class="t">舉例來說,在這篇有提到這個花園的文章裡面,又提到了阿拉伯海。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:23.000" id=35:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2123">35:23.000</a></div>
        <div class="t">另外一篇文章有提到阿拉伯海附近有哪些國家呢?有巴基斯坦、伊朗、索馬利亞等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:31.000" id=35:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2131">35:31.000</a></div>
        <div class="t">它就把這些國家的名字也放到問題裡面,希望可以誤導機器的判斷。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:37.000" id=35:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2137">35:37.000</a></div>
        <div class="t">那Kunguru這個Corpus比較讓人詬病的地方是,它的問題不是真正的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:43.000" id=35:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2143">35:43.000</a></div>
        <div class="t">它的問題其實是把Knowledge Base,其中一個Knowledge Base就是由一個Triple所組成的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:52.000" id=35:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2152">35:52.000</a></div>
        <div class="t">就假設你有一個Knowledge Base,它就會告訴你說,這個花園它在哪個國家呢?它在印度。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:59.000" id=35:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2159">35:59.000</a></div>
        <div class="t">它會把這個Knowledge Base裡面的其中一塊拿掉,用一個問號置換掉,然後要求你把問號的部分填上去。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:07.000" id=36:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2167">36:07.000</a></div>
        <div class="t">那這個Corpus為什麼叫做Kunguru呢?它是來自於袋鼠的Kunguru。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:14.000" id=36:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2174">36:14.000</a></div>
        <div class="t">為什麼跟袋鼠有什麼關係呢?因為你今天要回答這篇文章的問題的時候,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:20.000" id=36:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2180">36:20.000</a></div>
        <div class="t">你要回答這個問題的時候,你必須要在不同的文章間跳來跳去來擷取資訊,才能夠回答問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:28.000" id=36:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2188">36:28.000</a></div>
        <div class="t">所以這個Corpus叫做Kunguru。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:32.000" id=36:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2192">36:32.000</a></div>
        <div class="t">那還有另外一個Corpus叫做Hapa QA。Hapa QA的問題就是真正的問題了,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:40.000" id=36:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2200">36:40.000</a></div>
        <div class="t">就不是從Knowledge Base裡面擷一個Knowledge出來當作問題,它是真正的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:47.000" id=36:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2207">36:47.000</a></div>
        <div class="t">那像在Hapa QA裡面,它就會考你一些,比如說它說2015年的MVP是在哪一個球隊裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:01.000" id=37:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2221">37:01.000</a></div>
        <div class="t">所以你就要先找出2015年的MVP是誰,是一個叫做Booty Hill的人。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:07.000" id=37:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2227">37:07.000</a></div>
        <div class="t">那Booty Hill是哪一個球隊的人呢?它是這個球隊的人,那你就可以得到正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:14.000" id=37:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2234">37:14.000</a></div>
        <div class="t">但是你沒有辦法只看一段文字就得到正確答案,你沒辦法直接做Extract and Match,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:21.000" id=37:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2241">37:21.000</a></div>
        <div class="t">你必須要看多篇的文章和多段的文字,把不同的資訊從多段不同的文字裡面綜合起來,你才能夠得到正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:31.000" id=37:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2251">37:31.000</a></div>
        <div class="t">那Hapa QA裡面有一些特難的問題,舉例來說,像這個問題,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:37.000" id=37:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2257">37:37.000</a></div>
        <div class="t">它問你說Loss Alone跟Gaster這兩個樂團,他們的成員數目是不是一樣多的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:46.000" id=37:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2266">37:46.000</a></div>
        <div class="t">有一段文字提到Loss Alone這個樂團,有一段文字提到Gaster這個樂團,那它也有分別告訴你說這兩個樂團裡面有多少的成員。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:58.000" id=37:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2278">37:58.000</a></div>
        <div class="t">但是Machine必須要自己知道說,從這段文字裡面計算出Loss Alone成員的數目,再從這段文字裡面計算出Gaster成員的數目,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:06.000" id=38:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2286">38:06.000</a></div>
        <div class="t">然後最後經過比對後得到正確答案說這兩個樂團是有一樣多成員的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:12.000" id=38:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2292">38:12.000</a></div>
        <div class="t">所以Hapa QA裡面有很多頗為困難的問題,是遠超過過去Simple Questions可以回答的範圍。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:21.000" id=38:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2301">38:21.000</a></div>
        <div class="t">那為什麼Hapa QA叫做Hapa QA呢?有兩個原因,一個次要的原因是說,據說是這群作者在吃火鍋的時候想到要做這個Compass的計劃,所以叫做Hapa QA。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:34.000" id=38:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2314">38:34.000</a></div>
        <div class="t">然後另外一個比較主要的原因是因為,今天你要回答這些問題的時候,你必須要把多個不同的段落裡面的資訊抽取出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:44.000" id=38:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2324">38:44.000</a></div>
        <div class="t">比方我們煮火鍋的時候,要把各種不同的素材丟到同一個鍋子裡面才能煮一鍋好的火鍋。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:50.000" id=38:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2330">38:50.000</a></div>
        <div class="t">那Hapa QA是一樣,你需要從文章的各個不同的段落裡面擷取資訊出來,才能夠得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:00.000" id=39:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2340">39:00.000</a></div>
        <div class="t">那在Hapa QA之後,還有一個Compass叫做Drop。Drop它是Discrete Reasoning over the Text in the Paragraph的縮寫。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:12.000" id=39:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2352">39:12.000</a></div>
        <div class="t">什麼叫做Discrete Reasoning呢?其實這邊它所謂的Discrete Reasoning就是要機器算數學的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:21.000" id=39:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2361">39:21.000</a></div>
        <div class="t">所以Drop裡面很多的問題都像是數學的應用題。舉例來說,這邊有一篇文章說,有一個叫做無題的圖畫,它以16.3 million的天價賣出去了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:38.000" id=39:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2378">39:38.000</a></div>
        <div class="t">其實你可以自己去Google一下這幅圖長什麼樣子。那比本來大家所估計的12個million還要高。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:46.000" id=39:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2386">39:46.000</a></div>
        <div class="t">問題就是,今天這個無題的圖畫,它的售價比當初估測的12個million還要高出多少?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:58.000" id=39:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2398">39:58.000</a></div>
        <div class="t">答案是16.3-12是4.3個million。這個答案沒有出現在文章裡的任何地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:07.000" id=40:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2407">40:07.000</a></div>
        <div class="t">機器要解一個數學的問題,它把16.3抽出來,把12抽出來,然後製造16.3-12得到4.3個million才能得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:19.000" id=40:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2419">40:19.000</a></div>
        <div class="t">或是我們舉另外一個例子,你機器必須要學會做一些加法。舉例來說,這邊有一個問題是,JNA這個組織成立了一個戰鬥團。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:30.000" id=40:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2430">40:30.000</a></div>
        <div class="t">它們什麼時候成立戰鬥團呢?如果你只看這篇文章,你沒有細看的話,你會發現文章裡面只提到一個日期,是1992年的3月2日。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:40.000" id=40:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2440">40:40.000</a></div>
        <div class="t">它是正確答案嗎?它不是正確答案,因為文章裡面說,JNA在某個事件發生後的隔天成立了戰鬥團。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:51.000" id=40:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2451">40:51.000</a></div>
        <div class="t">所以它成立戰鬥團的時間不是3月2日,是3月2日的隔天,是3月3日。所以機器必須要知道,所謂的隔天就是把日期加1,3月2日的隔天就是3月3日。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:06.000" id=41:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2466">41:06.000</a></div>
        <div class="t">或者是這邊還有一個變態的問題,就是要問你說,這邊給你一個文章,然後再問你說,哪一個人踢進最多球?這邊有兩個人,有一個人叫做Matt,有一個人叫做John。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:23.000" id=41:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2483">41:23.000</a></div>
        <div class="t">他問你說Matt跟John,誰踢進比較多球?所以機器要一邊讀這篇文章一邊算說,這邊Matt踢進一球,John踢進一球,這個人也是John,他也有踢進一球。John又再踢進一球,John踢進比較多,所以答案是John。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:38.000" id=41:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2498">41:38.000</a></div>
        <div class="t">Drop它在出題的時候,其實做了一個很變態的事情,它是抱著惡意出題,特別把ByteDef的model拿出來,今天出的問題一定要讓ByteDef答錯才行。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:56.000" id=41:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2516">41:56.000</a></div>
        <div class="t">所以如果你拿ByteDef的model去做Drop,你得到的正確率會是0,因為Drop它出題的時候,就是要出那些ByteDef沒辦法答對的題目。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:08.000" id=42:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2528">42:08.000</a></div>
        <div class="t">所以如果是ByteDef,我剛剛講過ByteDef,它就是有做兩個方向,context-to-query,query-to-context的attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:14.000" id=42:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2534">42:14.000</a></div>
        <div class="t">如果你堅持用ByteDef去做的話,都會慘掉,ByteDef只會從文章裡面抽一段出來,ByteDef看到這個問題,它就抽個數字出來說16.3 million,是錯的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:25.000" id=42:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2545">42:25.000</a></div>
        <div class="t">或者這邊ByteDef就抽個日期出來,是錯的。這邊ByteDef隨便弄個人名出來,是錯的。Drop出題的時候,會故意出這種ByteDef,會答錯。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:39.000" id=42:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2559">42:39.000</a></div>
        <div class="t">那怎麼解這種需要reasoning的問題呢?其實像這種需要reasoning的問題,過去也是有的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:47.000" id=42:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2567">42:47.000</a></div>
        <div class="t">其實早在Baby的那個時候,就已經有這種需要reasoning的問題了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:59.000" id=42:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2579">42:59.000</a></div>
        <div class="t">舉例來說,在Baby的問題裡面,有一類的問題長得像是這個樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:04.000" id=43:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2584">43:04.000</a></div>
        <div class="t">這篇文章裡面有提到說,Brian是個青蛙,Lily是灰色的,Brian是黃色的,然後Julius是綠色的,然後Greg是個青蛙,然後問你Greg是什麼顏色。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:16.000" id=43:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2596">43:16.000</a></div>
        <div class="t">那如果今天只是一個只會match and extract the model的話,他可能會說,What color is Greg? Greg是個關鍵的詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:26.000" id=43:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2606">43:26.000</a></div>
        <div class="t">文章裡面哪裡有提到Greg呢?只有第五句話有提到Greg。所以在算attention的時候,第五個句子得到的attention位特別高。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:35.000" id=43:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2615">43:35.000</a></div>
        <div class="t">如果你要從第五個句子裡面抽資訊出來,你可能就抽出跟frog有關的資訊。但答案不是frog,當你問What color is Greg的時候,答案是frog,顯然是不對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:48.000" id=43:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2628">43:48.000</a></div>
        <div class="t">所以怎麼辦呢?為了要解這種問題,就有了multiple hop這樣的想法。也就是說,我們抽出frog以後,先不急著給答案,把這個frog拿去改變我們要match的目標。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:05.000" id=44:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2645">44:05.000</a></div>
        <div class="t">也就是說,我們現在改成要去match有出現frog的句子。那哪一個句子有出現frog呢?第一個句子Brian is a frog有出現frog。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:18.000" id=44:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2658">44:18.000</a></div>
        <div class="t">所以在第二次做matching的時候,因為現在是要找有出現frog的句子,所以第一個句子的attention位特別大,其他句子的attention位就小很多了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:27.000" id=44:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2667">44:27.000</a></div>
        <div class="t">那從第一個句子Brian is a frog裡面,你會抽出資訊Brian。再根據抽出來的資訊,再改變我們match的目標,接下來要match有Brian的句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:39.000" id=44:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2679">44:39.000</a></div>
        <div class="t">所以在第三次做attention的時候,有Brian的句子得到的attention位特別大,接下來你就抽出資訊是yellow,也許這就是正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:51.000" id=44:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2691">44:51.000</a></div>
        <div class="t">過去一般在做multiple half的時候要half幾次,要改變幾次match的對象,往往是人定的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:01.000" id=45:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2701">45:01.000</a></div>
        <div class="t">今天在之前的baby裡面通常就是做三次half,也就是改兩次match的對象。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:10.000" id=45:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2710">45:10.000</a></div>
        <div class="t">那怎麼做到剛才講的multiple half呢?Memory Network裡面就有做multiple half這件事,Memory Network是這樣做的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:20.000" id=45:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2720">45:20.000</a></div>
        <div class="t">你今天會給一篇文章,這文章裡面的每一個句子都會變成一個embedding。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:27.000" id=45:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2727">45:27.000</a></div>
        <div class="t">那通常會產生兩種embedding,一種embedding拿來做match,一種embedding拿來做extract。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:33.000" id=45:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2733">45:33.000</a></div>
        <div class="t">那question進來的時候,先做match,再做extract,把extract出來的資訊跟原來的問題做相加。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:43.000" id=45:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2743">45:43.000</a></div>
        <div class="t">這個相加目的是什麼呢?這個相加等於改變了我們要match的對象。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:50.000" id=45:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2750">45:50.000</a></div>
        <div class="t">本來只會match跟question有關的部分,現在這個question被改變了,你有了一個新的question,你就會match不一樣的資訊,extract不一樣的內容。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:01.000" id=46:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2761">46:01.000</a></div>
        <div class="t">那到底應該要做幾次的half才對呢?過去half這件事情通常就是當作一個hyperparameter,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:09.000" id=46:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2769">46:09.000</a></div>
        <div class="t">它就像是network的層數一樣,像network要有幾層,這個是人定的嘛,所以half的數目也是人定的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:18.000" id=46:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2778">46:18.000</a></div>
        <div class="t">但是有一個network叫做resonate,它試圖讓machine自己決定half的數目。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:26.000" id=46:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2786">46:26.000</a></div>
        <div class="t">那resonate它在做的事情呢,它在training的時候有點像是RL,那它的model呢,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:32.000" id=46:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2792">46:32.000</a></div>
        <div class="t">在每次half完都要make一個decision,都要決定說現在要停止輸出答案,還是要繼續half下去找出新的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:43.000" id=46:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2803">46:43.000</a></div>
        <div class="t">那細節我們就不講,就告訴大家說有一個東西叫做resonate,它試圖讓machine自己決定要half幾次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:51.000" id=46:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2811">46:51.000</a></div>
        <div class="t">那實際上resonate在train的時候是有用到reinforced algorithm的,讓machine可以在每一次要half之前都output一個indicator,決定說現在要half還是不要half。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:04.000" id=47:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2824">47:04.000</a></div>
        <div class="t">那近年來啊,在解這種reasoning的問題,在解這種multiple half的問題,往往會使用graph neural network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:18.000" id=47:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2838">47:18.000</a></div>
        <div class="t">那在這堂課裡面呢,我們就不細講graph neural network的相關的事情啦。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:23.000" id=47:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2843">47:23.000</a></div>
        <div class="t">如果你想知道什麼是graph neural network的話,可以參見這個機器學習那門課呢,江辰和助教的錄影。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:31.000" id=47:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2851">47:31.000</a></div>
        <div class="t">那在這邊graph neural network想要做到的事情,其實跟剛才我們看到的multiple half要做的事情,其實是非常類似的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:41.000" id=47:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2861">47:41.000</a></div>
        <div class="t">只是我們現在在改變我們要match的東西的時候,不需要再透過curve。就之前在memory network那一系列的work裡面,在做multiple half,在改變要match的對象的時候,它透過的方式是去改變原來的question,然後讓你match到不一樣的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:01.000" id=48:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2881">48:01.000</a></div>
        <div class="t">但是在graph neural network這個系列的work裡面,它不會去改變question,它靠的是一個graph。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:08.000" id=48:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2888">48:08.000</a></div>
        <div class="t">怎麼做呢?首先你可能會把你的文章裡面的entity都抽出來,把這些entity建一個graph。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:19.000" id=48:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2899">48:19.000</a></div>
        <div class="t">那怎麼把這些entity建一個graph呢?比較簡單的做法就是,如果這些entity出現在同篇文章裡面,就把它們連起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:28.000" id=48:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2908">48:28.000</a></div>
        <div class="t">或者是說,如果不同文章裡面,knowledge source的不同段落裡面,有提到同樣的entity,就把它們連起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:41.000" id=48:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2921">48:41.000</a></div>
        <div class="t">那如果今天問的問題是一個有關Tom Clancy的人的問題,我根本就沒仔細讀這個問題,就看到關鍵字Tom Clancy,不知道他是誰,管他的,他一個中國人叫做Tom。我們把文章裡面有出現Tom的位置都找出來,他們會有最大的attention weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:00.000" id=49:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2940">49:00.000</a></div>
        <div class="t">第一次做matching的時候,他們的attention weight也是最大的。然後接下來透過這個graph neural network,這些不同的entity,Tom會分享Tom的attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:11.000" id=49:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2951">49:11.000</a></div>
        <div class="t">這個有點像是page rank,這個Tom的attention會分享給跟他有連接的人。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:20.000" id=49:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2960">49:20.000</a></div>
        <div class="t">那可能像Jack,他跟Tom在這邊有連接,然後Jack在另外一個文章裡面跟Tom有連接。所以當Tom這個詞彙在分享他的attention的時候,可能Jack會得到最多的attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:34.000" id=49:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2974">49:34.000</a></div>
        <div class="t">這個有最多attention的entity,他可能就是答案,然後答案就是Jack。這個是graph neural network的基本的想法。那有關細節的部分,大家就自己再去看一下論文。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:50.000" id=49:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=2990">49:50.000</a></div>
        <div class="t">其實有關這個complex question,我今天不會講太多,因為我覺得complex question今天還是一個上代解決的問題。什麼樣的方法是最好的,目前還沒有一個固定的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:03.000" id=50:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3003">50:03.000</a></div>
        <div class="t">舉例來說,graph neural network雖然最近非常的流行,解這種reasoning的問題,往往都會用個graph。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:12.000" id=50:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3012">50:12.000</a></div>
        <div class="t">通常常見的一個typical的network架構可能是這樣子,你用BERT抽出一些embedding,然後接下來根據你的query會建出一個graph。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:23.000" id=50:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3023">50:23.000</a></div>
        <div class="t">在這個graph上面用graph neural network那套方法做一點propagation,然後再得到下一層的內容。接下來還會再重複用這個graph做一些propagation。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:36.000" id=50:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3036">50:36.000</a></div>
        <div class="t">這是ACL19的paper,但是近幾個月就在archive上有一篇paper說,graph好像也沒那麼必要。在這篇文章裡面,他們把graph拿掉,發現拿掉這個graph,得到的performance也差不多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:54.000" id=50:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3054">50:54.000</a></div>
        <div class="t">那為什麼前人會覺得一定要使用graph呢?這篇paper就發現說,如果你今天在用BERT的時候,這些embedding是BERT來的,如果你只把BERT當作feature attractor,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:06.000" id=51:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3066">51:06.000</a></div>
        <div class="t">就是你使用BERT的時候,你在train你的QA model的時候,你沒有fine-tune BERT,那這個graph就是需要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:16.000" id=51:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3076">51:16.000</a></div>
        <div class="t">但是如果你跟著fine-tune BERT,那這個graph就可以拿掉。所以其實BERT裡面的self-attention,它本身可以取代graph的部分功能。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:30.000" id=51:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3090">51:30.000</a></div>
        <div class="t">甚至你可以想像說,self-attention這件事,它本身就是一個graph,它self-attention會把所有這個文章裡面所有的entity通通都連在一起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:43.000" id=51:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3103">51:43.000</a></div>
        <div class="t">它是一個fully connected的graph,這個self-attention會讓所有的entity通通連在一起,得到一個fully connected的graph。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:53.000" id=51:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3113">51:53.000</a></div>
        <div class="t">而這個fully connected graph上面的weight是輕是重,是network自己認出來的。所以也許確實你今天有fine-tune你的BERT model,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:04.000" id=52:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3124">52:04.000</a></div>
        <div class="t">BERT model就可以做到原來這個graph neural network可以做到的功能,它裡面的self-attention layer就可以取代graph neural network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:13.000" id=52:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3133">52:13.000</a></div>
        <div class="t">所以這篇文章才發現說,如果你有fine-tune BERT,不需要這個graph的layer。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:19.000" id=52:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3139">52:19.000</a></div>
        <div class="t">所以你可以想見說,現在這種complex question的reasoning,還有很多上代研究的問題,等到解這種問題,還有很長一段路要走。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:29.000" id=52:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3149">52:29.000</a></div>
        <div class="t">好,建成問了一個問題,他說把graph塞進attention裡面的感覺嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:39.000" id=52:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3159">52:39.000</a></div>
        <div class="t">沒錯,就是如果你有fine-tune你的BERT的話,等於BERT就會做了graph neural network本來想做的事,那就不需要graph neural network那個layer了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#52:49.000" id=52:49.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3169">52:49.000</a></div>
        <div class="t">好,那我們講完這個dialogue QA再下課。第三類的問題叫做dialogue QA。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#53:00.000" id=53:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3180">53:00.000</a></div>
        <div class="t">dialogue QA想要做的事情是,它希望機器不是回答一個問題,而是回答一連串的問題,它要回答一個題組。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#53:11.000" id=53:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3191">53:11.000</a></div>
        <div class="t">dialogue QA有兩個知名的benchmark corpus,先講第一個,叫做口QA。口QA做的事情就是,機器先讀一篇文章,然後你問它一個問題,比如說what are the candidates running for,機器可以得到一個正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#53:29.000" id=53:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3209">53:29.000</a></div>
        <div class="t">接下來第二個問題是where,如果今天沒有第一個問題,只有第二個問題where,你就會摸不著頭腦,where哪裡哪裡哪裡,你到底是要問哪裡。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#53:40.000" id=53:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3220">53:40.000</a></div>
        <div class="t">但是這邊的where指的就是,這些candidates running for,他們是在哪裡做這件事呢?那你的機器要知道前一個問題問的是什麼,它才能夠得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#53:53.000" id=53:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3233">53:53.000</a></div>
        <div class="t">或者是說,這邊有一個問題是who is the democratic candidate,答案是Terry。接下來,第四個問題是who is his opponent,就是誰是他的對手呢?這個他是誰呢?你要看前一題的答案才知道說,原來他指的是Terry。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#54:15.000" id=54:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3255">54:15.000</a></div>
        <div class="t">機器才能知道說,Terry的對手是Ken。接下來人又問說,what party does he belong to?這個he指的是誰呢?這個he指的是Ken。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#54:27.000" id=54:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3267">54:27.000</a></div>
        <div class="t">機器必須要知道說,這個he指的是前一個問題的答案是Ken,所以它前一題必須要正確地回答出Ken這個答案,它才能夠回答第五個問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#54:38.000" id=54:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3278">54:38.000</a></div>
        <div class="t">接下來第二個問題再問,which of them is winning?他們之中誰贏了?這個他們是誰呢?這個他們指的是Terry跟Ken。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#54:47.000" id=54:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3287">54:47.000</a></div>
        <div class="t">機器必須要成功回答第三題跟第四題,才能夠知道說,這邊的他們是Terry跟Ken,然後正確地回答第六個問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#54:56.000" id=54:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3296">54:56.000</a></div>
        <div class="t">在Dialogue Q&A裡面,機器就是要回答一個題組,而每一個問題可能都是承接上一個問題。某一個問題直接拿出來,可能沒有答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#55:08.000" id=55:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3308">55:08.000</a></div>
        <div class="t">比如說你直接問,what party does he belong to?那he指的是誰呢?不知道。但是如果放在這個群題組裡面,根據上下文,我們期待機器可以回答說,he指的就是Ken。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#55:21.000" id=55:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3321">55:21.000</a></div>
        <div class="t">那這個是Dialogue Q&A。那除了Q&A以外,還有另外一個知名的Corpus就叫做Quark。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#55:29.000" id=55:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3329">55:29.000</a></div>
        <div class="t">那這個Quark跟Q&A它一個比較不一樣的地方是,在Q&A裡面問問題的人,他有看到文章。所以問問題的人,他不會問出很荒謬、沒有辦法回答的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#55:43.000" id=55:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3343">55:43.000</a></div>
        <div class="t">但在Quark裡面,它一個特別的地方是,問問題的人,人在出這個問題的時候,出問題的人是沒有看過文章的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#55:53.000" id=55:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3353">55:53.000</a></div>
        <div class="t">所以出問題的人根本不知道文章裡面有什麼樣的內容,所以出問題的人可能會問出文章裡面沒有的內容。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:01.000" id=56:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3361">56:01.000</a></div>
        <div class="t">出問題的人可能會問出一些沒有辦法回答的問題,而機器必須要知道哪些問題是沒有辦法回答的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:10.000" id=56:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3370">56:10.000</a></div>
        <div class="t">那像這種Dialogue Q&A的問題要怎麼解呢?最直覺的解法,通常你可能會把這樣子的解法當作一個很trivial的baseline。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:21.000" id=56:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3381">56:21.000</a></div>
        <div class="t">就是我們把Dialogue Q&A當作一般的Q&A來解。我們有一堆Q&A model,我們有一個Q&A model,我們就把每一個問題都當作是獨立的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:33.000" id=56:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3393">56:33.000</a></div>
        <div class="t">把每一個問題分別丟進Q&A model,得到一堆獨立的答案,再看看你得到什麼樣的結果。但你使用這樣的方法,你不會在Dialogue Q&A上得到太好的結果,它只能夠作為一個baseline。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:46.000" id=56:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3406">56:46.000</a></div>
        <div class="t">那今天一般在解Dialogue Q&A的問題的時候,你可能會採取什麼樣的解法呢?那一個經典的解法可能是這個樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#56:56.000" id=56:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3416">56:56.000</a></div>
        <div class="t">如果你今天把每一個問題都視為是獨立的,那你可能會這麼做,你把Document跟Question接起來丟到Bert裡面,Bert給你D,Bert的D,L個Layer產生一堆Embedding,L加1Layer再產生一大堆Embedding,那Q2也是一樣,Q3也是一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#57:16.000" id=57:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3436">57:16.000</a></div>
        <div class="t">但是怎麼把不同問題間的資訊串聯起來呢?舉例來說,像這篇ICLR219的paper,它就使用一個RNN,說你今天怎麼得到這個Embedding呢?不只要看上一層的Embedding,還要看前一個問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#57:36.000" id=57:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3456">57:36.000</a></div>
        <div class="t">所以今天產生這個Embedding的時候,我們把不同Question的Embedding可能用RNN串起來,那之所以用RNN是因為那個時候Bert還不流行,所以這篇ICLR219的paper是說,我們用RNN把這些Embedding串在一起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#57:53.000" id=57:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3473">57:53.000</a></div>
        <div class="t">所以每一個Embedding產生的時候,不只是考慮了前一層的Embedding,還考慮了前一個問題的Embedding,這是目前Dialogue Q&A一個蠻主流的解法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#58:07.000" id=58:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3487">58:07.000</a></div>
        <div class="t">那這篇用RNN就是因為19年的時候Bert還沒有Everywhere,但今天Self-Attention已經到處都是了,所以像這篇CIKN19的paper就用了Self-Attention的概念。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#58:23.000" id=58:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3503">58:23.000</a></div>
        <div class="t">所以Embedding產生的時候,不只是從上一個Layer抽取資訊,它還從其他問題的同一個位置,用Attention的方法抽取資訊出來,用Attention的方法做Weighted Sum,那這個是Dialogue Q&A今天一個主流的解法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#58:42.000" id=58:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3522">58:42.000</a></div>
        <div class="t">好,今天有了Bert的Model以後,是不是Question Answering的問題就被解決了呢?如果你看那些什麼Squad Leaderboard的話,確實會給你一種Question Answering已經被解決的錯覺。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#58:59.000" id=58:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3539">58:59.000</a></div>
        <div class="t">舉例來說,這個是Squad 2.0的Leaderboard,這是Human的Performance,EN是Exact Match,也就是機器得到的答案如果跟正確的答案一模一樣,才能夠得到一分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#59:14.000" id=59:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3554">59:14.000</a></div>
        <div class="t">那F1呢,就算是機器的答案跟正確的答案有點不一樣,只要有一部分是重疊的,也可以得到分數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#59:23.000" id=59:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3563">59:23.000</a></div>
        <div class="t">人類在Squad 1.0上的EN分數是86.8%,而今天第一名的機器已經超越人類了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#59:36.000" id=59:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3576">59:36.000</a></div>
        <div class="t">不只第一名的機器超越人類,你看前五名統統是90分以上,前五名的Model統統都已經超越人類了。當然這些Model都是以Bert為基礎做的,尤其都是以Albert為基礎做的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#59:53.000" id=59:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3593">59:53.000</a></div>
        <div class="t">第一名是用Albert做的,第二名他是個Ensemble,但他其實內部用的也是Albert。第三名是Electra加Albert,第四名是Albert,第五名也是Albert。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:00:08.000" id=01:00:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3608">01:00:08.000</a></div>
        <div class="t">用Bert的Model好像在一定程度上解決了QA的問題,但是QA的問題真的已經被解決了嗎?這篇Paper是這樣做的,他說這個是比較舊的Paper,所以當時的實驗是做在Baby上面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:00:27.000" id=01:00:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3627">01:00:27.000</a></div>
        <div class="t">在Baby上面,機器往往可以得到非常高的正確率。有幾個Task比較難,但很多Task機器都可以得到90%以上的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:00:40.000" id=01:00:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3640">01:00:40.000</a></div>
        <div class="t">現在,如果我們只給機器看文章的問題,把Squad任務裡面的文章做隨機的置換,只讓機器看到問題,這個時候Performance當然會比有看到文章的狀況還要差。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:04.000" id=01:01:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3664">01:01:04.000</a></div>
        <div class="t">但是神奇的事情是,假如我們讓機器只看文章,隨機給它一個錯誤的問題,這時候發生什麼事呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:14.000" id=01:01:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3674">01:01:14.000</a></div>
        <div class="t">在好幾個任務上,機器不給它問題,只給它文章,反而可以得到更高的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:26.000" id=01:01:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3686">01:01:26.000</a></div>
        <div class="t">而在一些任務上面,不管機器有沒有看到問題,它都可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:34.000" id=01:01:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3694">01:01:34.000</a></div>
        <div class="t">比如說在第20個任務上,如果今天有看文章也有看問題,是100%的正確率。如果只有看文章沒看到問題,也有100%的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:44.000" id=01:01:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3704">01:01:44.000</a></div>
        <div class="t">代表今天你的模型不需要看這個問題,它光看文章就可以知道正確答案是什麼了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:01:53.000" id=01:01:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3713">01:01:53.000</a></div>
        <div class="t">再舉另外一個例子,這群作者試了一個叫做CVT的Copper。在這個CVT的Copper上面,如果你給機器看文章也看問題的話,得到的正確率是這一排。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:08.000" id=01:02:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3728">01:02:08.000</a></div>
        <div class="t">如果你今天只給機器看問題,不給它看文章,在某一些狀況下,這邊是四種不同類型的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:18.000" id=01:02:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3738">01:02:18.000</a></div>
        <div class="t">在這兩種類型的問題,機器居然比它要看到文章還要好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:24.000" id=01:02:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3744">01:02:24.000</a></div>
        <div class="t">不過這個是因為CVT是一個有點怪異的Copper,CVT其實是要機器做剋漏子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:33.000" id=01:02:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3753">01:02:33.000</a></div>
        <div class="t">它是把一篇文章裡面的21個句子拿出來,前20個句子當作是文章,第21個句子當作是問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:44.000" id=01:02:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3764">01:02:44.000</a></div>
        <div class="t">然後第21個句子裡面會有一個詞彙是鏤空的,那機器的任務、問題的答案就是要把那個鏤空的部分填回去。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:02:54.000" id=01:02:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3774">01:02:54.000</a></div>
        <div class="t">那你今天就會發現說,往往機器只要看第21句就可以把鏤空的部分填回去,給它看之前的1到20句,其實沒有幫助。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:06.000" id=01:03:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3786">01:03:06.000</a></div>
        <div class="t">這就顯示說CVT這個Copper其實它的設計是有一些問題的,它讓機器不看文章,只看問題就可以得到答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:19.000" id=01:03:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3799">01:03:19.000</a></div>
        <div class="t">不過這樣的狀況還好在Square上面並沒有真的出現。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:24.000" id=01:03:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3804">01:03:24.000</a></div>
        <div class="t">在Square上面,如果機器有看文章、有看問題得到的正確率是這樣,那個時候還沒有BERT,用的是QAnet。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:33.000" id=01:03:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3813">01:03:33.000</a></div>
        <div class="t">如果機器只看問題的話,那它的正確率當然會暴跌,只看文章的話,正確率當然會暴跌。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:46.000" id=01:03:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3826">01:03:46.000</a></div>
        <div class="t">那在18年的EMNLP還發現了一個特殊的現象,這個現象是這樣子的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03:53.000" id=01:03:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3833">01:03:53.000</a></div>
        <div class="t">今天給機器看一篇文章,那如果你問它,What did Tesla spend Aster's money on?機器可以得到正確的答案,就是這個深藍色框框所框起來的部分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04:06.000" id=01:04:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3846">01:04:06.000</a></div>
        <div class="t">但是當你今天把你的問題改成只有一個詞彙叫做Date,結果機器還是得到正確的答案,不只得到正確的答案,它的性侵分數還從0.78增加到0.9。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04:21.000" id=01:04:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3861">01:04:21.000</a></div>
        <div class="t">你給機器看這個完整的問題的時候,它得到的這個答案,它的性侵分數是0.78,你問它一個Date,人根本不知道在問什麼,機器居然也得到了正確的答案,而且性侵分數還更高。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04:35.000" id=01:04:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3875">01:04:35.000</a></div>
        <div class="t">在VQA上也發現類似的現象,你給機器看這張圖片,那你問機器說,What color is the flower?機器會回答Yellow。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04:45.000" id=01:04:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3885">01:04:45.000</a></div>
        <div class="t">但你把你的問題改成花,人根本不知道問什麼,你要問花的什麼,問花有幾朵嗎?問花有沒有插在花盆裡面嗎?不知道。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04:55.000" id=01:04:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3895">01:04:55.000</a></div>
        <div class="t">結果機器自己知道說答案就是Yellow,而且它的性侵分數只有略微的下降。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:02.000" id=01:05:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3902">01:05:02.000</a></div>
        <div class="t">所以太神奇了,機器料事如神啊,你不用問它完整的問題啊,你問它花,它就知道你要問花的顏色。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:10.000" id=01:05:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3910">01:05:10.000</a></div>
        <div class="t">你隨便答一個Date,你問題根本沒問完,機器就得到正確的答案,怎麼這麼神奇?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:16.000" id=01:05:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3916">01:05:16.000</a></div>
        <div class="t">在這篇文章裡面其實有做更完整的分析,這邊只是舉兩個例子,文章裡面的完整分析是這樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:23.000" id=01:05:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3923">01:05:23.000</a></div>
        <div class="t">在那篇文章裡面,作者試圖把SQUAD、SNLI跟VQA這三個任務的問題都把它縮短,原來問題的長度分布是藍色的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:38.000" id=01:05:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3938">01:05:38.000</a></div>
        <div class="t">縮短以後的問題的長度分布是橙色的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:43.000" id=01:05:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3943">01:05:43.000</a></div>
        <div class="t">然後你會發現說把問題縮短對機器的影響不大,這邊是展現這幾個任務上面機器的Confidence Score。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:05:54.000" id=01:05:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3954">01:05:54.000</a></div>
        <div class="t">其實把這些問題縮短以後,在縮短問題的時候,這群作者是有稍微特別設計一下要把哪些詞彙拿掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:03.000" id=01:06:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3963">01:06:03.000</a></div>
        <div class="t">所以他們會刻意只拿掉不會改變機器答案的詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:08.000" id=01:06:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3968">01:06:08.000</a></div>
        <div class="t">所以今天這些原來的問題跟縮短後的問題,機器得到的答案是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:16.000" id=01:06:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3976">01:06:16.000</a></div>
        <div class="t">當機器在看這些原來的問題跟縮短後的問題的時候,它的正確率完全沒有改變。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:22.000" id=01:06:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3982">01:06:22.000</a></div>
        <div class="t">接下來,把這些原來的問題跟縮短後的問題拿去給人看。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:29.000" id=01:06:29.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3989">01:06:29.000</a></div>
        <div class="t">人在原來的問題上可以得到不錯的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:34.000" id=01:06:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3994">01:06:34.000</a></div>
        <div class="t">但一旦給人這些縮短後的問題,人發現我根本就看不懂啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:39.000" id=01:06:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=3999">01:06:39.000</a></div>
        <div class="t">所以人給出的正確率跟隨機差不多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:43.000" id=01:06:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4003">01:06:43.000</a></div>
        <div class="t">這太神奇了,機器可以答對這些縮短的問題,但是人沒辦法答對。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:51.000" id=01:06:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4011">01:06:51.000</a></div>
        <div class="t">但這個時候你不會說太神奇了,機器超越人類了,又有故事可以寫了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06:56.000" id=01:06:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4016">01:06:56.000</a></div>
        <div class="t">不是這樣,這個時候你會覺得,這什麼地方怪怪的?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:01.000" id=01:07:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4021">01:07:01.000</a></div>
        <div class="t">到底機器學到了什麼?它真的學到東西了嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:06.000" id=01:07:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4026">01:07:06.000</a></div>
        <div class="t">還是今天我們在Square上面看到的這麼好的performance只是一種假象?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:11.000" id=01:07:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4031">01:07:11.000</a></div>
        <div class="t">機器只是抓到了人類在Square出題的方向,它知道人類會怎麼出題,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:19.000" id=01:07:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4039">01:07:19.000</a></div>
        <div class="t">它根本就不用看問題了,你隨便給它問題的一小部分,它都可以猜中答案了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:25.000" id=01:07:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4045">01:07:25.000</a></div>
        <div class="t">它根本就不需要真的去理解文章,它光看問題的一部分就可以猜出答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:32.000" id=01:07:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4052">01:07:32.000</a></div>
        <div class="t">所以這代表的並不是說機器真的超越人類,而是也許我們今天在這些Benchmark corpus上的結果是有問題的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07:41.000" id=01:07:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4061">01:07:41.000</a></div>
        <div class="t">也許這些Benchmark corpus的設計並沒有辦法真正檢驗機器的能力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:02.000" id=01:08:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4082">01:08:02.000</a></div>
        <div class="t">就好像說你去考駕照的時候,如果你有去上那種考駕照的補習班,它都會教你說,看到文章裡面、看到問題裡面出現某個詞彙,你就選選項C,不要猶豫。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:17.000" id=01:08:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4097">01:08:17.000</a></div>
        <div class="t">所以機器很有可能學到的就是類似的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:22.000" id=01:08:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4102">01:08:22.000</a></div>
        <div class="t">所以如果今天我們單看Square的結果,你並不能夠真的知道機器的能力到什麼階段。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:30.000" id=01:08:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4110">01:08:30.000</a></div>
        <div class="t">所以我們也許需要更好的Benchmark corpus。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:34.000" id=01:08:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4114">01:08:34.000</a></div>
        <div class="t">舉一個例子,在VQA這樣子的Benchmark corpus上,有人就發現說在VQA裡面,它的測試資料跟訓練資料裡面有非常明顯的buyer。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:46.000" id=01:08:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4126">01:08:46.000</a></div>
        <div class="t">舉例來說,假設問題裡面有提到運動,那你就回答網球,不知道為什麼出題的人特別喜歡打網球,問運動就是打網球,你就會對了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08:58.000" id=01:08:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4138">01:08:58.000</a></div>
        <div class="t">所以這樣子的狀況,你並沒有辦法透過VQA真的去衡量機器看一張圖片回答問題的能力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09:05.000" id=01:09:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4145">01:09:05.000</a></div>
        <div class="t">所以就有人設計了新的VQA corpus,叫做VQACP。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09:11.000" id=01:09:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4151">01:09:11.000</a></div>
        <div class="t">在VQACP裡面,故意給訓練資料跟測試資料不同的分佈。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09:17.000" id=01:09:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4157">01:09:17.000</a></div>
        <div class="t">在VQACP裡面,在訓練資料裡面,看到what sport這樣的question,出現頻率最高的是tennis。但是在測試資料裡面,看到what sport這樣的question,出現頻率最高的就變成滑雪。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09:33.000" id=01:09:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4173">01:09:33.000</a></div>
        <div class="t">看到which,本來在訓練資料裡面出現答案最多次的是左邊,在測試資料裡面就刻意給你改成右邊。出現r,本來在訓練資料裡面最應該回答的出現次數最多的是no,在測試資料裡面就故意給你改成右邊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:09:52.000" id=01:09:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4192">01:09:52.000</a></div>
        <div class="t">看看機器在這種狀況下,它能不能夠正確的學會怎麼看一張圖片,怎麼回答問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:10:02.000" id=01:10:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4202">01:10:02.000</a></div>
        <div class="t">這邊是說還沒有VQACP只用原本的VQA來做實驗。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:10:10.000" id=01:10:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4210">01:10:10.000</a></div>
        <div class="t">如果你只用原本的VQA來做實驗,你會發現說機器可以得到頗高的正確率,下面這四個是deep learning base的model,機器都得到了50%以上的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:10:22.000" id=01:10:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4222">01:10:22.000</a></div>
        <div class="t">但比較奇怪的就是說,機器如果只給它看問題,它有48%的正確率。不只是只給它看問題,給它看更少,只告訴它問題是哪一個類別的,也有35%的正確率,這真的是有點怪怪的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:10:39.000" id=01:10:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4239">01:10:39.000</a></div>
        <div class="t">如果你今天換成VQACP,這樣測試資料跟訓練資料,它們的分佈不一樣,機器直接鏟掉,你會發現說本來什麼60%、50%以上的那些model正確率,現在都掉到30%左右了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:10:55.000" id=01:10:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4255">01:10:55.000</a></div>
        <div class="t">然後這些什麼只給question type、只給question的狀況都直接鏟掉,所以這可能VQACP上的performance可能更接近機器真實的能力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:11:07.000" id=01:11:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4267">01:11:07.000</a></div>
        <div class="t">我講這麼多只是想要告訴大家說,今天雖然有各式各樣的浮誇,說在benchmark corpus上面,機器閱讀理解的能力已經超越人類了,但並不代表機器回答問題的能力真的超越人類。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:11:26.000" id=01:11:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4286">01:11:26.000</a></div>
        <div class="t">那如果我們把那些用BERT做出來的model,在squad上號稱可以跟人的performance相匹敵的model,拿來直接測試在baby上面,會如何呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:11:39.000" id=01:11:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4299">01:11:39.000</a></div>
        <div class="t">那baby我們在這門課的一開始就已經提過,baby這個corpus是一個artificial的corpus,它裡面的句子是用某種template所生出來的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:11:52.000" id=01:11:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4312">01:11:52.000</a></div>
        <div class="t">如果我們現在把訓練在squad上的model,直接測試在baby的20個任務上,結果會怎樣呢?你發現結果都還蠻慘的,任務4跟任務5還有超過50%的正確率,其他基本上都是壞掉了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12:12.000" id=01:12:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4332">01:12:12.000</a></div>
        <div class="t">不要忘了baby在好幾年前就已經號稱全破了,好幾年前就已經有模型說在所有的baby corpus上都可以得到95%以上的正確率了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12:22.000" id=01:12:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4342">01:12:22.000</a></div>
        <div class="t">所以當然有人會說,這個squad本來就是extract and match的QA的problem,baby比較難,baby是需要機器做一下推理才能夠答對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12:34.000" id=01:12:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4354">01:12:34.000</a></div>
        <div class="t">所以訓練在squad上的model不太可能在baby上得到正確的答案。這顯示說,就算在squad上面機器的performance跟人差不多,這也不代表什麼。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12:47.000" id=01:12:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4367">01:12:47.000</a></div>
        <div class="t">說在squad上面機器跟人的performance差不多,就是機器在閱讀的能力上超越人類,這個其實太浮誇了。有關QA的研究,其實還有很長一段路要走。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:13:01.000" id=01:13:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ&t=4381">01:13:01.000</a></div>
        <div class="t">那這個有關QA的部分呢,我們就分享到這邊。</div>
    </div>
    
</body>
</html>   