<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>[DLHLP 2020] Speech Separation (1/2) - Deep Clustering, PIT</h2><a href=https://www.youtube.com/watch?v=tovg5ZxNgIo><img src=https://i.ytimg.com/vi_webp/tovg5ZxNgIo/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=0">00:00.000</a></div>
        <div class="t">整理&字幕由Amara.org社區提供</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:30.000" id=00:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=30">00:30.000</a></div>
        <div class="t">您可以專注在您想要聽的聲音上,無視外界的雜訊,只把您想要聽的聲音訊號擷取出來。這叫做機尾酒會效應。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:44.000" id=00:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=44">00:44.000</a></div>
        <div class="t">人類可以輕易地做到這件事情,而speech separation這個研究方向想要做的事情,就是機器能不能夠跟人類一樣,把他要聽的資訊從吵雜的環境,從很多其他聲音的干擾裡面,把它抽取出來呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04.000" id=01:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=64">01:04.000</a></div>
        <div class="t">那這個speech separation又可以分成兩類,一個叫做speech enhancement,speech enhancement的意思是說,你現在要做的事情是speech跟nonspeech的separation,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:16.000" id=01:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=76">01:16.000</a></div>
        <div class="t">也就是你現在只有一個人在講話,而有很多其他不是人類聲音的聲音訊號在干擾,而在這個情況下,你能不能夠把聲音的部分抽取出來呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:28.000" id=01:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=88">01:28.000</a></div>
        <div class="t">這個叫做speech enhancement,或者又叫做denoising。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:34.000" id=01:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=94">01:34.000</a></div>
        <div class="t">還有另外一個任務叫做speaker separation,speaker separation是說,同時有很多人在講話。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:44.000" id=01:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=104">01:44.000</a></div>
        <div class="t">在同時有很多人在講話的情況下,我們能不能夠把每一個人的聲音訊號分離出來?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:51.000" id=01:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=111">01:51.000</a></div>
        <div class="t">今天同時有一個女生在講話,一個男生在講話,一個小孩在講話,你機器能不能夠把這三個人的聲音訊號分離開來,這樣他就能夠選擇說現在他要專注在哪一個人的聲音訊號上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:05.000" id=02:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=125">02:05.000</a></div>
        <div class="t">這個叫做speaker separation,所以speech separation有兩種,一個是speech enhancement,一個是speaker separation。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:14.000" id=02:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=134">02:14.000</a></div>
        <div class="t">我們作業上要做的事情就是speaker separation,給你兩個人的聲音,你要訓練一個模型把兩個人的聲音分離開來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:24.000" id=02:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=144">02:24.000</a></div>
        <div class="t">speaker separation這個任務,它本質上的目的就是輸入一段聲音訊號,這段聲音訊號裡面其實是兩段聲音訊號疊在一起的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:36.000" id=02:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=156">02:36.000</a></div>
        <div class="t">你給這個speaker separation一段聲音訊號,它現在要輸出兩段聲音訊號,這是一個輸入聲音、輸出聲音的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:49.000" id=02:49.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=169">02:49.000</a></div>
        <div class="t">在以下的討論裡面,我們只專注在輸入是兩個speaker的聲音混合起來的狀況。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:58.000" id=02:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=178">02:58.000</a></div>
        <div class="t">同樣的想法,其實你也可以輕易地拓展到多個speaker,因為如果今天輸入的聲音訊號是兩個speaker的聲音訊號混雜在一起,那你就突出兩段聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:09.000" id=03:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=189">03:09.000</a></div>
        <div class="t">如果今天是三個,那你就突出三段聲音訊號,K一個就突出K一個聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:15.000" id=03:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=195">03:15.000</a></div>
        <div class="t">所以你可以輕易地想像說,怎麼把等一下我們講的東西拓展到更多的speaker上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:22.000" id=03:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=202">03:22.000</a></div>
        <div class="t">舉例來說,都只舉兩個speaker的例子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:28.000" id=03:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=208">03:28.000</a></div>
        <div class="t">等一下我們講的時候,我們只focus在單一麥克風的狀況。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:34.000" id=03:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=214">03:34.000</a></div>
        <div class="t">我們最後會稍微提一下說,如果是多個麥克風的話要怎麼解。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:38.000" id=03:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=218">03:38.000</a></div>
        <div class="t">但我們現在就專注在單一麥克風的狀況,所以就代表說我們的speaker separation model只聽到一段聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:48.000" id=03:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=228">03:48.000</a></div>
        <div class="t">接下來的討論,我們只專注在講speaker independent training,也就是說我們的訓練跟測試的語者是完全不同的兩群語者。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:02.000" id=04:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=242">04:02.000</a></div>
        <div class="t">訓練的時候聽到的是ABCD的聲音,測試的時候聽到的是EFGH的聲音。訓練跟測試的語者是兩群完全不同的語者。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:18.000" id=04:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=258">04:18.000</a></div>
        <div class="t">如果訓練跟測試的語者是一樣的,那這樣就是speaker dependent training。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:23.000" id=04:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=263">04:23.000</a></div>
        <div class="t">那你可以想見說speaker independent training是比speaker dependent training還要更為複雜的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:30.000" id=04:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=270">04:30.000</a></div>
        <div class="t">那在做speaker separation的時候,其實你輸入跟輸出的這個聲音訊號的長度是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:38.000" id=04:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=278">04:38.000</a></div>
        <div class="t">也就是輸入的這段聲音訊號的長度跟紅色這段聲音訊號的長度還有跟藍色這段聲音訊號的長度其實是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:47.000" id=04:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=287">04:47.000</a></div>
        <div class="t">因為你只是把本來這兩段聲音疊起來的狀態把它分離開來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:52.000" id=04:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=292">04:52.000</a></div>
        <div class="t">所以一般在做speaker separation的時候,你用不上sequence-to-sequence的model。如果用sequence-to-sequence的model是殺雞用了牛刀,sequence-to-sequence的model它的強項是輸入的聲音訊號跟輸出的聲音訊號長度不一樣的時候,你才會想要用sequence-to-sequence的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:09.000" id=05:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=309">05:09.000</a></div>
        <div class="t">如果長度是一樣的時候,你就沒有必要用sequence-to-sequence的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:15.000" id=05:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=315">05:15.000</a></div>
        <div class="t">不過之前Google也有一篇paper在做speaker separation的時候用了sequence-to-sequence的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:22.000" id=05:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=322">05:22.000</a></div>
        <div class="t">那他們也知道說,那個paper的作者有偷偷跟我講說,他們也知道說用sequence-to-sequence的model在speaker separation裡面是殺雞用了牛刀,是沒有必要的,因為輸入跟輸出的長度是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:34.000" id=05:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=334">05:34.000</a></div>
        <div class="t">但為什麼他們還是要用sequence-to-sequence的model呢?因為他們就是想要顯示說sequence-to-sequence的model很神奇啊,這種問題也可以解啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:43.000" id=05:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=343">05:43.000</a></div>
        <div class="t">作者告訴我說,sequence-to-sequence的model厲害的地方就是,今天在做speaker separation的時候,他第一件學到的事情就是輸入跟輸出的聲音訊號長度是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:53.000" id=05:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=353">05:53.000</a></div>
        <div class="t">他還不知道怎麼做speaker separation的時候,他就知道說輸入跟輸出的聲音訊號長度是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:03.000" id=06:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=363">06:03.000</a></div>
        <div class="t">那這個speaker separation要怎麼做呢?在概念上,用machine learning的想法非常的簡單。我們說machine learning,你要訓練一個model,你就要有輸入跟輸出的pair。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:16.000" id=06:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=376">06:16.000</a></div>
        <div class="t">如果沒有輸入跟輸出的pair,那你就得想些其他的方法來解這個問題。像我們在做voice conversion的時候,沒有輸入和輸出的pair,所以我們必須要有feature disentangle的方法等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:28.000" id=06:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=388">06:28.000</a></div>
        <div class="t">但是在speaker separation,你很容易收集到這一種成對的資料。怎麼收集成對的資料呢?你並不需要刻意去收集mixed的聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:41.000" id=06:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=401">06:41.000</a></div>
        <div class="t">你不需要說,我去收集很多mixed的聲音訊號,然後再找工讀生來標註說,這個聲音訊號丟到speaker separation的model裡面應該要offer什麼樣的聲音訊號,不用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:52.000" id=06:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=412">06:52.000</a></div>
        <div class="t">你就收集很多單一的語者的聲音訊號,然後把這些單一語者的聲音訊號兩兩拿出來做結合,就產生mixed的聲音訊號了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:05.000" id=07:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=425">07:05.000</a></div>
        <div class="t">那你就有訓練資料了,你就知道說,輸入這個mixed的聲音訊號,到底speaker separation的正確答案是什麼呢?就是原來拿來混出這個mixed聲音訊號的這兩段聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:18.000" id=07:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=438">07:18.000</a></div>
        <div class="t">所以在做speaker separation的時候,你產生這個訓練資料其實是容易的。你不用刻意去收集mixed的聲音訊號,那個mixed的聲音訊號你就自己產生就可以了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:31.000" id=07:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=451">07:31.000</a></div>
        <div class="t">在進入技術的部分之前,我們來講一下speaker separation的evaluation。這邊,speaker separation是可以做evaluation的,可以有客觀的評估方法的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:49.000" id=07:49.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=469">07:49.000</a></div>
        <div class="t">像我們在上一堂課講voice conversion的時候,我們完全沒有提到怎麼evaluate你的結果。那是因為你在做voice conversion的時候,你把一個人的聲音轉成另外一個人的聲音,把A的聲音轉成B的聲音以後,正確答案應該是什麼?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:04.000" id=08:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=484">08:04.000</a></div>
        <div class="t">我們沒有正確答案。因為沒有正確答案,所以你根本沒有辦法做客觀的評量,你只能靠人來做主觀的評量。但是因為在做speaker separation的時候,你是有正確答案的,你有被混在一起之前的聲音。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:21.000" id=08:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=501">08:21.000</a></div>
        <div class="t">所以你有正確答案,所以你可以做客觀的評估。怎麼做客觀的評估呢?我們假設ground truth,正確答案叫做x hat,我們用x hat來當作正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:36.000" id=08:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=516">08:36.000</a></div>
        <div class="t">我們用x star來當作你的model的輸出。那當然這個x star跟x hat越接近,就代表說現在你的model的performance越好。但是怎麼評估這個x star跟x hat接近的程度呢?就有不同的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:55.000" id=08:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=535">08:55.000</a></div>
        <div class="t">一個最基本的想法叫做signal-to-noise ratio,SNR。SNR怎麼算呢?這邊我們的每一個x,就是x star跟x hat,其實都是聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:09.000" id=09:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=549">09:09.000</a></div>
        <div class="t">一段聲音訊號,一段waveform,其實你可以把它想成是一個非常長的向量。這個向量有多長呢?如果是16kHz的waveform,那它的每一秒就有16k的point。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:27.000" id=09:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=567">09:27.000</a></div>
        <div class="t">你要表示一秒鐘的聲音訊號,你就需要16k微的長度。那我們計算一下x star跟x hat的差距,這邊用1來表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:40.000" id=09:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=580">09:40.000</a></div>
        <div class="t">然後接下來呢,你去計算x hat光truth的node平方,除掉x hat跟x star光truth跟model output它們之間差距的node平方,再取16個10,就得到SNR。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:57.000" id=09:57.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=597">09:57.000</a></div>
        <div class="t">如果今天的error是0,那SNR算出來就是無窮大。你的error這個1,它越小,你的SNR算出來就越大。但是SNR會有什麼樣的問題呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:10.000" id=10:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=610">10:10.000</a></div>
        <div class="t">當你把SNR用在speaker separation上的時候,其實是會有一些問題的。我們假設現在你的x hat這個光truth長這樣,因為這邊每一個聲音訊號可以看作是一個非常高微的向量,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:23.000" id=10:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=623">10:23.000</a></div>
        <div class="t">每一個聲音訊號我們可以把它當作是一個向量來表示。x hat長這個樣子,那x star它跟x hat是完全平行的,這是我們model的output x star。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:36.000" id=10:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=636">10:36.000</a></div>
        <div class="t">那x star呢,它比x hat小一些。x star跟x hat雖然聲音訊號一模一樣,但x hat聲音比較小一些。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:47.000" id=10:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=647">10:47.000</a></div>
        <div class="t">這個時候如果你計算SNR,會發現說這個error還挺大的,SNR算出來還挺小的。但是問題是,你的x star其實聲音聽起來跟x hat其實一模一樣,只是比較小聲一點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:00.000" id=11:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=660">11:00.000</a></div>
        <div class="t">你如果要讓x star跟x hat一樣,你要讓你的model的輸出跟光truth一樣,你就把音量調大一點,你model的輸出聽起來就跟光truth一樣了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:09.000" id=11:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=669">11:09.000</a></div>
        <div class="t">所以你的model明明是得到一個非常好的結果,但是卻會有不夠高,會有很低的SNR。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:17.000" id=11:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=677">11:17.000</a></div>
        <div class="t">那再舉另外一個SNR會造成的問題。藍色這個箭頭是你的光truth,黃色這個箭頭是你model的output。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:27.000" id=11:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=687">11:27.000</a></div>
        <div class="t">那現在你的model的output跟光truth之間,它們的差距很大,所以你的SNR很小。現在我們可以什麼事都不做,只做一個非常簡單的變動,你的model完全沒有變得比較厲害,但就讓SNR變大了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:44.000" id=11:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=704">11:44.000</a></div>
        <div class="t">怎麼做呢?我們就把這個向量把它伸長,我們把原來model的output直接把它變長。我們把model的output變長以後,你會發現這個e這個vector就變短了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:01.000" id=12:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=721">12:01.000</a></div>
        <div class="t">把model的outputX大變長,e直接就變短了。也就是你的model其實什麼事都沒有做,它唯一做的事情就是把輸出的音量調大一點,結果SNR反而就上升了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:16.000" id=12:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=736">12:16.000</a></div>
        <div class="t">從SNR的角度來看,當SNR在評估的時候,你的model是比較好的,但問題是你的model只是把音量放大一點,所以SNR並不是一個非常好的在speaker separation的evaluation measure。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:31.000" id=12:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=751">12:31.000</a></div>
        <div class="t">今天在文獻上比較常看到的一種評估你的speaker separation performance好壞的方法,叫做scale invariant signal-to-noise ratio,縮寫是SISDR。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:48.000" id=12:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=768">12:48.000</a></div>
        <div class="t">那我在文獻上也有看過有人把一模一樣的measure叫做SISNR,所以有時候你看到SISNR,其實它就是SISDR。不過它叫什麼名字沒有那麼重要,重點是這個式子是怎麼算的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:07.000" id=13:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=787">13:07.000</a></div>
        <div class="t">這個SISDR是這樣算的,這個是你的Ground Truth,這個是你model的output,然後你把你model的output這個X star投影到X hat上面,得到X大T。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:23.000" id=13:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=803">13:23.000</a></div>
        <div class="t">然後剩下的跟這個X hat跟Ground Truth是orthogonal的部分呢,叫做X大E,然後這個XE加XT就得到X大。SISDR就是把XT的這個none平方除掉XE的none平方再取10log10,就是SISDR。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:46.000" id=13:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=826">13:46.000</a></div>
        <div class="t">所以你可以想像說,如果你的X大跟X hat越平行,SISDR算出來就越大。如果X大跟X hat越垂直、越orthogonal,那SISDR算出來就越小。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:00.000" id=14:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=840">14:00.000</a></div>
        <div class="t">那這個XT怎麼算呢?這個大學現代就有教過了,套個公式,直接就算出來。這個XT是什麼?XT是X大跟X hat的inner product,再除掉X hat的長度,然後再乘上X hat就得到X大T。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:18.000" id=14:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=858">14:18.000</a></div>
        <div class="t">那XE是什麼呢?XE是X大減X大T,就是XE。那SISDR能不能解決我們剛才看到的SNR的問題呢?我們來看看剛才的SNR問題SISDR能不能解決。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:36.000" id=14:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=876">14:36.000</a></div>
        <div class="t">如果今天你的X大跟X hat正好是平行的,如果用SNR算,你有一個很大的E,所以SNR算出來不會太大。但是如果你用SISDR算,因為XT就等於X大,而XE跟這個X hat orthogonal的部分是0,所以你SISDR算出來就會是無限大,代表說你現在model的output其實是完美的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:01.000" id=15:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=901">15:01.000</a></div>
        <div class="t">我們再看另外一個剛才SNR所遇到的問題。剛才在SNR裡面說,你單純把X變大,有機會讓你的SNR也跟著變大。但是在SISDR裡面會這個樣子嗎?你直接把你的輸出乘K倍,那X大T跟XE也跟著變K倍,結果是不影響你的SISDR的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:26.000" id=15:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=926">15:26.000</a></div>
        <div class="t">你在文獻上常常看到的一種呈現SISDR的方式是SISDR的improvement,有時候縮寫成SISDRI。這個improvement怎麼算的呢?你用一個mixed audio丟到speaker separation裡面,得到separate的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:46.000" id=15:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=946">15:46.000</a></div>
        <div class="t">那你把mixed的結果跟separate的結果分別去跟你的正確答案計算SISDR。那你把separate以後所算出來的SISDR去減掉separate之前的SISDR。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:03.000" id=16:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=963">16:03.000</a></div>
        <div class="t">這個值通常是正的,因為你做完speaker separation以後,你的SISDR會提升。所以SISDR2應該會比1大,你把2減掉1,就是SISDR的improvement。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:16.000" id=16:16.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=976">16:16.000</a></div>
        <div class="t">你要這麼做是因為,也許你本來在你的mixed audio裡面,紅色的interference的聲音訊號本來就很小。如果本來就很小,你SISDR1可能算出來就已經很大,那你SISDR2就算很大,可是搞不好進步不多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:34.000" id=16:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=994">16:34.000</a></div>
        <div class="t">所以在SISDR裡面,我們通常看的是它的improvement,而不見得是看它的絕對值。那除了SISDR以外,還有很多其他的針對聲音訊號好壞的evaluation的方式。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:48.000" id=16:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1008">16:48.000</a></div>
        <div class="t">比如說PSQ,它是量語音的quality,或STOI,它是量聲音的intelligibility,也就是聲音的可理解程度。像這種PSQ、STOI,它們就很複雜了,它們就不是三言兩語就可以講清楚。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:05.740" id=17:05.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1025">17:05.740</a></div>
        <div class="t">它們是古聖先賢花了很多時間研究人類的聽覺,去做了很多user study以後所得到的計算的方法。這個我們就不細講了,你只要知道有這些evaluation measure就可以了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:20.440" id=17:20.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1040">17:20.440</a></div>
        <div class="t">講到這邊,好像speaker separation就講完了。反正製造訓練資料也很容易,然後你有一個model,你有pair data,硬train下去就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:37.640" id=17:37.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1057">17:37.640</a></div>
        <div class="t">所以你現在有訓練資料,你只要輸入這段mix的聲音訊號,輸出掉是這兩段紅色跟藍色的聲音訊號。然後你可能就說,我就train一個model,輸入mix的聲音訊號,然後它就輸出一個x1,x1代表一段聲音訊號,這段聲音訊號要跟紅色的越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:58.880" id=17:58.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1078">17:58.880</a></div>
        <div class="t">然後再輸個x2,x2要跟藍色的越接近越好。那怎麼讓兩段聲音訊號越接近越好呢?我們說對network來說,聲音訊號可能是表示成acoustic feature sequence,所以每段聲音訊號其實就是一個matrix,那你就讓matrix的l1或l2的distance越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:20.040" id=18:20.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1100">18:20.040</a></div>
        <div class="t">那其實因為我們最後evaluate的對象是sisdr,而sisdr這件事情本身是可以為分的,所以假設你的speaker separation夠強,你可以直接產生聲音訊號,你不是產生acoustic feature,你直接產生waveform,你直接產生聲音訊號,那你可以計算兩段聲音訊號之間的sisdr。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:45.480" id=18:45.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1125">18:45.480</a></div>
        <div class="t">你可以直接訓練你的speaker separation去minimize它的output跟ground truth之間的sisdr,那就解決了,感覺speaker separation沒有什麼可以講的可以做的東西了,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:01.320" id=19:01.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1141">19:01.320</a></div>
        <div class="t">但是問題是,有一個神秘的問題是這個樣子的,為什麼是紅色的聲音訊號放在上面當作ground truth,藍色的聲音訊號是下面這個輸出的ground truth呢?為什麼不是藍色的是上面的ground truth,紅色的是下面的ground truth呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:21.320" id=19:21.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1161">19:21.320</a></div>
        <div class="t">有人可能會問說,這個是個問題嗎?這會是個問題。為什麼這會是個問題呢?因為我們在訓練的時候,我們是speaker independent的training,所以我們訓練資料裡面有非常多不同的speaker。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:38.760" id=19:38.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1178">19:38.760</a></div>
        <div class="t">如果你訓練跟測試的時候都固定是藍色跟紅色這兩個speaker,那沒有問題,你要把誰擺上面誰擺下面,你只要事先決定好,在train network的時候都不要改變,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:53.240" id=19:53.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1193">19:53.240</a></div>
        <div class="t">但問題是,我們訓練資料裡面有好多的speaker,有藍色紅色的speaker,也有綠色跟黃色的speaker。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:01.240" id=20:01.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1201">20:01.240</a></div>
        <div class="t">你可能會說,那我們就事先定好說,反正紅色的speaker都要在上面,藍色的都要在下面,黃色的都要在上面,綠色的都要在下面,那這樣也許會對你的training造成問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:14.040" id=20:14.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1214">20:14.040</a></div>
        <div class="t">什麼樣的問題呢?我們假設藍色的是男生,紅色的是女生的聲音訊號,所以你輸入男生跟女生混雜的聲音,你的network學會說,上面這個輸出就是輸出女生的聲音,下面這個輸出就是輸出男生的聲音。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:29.720" id=20:29.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1229">20:29.720</a></div>
        <div class="t">但如果你現在其實綠色的聲音是女生的聲音,黃色的聲音其實是男生的聲音,那就變成你在用這段聲音訊號當作input的時候,輸入男生跟女生混雜的聲音的時候,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:44.680" id=20:44.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1244">20:44.680</a></div>
        <div class="t">你告訴你的network說,我上半部,上面要輸出男生的聲音,下面要輸出女生的聲音,會變成說在上面這個case,你是上面女生的聲音,下面男生的聲音,在下面這個case,你是上面男生的聲音,下面女生的聲音。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:59.780" id=20:59.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1259">20:59.780</a></div>
        <div class="t">那你的network就很困惑,你的network就很崩潰,到底上面應該是男生的聲音還是女生的聲音,它就會無所適從,你training的時候可能就沒有辦法train好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:12.740" id=21:12.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1272">21:12.740</a></div>
        <div class="t">有人可能會問說,這也許不是一個問題,我們就事先按照性別,把男生的聲音跟女生的聲音分成兩群,然後就看男生的聲音就要在上面,女生的聲音就要在下面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:25.640" id=21:25.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1285">21:25.640</a></div>
        <div class="t">但是這樣也不見得能完全解決問題,因為你之所以覺得男生跟女生的聲音應該分成兩群,是因為男生的聲音都比較低沉,女生的聲音都比較高亢。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:35.220" id=21:35.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1295">21:35.220</a></div>
        <div class="t">這件事情未必是真的,也有女生的聲音比較低沉,也有男生的聲音比較高亢。有人可能就會說,那我們就不要按照性別來分,我們按照聲音是高還是低來分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:47.040" id=21:47.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1307">21:47.040</a></div>
        <div class="t">聲音高的就第一個當作上面的輸出,聲音低的就當作下面的輸出。但是如果你今天mix的聲音訊號裡面,兩個人的聲音是一樣高的,兩個人的聲音其實沒有誰特別高誰特別低呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:02.160" id=22:02.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1322">22:02.160</a></div>
        <div class="t">那應該誰在上面,誰在下面。所以到底今天應該要讓哪一個speaker,哪一個光處當作第一個輸出,上面這個輸出的光處,哪一個光處當作下面第二個輸出的光處?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:17.100" id=22:17.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1337">22:17.100</a></div>
        <div class="t">這會是一個問題的,這個問題叫做permutation issue,也就是說你根本就不知道說你要把你的正確答案怎麼進行擺放。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:26.460" id=22:26.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1346">22:26.460</a></div>
        <div class="t">現在有兩種擺放正確答案的方式,你今天輸入這個紅藍的聲音訊號,你可以把藍色放上面,也可以把藍色放下面,你可以把紅色放上面,也可以把紅色放下面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:38.820" id=22:38.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1358">22:38.820</a></div>
        <div class="t">你有兩種擺放你正確答案的方式,但是你不知道哪一種才是對的。你不知道說,如果你隨便為每一筆全領資料都自己定一種擺放的方式,會不會最後產生矛盾的狀況。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:53.400" id=22:53.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1373">22:53.400</a></div>
        <div class="t">這個叫做permutation issue,過去這其實是一個問題,這讓人有點不知道說要怎麼把這種deep learning的技術直接放到speaker的separation裡面,所以過去大家是有困惑的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:10.100" id=23:10.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1390">23:10.100</a></div>
        <div class="t">過去通常這種deep learning的方法,你大概就只能做speaker-dependent的separation,speaker-independent的separation,不知道怎麼用傳統的deep learning來解。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:26.240" id=23:26.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1406">23:26.240</a></div>
        <div class="t">最早用deep learning來解speaker-independent的separation的model,我覺得應該是Deep Clustering,它是16年的時候由Merle,Merle是Mitsubishi在美國的研究機構,由Merle所提出來的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:46.900" id=23:46.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1426">23:46.900</a></div>
        <div class="t">那這個model是怎麼運作的呢?Deep Clustering是怎麼運作的呢?Deep Clustering它其實使用了source separation的一個特性,那in general而言,source separation要做的事情當然是輸入聲音訊號,吐出兩段聲音訊號,那聲音訊號其實可以表示成一個矩陣,所以等於就是輸入一個矩陣x,輸出兩個矩陣x1跟x2。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:12.180" id=24:12.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1452">24:12.180</a></div>
        <div class="t">但是你如果任一個general的model去做這件事情,輸入一個矩陣,輸出兩個矩陣,其實是殺雞用的牛刀。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:21.020" id=24:21.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1461">24:21.020</a></div>
        <div class="t">為什麼呢?因為在做speaker separation的時候,其實輸入的這段聲音訊號跟輸出的這兩段聲音訊號其實是非常類似的,甚至講得更直接一點,這兩段聲音訊號的相加就是輸入的這段聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:38.940" id=24:38.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1478">24:38.940</a></div>
        <div class="t">你只要把輸入的這段聲音訊號減去一些東西,就變成x1,減去另外一些東西,就變成x2,所以這個speaker separation的任務跟voice conversion的任務不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:51.680" id=24:51.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1491">24:51.680</a></div>
        <div class="t">Voice conversion裡面,你是輸入一段聲音訊號,輸出一段很不一樣的聲音訊號,但在speaker separation裡面,你是輸入一段聲音訊號以後,把它減掉一些東西,就可以當作你的source。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:03.260" id=25:03.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1503">25:03.260</a></div>
        <div class="t">所以考量到這個特性,我們根本不需要一個general的model來做speaker separation這件事情,所以你會發現說,過去在文獻上會把speaker separation想成這樣一件事情,我們不是直接產生新的聲音訊號,而是產生mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:22.400" id=25:22.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1522">25:22.400</a></div>
        <div class="t">那mask它也是matrix,那mask這個matrix的大小跟你輸入的聲音訊號大小是一樣的,你輸入聲音訊號x,你產生兩個matrix,n1跟n2,x的大小跟n1是一樣的,x的大小跟n2是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:40.820" id=25:40.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1540">25:40.820</a></div>
        <div class="t">接下來,你把x乘上跟n1做點乘,做element wise的相乘,然後得到x1。你把n2跟x做點乘,做element wise的相乘,得到x2。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:55.400" id=25:55.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1555">25:55.400</a></div>
        <div class="t">那你這樣就可以確保說,所謂的x1它就只是x乘上什麼東西以後變成x1,所謂的x2它不會變得跟x非常非常不一樣,所謂的x2就是把x乘上一個什麼東西以後變成x2。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:10.980" id=26:10.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1570">26:10.980</a></div>
        <div class="t">那你一樣可以看作是輸入是x,輸出是x1、x2,你的整個speaker separation model仍然是輸入一段聲音訊號,輸出兩段聲音訊號。但是在這個model裏面你做了一些手腳,你只要求你的network輸出mask,然後用mask跟輸入相乘,就得到最終輸出的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:31.760" id=26:31.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1591">26:31.760</a></div>
        <div class="t">這個是在speaker separation裏面常用的model的設計,考慮到speaker separation這個任務的特性以後所常使用的一種設計的方式。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:45.380" id=26:45.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1605">26:45.380</a></div>
        <div class="t">那這個mask它可以是binary的,也可以是continuous的,就是這個mask它是一個matrix,這個matrix裏面的值可以是實數,也可以是0或1,也可以是binary的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:02.980" id=27:02.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1622">27:02.980</a></div>
        <div class="t">那有人可能會覺得說,binary的mask真的可以給我們好的結果嗎?如果你今天這個mask是binary的之後0跟1,那就代表這個輸入的matrix裏面有些值會被保留,有些值就完全丟掉變成0,這樣真的會給我們好的結果嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:21.360" id=27:21.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1641">27:21.360</a></div>
        <div class="t">神奇的是,如果你有一個好的binary mask,其實有好的binary的mask,你的結果往往就足夠好了。怎麼說呢?我們這邊就舉一個真實的例子,這個真實的例子叫做ideal的binary mask,它的縮寫是IBM。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:41.580" id=27:41.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1661">27:41.580</a></div>
        <div class="t">我們現在有兩段聲音訊號,我們把它混起來變成mixed audio,那每段聲音訊號我們現在用它的spectrogram來表示,那如果你不知道spectrogram是什麼的話也沒有關係,我們這門課儘量不講訊號處理的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:56.680" id=27:56.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1676">27:56.680</a></div>
        <div class="t">你不知道spectrogram是什麼也沒有關係,反正就是每段聲音訊號就如同我們之前講的,它都會變成一個vector sequence,也就是會變成一個matrix。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:06.960" id=28:06.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1686">28:06.960</a></div>
        <div class="t">那有一種神奇的binary mask叫做ideal的binary mask,這種binary mask你只要把它乘到這個藍色的聲音訊號上,你只要把它乘到這個mixed的聲音訊號上,你聽起來就像是這個藍色的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:29.440" id=28:29.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1709">28:29.440</a></div>
        <div class="t">你把這個ideal的binary mask乘到這個上面去,你就聽到紅色的這個人的聲音訊號了。那這種ideal的binary mask怎麼得到呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:40.120" id=28:40.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1720">28:40.120</a></div>
        <div class="t">它其實非常簡單,你就比這兩段聲音訊號它們在這個矩陣上同一個位置,誰的值比較大,比較大的那個人就是1,比較小的那個人就是0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:55.600" id=28:55.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1735">28:55.600</a></div>
        <div class="t">所以今天我們拿藍色跟紅色這兩段聲音訊號來進行比較,然後發現說紅色的聲音訊號這邊的值比較大,那這邊在做這個ideal的binary mask的時候,紅色的聲音訊號這邊就給它1,藍色的聲音訊號這邊就給它0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:14.440" id=29:14.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1754">29:14.440</a></div>
        <div class="t">就代表說,我們覺得說這兩段藍色跟紅色的聲音訊號加起來得到新的聲音訊號以後,右下角這一塊會是屬於紅色的,它就完全不會歸給藍色的聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:27.720" id=29:27.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1767">29:27.720</a></div>
        <div class="t">講到這邊,你可能覺得說這個想法聽起來怪怪的,你可以舉出這個想法的好多好多好多的問題,ideal的binary mask聽起來好像不怎麼ideal。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:40.120" id=29:40.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1780">29:40.120</a></div>
        <div class="t">你說藍色跟紅色的聲音訊號加起來變成這樣子的一個matrix,然後你看說藍色跟紅色誰比較大,到時候混合以後的這個矩陣,右下角就歸給誰的,看誰右下角的這個值比較大,然後就混合起來後右下角這個值就歸給誰。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:58.800" id=29:58.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1798">29:58.800</a></div>
        <div class="t">這會不會有點奇怪啊?因為這個藍色的聲音訊號這邊它只是比紅色小啊,它還有一些值啊,兩個相加以後,這個右下角這邊不是也應該會有一些藍色的成分嗎?不管它,就是這樣子,就直接這樣走。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:12.000" id=30:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1812">30:12.000</a></div>
        <div class="t">我們把用ideal binary mask的方法得到這個binary mask,直接存到這個混合的矩陣上,這邊有0的地方就消掉,就代表說它們不屬於藍色的,只剩下屬於藍色的部分保留下來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:30.080" id=30:30.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1830">30:30.080</a></div>
        <div class="t">那你可能說這個藍色的部分,當時相加的時候應該也混到一些紅色的東西啊,不管它,統統保留下來。你說這個屬於紅色的部分,其實也有一些藍色的成分在吧,不管它,就把它統統都消掉,這個叫做ideal binary mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:45.520" id=30:45.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1845">30:45.520</a></div>
        <div class="t">直覺地想起來,你可能會覺得說這個方法好像沒有很ideal,但實際上它還頗強的。我們這邊就是直接給你一個真正的實驗結果,告訴你說它聽起來像是什麼樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:16.520" id=31:16.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1876">31:16.520</a></div>
        <div class="t">藍色的聲音是男生的聲音。那這個紅色的聲音和藍色的聲音,它們是同一句話的,一個是女生講的,一個是男生講的,混起來是這個樣子的,兩個人同時講話。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:31.940" id=31:31.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1891">31:31.940</a></div>
        <div class="t">好,現在把這一段聲音訊號的spectrogram,也就是這個matrix,乘上ideal的binary mask,得到這個結果。放出來的聲音訊號聽起來像是什麼樣子呢?聽起來是這樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:45.420" id=31:45.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1905">31:45.420</a></div>
        <div class="t">你會發現說,它真的做到soul separation了,它這個聲音訊號聽起來就跟原來的聲音訊號幾乎是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:00.140" id=32:00.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1920">32:00.140</a></div>
        <div class="t">我第一次聽到的時候,我還以為是不小心弄錯了,把同一段聲音訊號copy了兩次。但是如果你把這兩段聲音訊號去把它們的spectrogram,也就是把這個矩陣畫出來,你會發現說它們確實是不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:16.560" id=32:16.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1936">32:16.560</a></div>
        <div class="t">看這個矩陣的時候,確實每個地方都有值,看這個矩陣的時候,發現說很多地方真的就是補齡,真的就是直接拿掉。但是人聽起來覺得還不錯,聽起來幾乎是完美地做到了soul separation。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:31.560" id=32:31.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1951">32:31.560</a></div>
        <div class="t">所以,如果你可以產生這種ideal的binary mask,你其實真的就解了soul separation的問題了。但問題是,你沒有那麼容易產生ideal的binary mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:45.480" id=32:45.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1965">32:45.480</a></div>
        <div class="t">因為ideal binary mask,你必須要知道原來的聲音訊號是什麼,比較它們轉成spectrogram,轉成矩陣以後同一個位置的大小,你才能產生這種ideal的binary mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:57.480" id=32:57.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1977">32:57.480</a></div>
        <div class="t">但是我們要做的是soul separation,你並不知道原來的聲音訊號是什麼,你是拿到了mixed的聲音訊號以後,需要去產生ideal的binary mask,然後再把這個mask跟原來的矩陣做點層,然後才能做soul separation這件事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:18.360" id=33:18.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=1998">33:18.360</a></div>
        <div class="t">所以,真正你要在實作的時候,你是要想辦法learn一個mask generation,這個mask generation它把ideal的binary mask當作它的learning target,當作它的目標。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:30.360" id=33:30.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2010">33:30.360</a></div>
        <div class="t">就ideal binary mask,你其實在有光處理的情況下,你可以輕易地得到,但是今天在真的做soul separation的時候,你在做testing的時候,你在做influence的時候,你是沒有光處理的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:44.240" id=33:44.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2024">33:44.240</a></div>
        <div class="t">所以,你要你learn一個model,learn一個mask generation,它知道怎麼吃這個聲音訊號進來,產生ideal的binary mask,有了ideal binary mask以後,你就可以做到soul separation這件事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:57.760" id=33:57.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2037">33:57.760</a></div>
        <div class="t">那ideal binary mask在訓練的時候,因為有光處理,在訓練的時候,我們確實可以為這些mixed audio根據原來的光處理產生出這種ideal的binary mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:10.400" id=34:10.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2050">34:10.400</a></div>
        <div class="t">那接下來這個ideal的binary mask就是我們訓練的目標,就是我們learning的target,我們期待訓練一個mask generation,它可以產生這種ideal binary mask,不根據光處理,根據mixed audio產生ideal binary mask,可以拿來跟原來的input做點層,就可以做到soul separation這件事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:30.760" id=34:30.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2070">34:30.760</a></div>
        <div class="t">這個是mask generation,但是就算有了mask generation,我們其實也並沒有真的解決我們剛才提到的permutation的issue,因為我們現在還是有兩個光處理,還是有兩個正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:49.860" id=34:49.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2089">34:49.860</a></div>
        <div class="t">但是這兩個正確答案,你會發現說它們是非常有關係的,其實你知道其中一個正確答案,你就知道另外一個正確答案,其中一個地方是0,另外一個地方就是1,它們在對應的位置,其中一個是1,另外一個就是0,所以你知道其中一個,就知道另外一個。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:12.400" id=35:12.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2112">35:12.400</a></div>
        <div class="t">Deep clustering是怎麼運作的呢?我們先講它在influence的時候是怎麼做的,然後再講在training的時候應該怎麼訓練這樣子的一個network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:24.760" id=35:24.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2124">35:24.760</a></div>
        <div class="t">Deep clustering的本體是一個embedding的generation,那你說不是在講mask的generation嗎?怎麼突然講到embedding的generation?等一下會講說怎麼從embedding generation的結果產生出mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:39.280" id=35:39.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2139">35:39.280</a></div>
        <div class="t">我們先講embedding的generation。embedding的generation是這樣的,我們吃一段聲音訊號,這個是mixed audio當作輸入,它的長度是t,那它的高度是d,那如果你知道什麼是spectrogram的話,那這個就是frequency,這個就是time,這個就是frequency,那你不知道什麼是spectrogram的話,反正就是一個矩陣就是了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:00.000" id=36:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2160">36:00.000</a></div>
        <div class="t">這個矩陣輸入embedding的generation以後,它會變成一個立方體,這個立方體的長跟寬跟原來輸入的matrix是一樣的,但是它有了一個高,這個高的dimension,我們用大A來表示。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:19.480" id=36:19.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2179">36:19.480</a></div>
        <div class="t">比如說這邊的每一個grid,每一個格子本來是只有一個數值,但我們現在要把每一個格子擴張成一個向量,那實際上在這個embedding的generation裡面,它可能就是考慮這個格子裡面的數值跟這個格子周圍的數值,因為只看一個數值沒辦法變成一個向量,你看一個數值跟它周圍的數值合起來,一起把它變成一個向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:49.480" id=36:49.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2209">36:49.480</a></div>
        <div class="t">所以,現在每一個grid、每一個格子都用一個向量來表示以後,接下來你對這些向量做k-means的clustering,我假設大家是知道了,這個在Machinery的時候講過了,k-means的clustering把這些向量分成兩群,k-means的clustering就是自動把向量分成兩群的技術,那它用的原則就是比較像的向量、比較接近的向量就聚集在一起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:16.840" id=37:16.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2236">37:16.840</a></div>
        <div class="t">那k-means的clustering的cluster的數目,就是要有幾個cluster,通常需要事先訂好,那我們這邊就假設說我們要有k個cluster,那這邊的大k就是speaker的數目,如果你今天有兩個speaker,那你就是產生兩個cluster,如果你有三個speaker,你就會產生三個cluster。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:38.600" id=37:38.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2258">37:38.600</a></div>
        <div class="t">那我們在這門課裡面,我說我們都只做兩個speaker的case,所以我們k-means的clustering的時候就把這些向量分成兩群,那這邊標1的代表他們被分到一群,這邊標2的代表他們被分到另外一群。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:54.760" id=37:54.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2274">37:54.760</a></div>
        <div class="t">然後接下來根據這個分群的結果,你就可以產生binary的mask,根據分群的結果產生binary的mask。如果今天分在同一群的人,就有同樣的數字,今天這些紅色的點都分在第一群,那就產生一個mask,只有分在第一群的人的數字是1,分在另外一群的人都是0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:17.880" id=38:17.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2297">38:17.880</a></div>
        <div class="t">黃色這一點分在第二群,那就產生第二個mask,只有分在第二群的人數是1,其他都是0。那如果k比2還要大,也是以此類推,用同樣的方法,如果k等於3,你就產生三個mask,有三群你就產生三個mask,兩群你就產生兩個mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:35.640" id=38:35.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2315">38:35.640</a></div>
        <div class="t">產生完mask以後,假設這些mask跟ideal的binary mask很接近的話,就結束了,你直接把這個mask跟輸入的matrix做點乘,你就可以把聲音訊號分成兩個人的聲音訊號,就可以把兩個人的聲音訊號分離出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:54.840" id=38:54.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2334">38:54.840</a></div>
        <div class="t">這個是deep clustering的操作,那訓練的時候怎麼辦呢?在這個deep clustering裡面,k-means是一個algorithm,這個algorithm它是沒有辦法train的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:09.880" id=39:09.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2349">39:09.880</a></div>
        <div class="t">其實deep clustering後來有一個進階的版本,它想辦法讓k-means clustering也有辦法train,但這邊我們就不講這個,你可以自己再詳細讀一下文獻。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:20.280" id=39:20.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2360">39:20.280</a></div>
        <div class="t">k-means clustering一般認知裡面就沒有辦法train的東西,它是一個固定的algorithm,你就把這些vector帶到這個algorithm裡面,自動輸出就是分群。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:29.800" id=39:29.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2369">39:29.800</a></div>
        <div class="t">你能train的是什麼?你能train的是embedding的generation。那我們要怎麼train這個embedding的generation呢?我們要怎麼train一個network,把這邊的grid都變成這邊的vector呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:42.680" id=39:42.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2382">39:42.680</a></div>
        <div class="t">deep clustering在training的時候是這個樣子,因為我們在training的時候,我們可以為mixed的聲音訊號找出它的ideal binary mask,按照我們剛才講的非常簡單的一個algorithm,就可以找出ideal的binary mask。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:59.240" id=39:59.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2399">39:59.240</a></div>
        <div class="t">假設找出ideal binary mask以後,我們發現說第一排的第二個值跟第三個值是不一樣的,它們屬於不同的speaker,也就代表說現在在這個mixed的聲音訊號裡面,第一排的第二個格子跟第三個格子屬於不同的speaker。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:21.300" id=40:21.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2421">40:21.300</a></div>
        <div class="t">那你在train這個embedding generation的時候,你就希望說你的訓練的目標是要把這兩個格子所對應的向量,把它們拉遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:33.640" id=40:33.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2433">40:33.640</a></div>
        <div class="t">把它們拉遠以後,在做完k-means clustering以後,這兩個向量就會屬於不同的cluster,這兩個向量屬於不同的cluster,在產生這兩個ideal binary mask的時候,這兩個值就會是不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:49.140" id=40:49.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2449">40:49.140</a></div>
        <div class="t">同理,假設你今天做完ideal binary mask以後,你發現第一排的第一個值跟第二個值、第一個值跟第二個值是一樣的,就代表說這兩個grid屬於同一個speaker,在train你的embedding generation的時候,你就希望這兩個vector越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:09.620" id=41:09.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2469">41:09.620</a></div>
        <div class="t">因為如果它們很接近的話,做完k-means clustering,它們就會被歸類為同一個cluster,那它們被歸類為同一個cluster的話,在產生ideal binary mask的時候,這兩個ideal binary mask就會這邊都是1,或者是這邊都是0,那你就可以把上面這兩個值歸給同一個speaker。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:33.180" id=41:33.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2493">41:33.180</a></div>
        <div class="t">那這個就是deep clustering training的精神。所以deep clustering它真正train的只有embedding的generation,後面這個k-means是沒有在train的,你只train這個embedding的generation。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:46.860" id=41:46.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2506">41:46.860</a></div>
        <div class="t">那embedding的generation,它train的目標是什麼呢?它train的目標就是,如果有兩個grid它們屬於不同的speaker,就把它們產生出來的vector拉遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:57.500" id=41:57.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2517">41:57.500</a></div>
        <div class="t">如果兩個grid是屬於同一個speaker,就把產生出來的vector拉近,這個就deep clustering在訓練這個embedding generation的時候的learning的target。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:08.380" id=42:08.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2528">42:08.380</a></div>
        <div class="t">那deep clustering它work不work呢?它是work的,而且還有一個神奇的地方是,如果你讀最原始的文獻,就已經發現說,如果我們今天training的時候只有兩個speaker,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:20.540" id=42:20.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2540">42:20.540</a></div>
        <div class="t">但是在testing的時候,你設三個speaker,你有三個speaker,居然也是work的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:27.980" id=42:27.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2547">42:27.980</a></div>
        <div class="t">也就是training的時候,你只說training的資料都只有兩個speaker,你只要同樣的speaker被拉近,你只需要產生的embedding,同樣的speaker被拉近,不同的speaker被拉遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:37.580" id=42:37.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2557">42:37.580</a></div>
        <div class="t">testing的時候有三個speaker,你只要把k-means的clustering設成3,你居然就可以做到三個speaker的source separation,這真的是非常的神奇。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:50.860" id=42:50.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2570">42:50.860</a></div>
        <div class="t">你可以想見說這個embedding generation,它是學到說,根據這個輸入的vector,它會看這每一個grid跟它周圍的鄰居,然後就抽取出可以代表這個grid它的speaker的特徵。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:04.700" id=43:04.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2584">43:04.700</a></div>
        <div class="t">所以它在兩個speaker的時候就已經學到說,每一個grid它所對應的speaker特徵應該是長什麼樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:10.700" id=43:10.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2590">43:10.700</a></div>
        <div class="t">就算只有三個speaker,它還是可以抽出每個speaker的特徵,所以k-means clustering的時候,你只要把k設成3,就可以把這些vector分成三群,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:19.380" id=43:19.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2599">43:19.380</a></div>
        <div class="t">你就可以產生三個ideal的binary mask,你就可以把input的聲音訊號分成三個語者的聲音訊號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:26.940" id=43:26.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2606">43:26.940</a></div>
        <div class="t">Deep clustering其實蠻穩的。我第一次看到Deep clustering的時候,我記得是在2017年的ASRU,那個時候在日本沖繩辦的conference。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:36.700" id=43:36.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2616">43:36.700</a></div>
        <div class="t">那個時候Merle他們就做了一個現場的demo。你知道這種source separation的技術,過去我很少有看過有人做現場的demo,語音做現場的demo實在太容易失敗了,所以很少有人做現場的demo。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:50.900" id=43:50.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2630">43:50.900</a></div>
        <div class="t">他們居然做的是現場的demo。他們說,台下隨便找兩個觀眾上來,應該是沒有事先套好的,隨便找兩個人上來,就讓他們同時念兩句話,隨便愛講什麼都可以。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:02.820" id=44:02.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2642">44:02.820</a></div>
        <div class="t">然後居然現場就把那兩個聲音訊號成功地做出source separation,是當時大家都覺得非常的驚人,所以Deep clustering這一招確實是work的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:16.360" id=44:16.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2656">44:16.360</a></div>
        <div class="t">但它有一個比較大的壞處,就是它沒有真的end-to-end。它中間有很多的process,有k-means的operation,有產生ideal binary mask這件事,ideal binary mask也不是完美的,所以它不是真的end-to-end,但是它是work。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:36.700" id=44:36.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2676">44:36.700</a></div>
        <div class="t">接下來我們就要講第二招,第二招叫做Permutation Invariant Training,它的縮寫叫做PIT。PIT應該最早是騰訊娛動的團隊所propose的方法,如果你用PIT這招,你就真的有辦法做到end-to-end的training。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:58.840" id=44:58.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2698">44:58.840</a></div>
        <div class="t">PIT這招是什麼意思呢?PIT這招它的基本的想法是說,如果我們有一個speaker separation的model,假設我們已經有了一個speaker separation的model,它的參數我們叫做θi。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:13.720" id=45:13.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2713">45:13.720</a></div>
        <div class="t">有了這個speaker separation model以後,其實我們就知道要怎麼安排我們的光束了。怎麼安排我們的光束呢?我們就說,如果把紅色的光束放在上面,藍色的光束放在下面,那我們可以算一個loss。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:29.720" id=45:29.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2729">45:29.720</a></div>
        <div class="t">把藍色的光束放在上面,紅色的光束放在下面,我們可以算一個loss。我們算出這兩個loss以後,算出這兩個狀況以後,再看看說誰的loss比較小。loss比較小的這種光束的排法,就代表它是一個比較好的光束,比較適合現在的model的光束。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:54.140" id=45:54.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2754">45:54.140</a></div>
        <div class="t">所以在有model的前提之下,你根據哪一種排法的loss比較小,你就可以決定哪一種排法比較適合現在的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:04.040" id=46:04.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2764">46:04.040</a></div>
        <div class="t">但問題就是,我們要知道某一種排法,我們才可以開始訓練model。這model不是憑空生出來的,要知道某一種排法才能開始訓練model,這就變成一個雞生蛋、蛋生雞的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:16.460" id=46:16.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2776">46:16.460</a></div>
        <div class="t">你有一個model,你可以知道要怎麼排,但是你要先知道怎麼排,你才能訓練一個model。所以怎麼解這個問題呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:25.840" id=46:25.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2785">46:25.840</a></div>
        <div class="t">PAT的想法就直覺上其實也蠻單純的,而且在實作上,它是可以work的,沒有問題,它是真的可以收斂的。它是怎麼做的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:36.280" id=46:36.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2796">46:36.280</a></div>
        <div class="t">你一開始先有random的assignment,就不要想那麼多,隨便要紅色牌上面也可以,藍色牌上面也可以,隨機安排。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:47.020" id=46:47.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2807">46:47.020</a></div>
        <div class="t">然後train一下你的network,update一下它的參數。那你update完你的參數以後,你就有一個network了,然後用這個network去決定你的正確答案要怎麼安排。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:59.960" id=46:59.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2819">46:59.960</a></div>
        <div class="t">怎麼樣安排正確答案,可以讓loss算出來最小。安排好正確答案以後,再去訓練你的network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:07.080" id=47:07.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2827">47:07.080</a></div>
        <div class="t">訓練一下以後,你有一個新的network,那答案的安排就不一樣了。你有一個新的network,要怎麼安排答案就變得不一樣了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:15.600" id=47:15.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2835">47:15.600</a></div>
        <div class="t">你有新的network,就再安排一次答案,然後再訓練network,再重新安排答案,再訓練一次network。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:21.560" id=47:21.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2841">47:21.560</a></div>
        <div class="t">這兩件事情就這樣往復地不斷地循環,直到它收斂為止。這一招雖然聽起來沒有很複雜,但是它是work的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:33.960" id=47:33.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2853">47:33.960</a></div>
        <div class="t">有人可能會問說,在訓練初始的期間,因為我們的正確答案的排法,正確答案的放法是隨機的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:47.440" id=47:47.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2867">47:47.440</a></div>
        <div class="t">所以今天在訓練初始的過程中,你的assignment可能會不斷地變換,因為你的network參數不斷地改變,所以你的assignment會不斷地變換。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:58.480" id=47:58.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2878">47:58.480</a></div>
        <div class="t">對,沒錯。在訓練初始的時候,assignment會不斷地變換,不過它慢慢地就會收斂下來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:05.880" id=48:05.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2885">48:05.880</a></div>
        <div class="t">這是我們實驗室做的一個真正的實驗結果。藍色這條線是SISDR的improvement。這個improvement就是隨著訓練的APOC,它的結果慢慢變好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:23.880" id=48:23.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2903">48:23.880</a></div>
        <div class="t">那黑色這條線是什麼呢?黑色這條線就是這一次的assignment跟上一次的assignment不同的比例。所以你會發現說,在訓練的初始期間,因為最開始的assignment是隨機的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:39.720" id=48:39.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2919">48:39.720</a></div>
        <div class="t">所以最開始在訓練的初始的時候,你的assignment是會劇烈地變化,因為你的model不知道說要怎麼擺放這些ground truth比較好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:49.720" id=48:49.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2929">48:49.720</a></div>
        <div class="t">但是慢慢地變化的次數就會越來越少,最後就找到一種合適的擺放方法,然後整個訓練的過程就收斂下來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:59.840" id=48:59.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2939">48:59.840</a></div>
        <div class="t">在前期的時候,擺放會不斷地改變。你每次訓練完model以後,你都要重新看一下要怎麼做assignment,所以你的擺放方法會不斷地改變。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:10.400" id=49:10.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2950">49:10.400</a></div>
        <div class="t">前期可能是因為這個擺放的方法不斷改變,所以訓練就比較不穩。你會發現說,這個SDRI這個數值就是上下跳動,它有點上下的跳動,不過最終就收斂下來了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:24.000" id=49:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2964">49:24.000</a></div>
        <div class="t">這邊是另外一個實驗結果。這個實驗結果想要跟大家分享的是,確實PIT還蠻有用的,是需要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:31.580" id=49:31.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2971">49:31.580</a></div>
        <div class="t">如果你今天只是用一些你自己發明的方法來做assignment,來決定ground truth要怎麼擺的話,不見得能得到好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:40.500" id=49:40.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2980">49:40.500</a></div>
        <div class="t">舉例來說,A這條線是用energy來擺放你的ground truth。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:46.300" id=49:46.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2986">49:46.300</a></div>
        <div class="t">你今天看你的mix的audio裡面,哪一個energy比較大?大的那個放上面,小的那個放下面,訓練下去,結果沒有很好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:55.300" id=49:55.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=2995">49:55.300</a></div>
        <div class="t">如果今天你說,我們用speaker的特性來分好不好?用speaker的特性來分真的是一種很直覺的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:02.680" id=50:02.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3002">50:02.680</a></div>
        <div class="t">我們這邊是用speaker embedding來分,用d-vector來分,很直覺你也可以想說,聲音比較高的分音類,聲音比較低的分音類。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:14.060" id=50:14.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3014">50:14.060</a></div>
        <div class="t">反正我們這邊是用learn的,我們把speaker用d-vector,代表這個speaker特徵的向量,把它cluster成兩群,一群放上面,一群固定放下面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:27.260" id=50:27.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3027">50:27.260</a></div>
        <div class="t">訓練下去以後,結果行不行呢?比剛才用energy好。但是如果你用PIT的話,結果會更好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:36.260" id=50:36.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3036">50:36.260</a></div>
        <div class="t">所以用PIT是贏過按照speaker特性分跟按照energy分的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:43.240" id=50:43.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3043">50:43.240</a></div>
        <div class="t">我們發現一個有趣的現象是說,因為在PIT訓練的初始的時候,你不知道你的assignment應該是怎麼樣,你都很關注應該要怎麼擺,所以在訓練初始的時候是不太穩定的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:56.500" id=50:56.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3056">50:56.500</a></div>
        <div class="t">也許因為你的擺法最終不夠好,沒有收斂到一個最好的結果,所以你可以有一個新的做法是說,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:04.580" id=51:04.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3064">51:04.580</a></div>
        <div class="t">我們先用PIT訓練一次,把PIT得到的最終的正確答案的擺放方法就當作正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:15.260" id=51:15.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3075">51:15.260</a></div>
        <div class="t">你說我們之前不知道要誰放上面誰放下面,那PIT訓練一次以後,它就幫我們決定好了,它是data-driven的,network自己決定說誰要擺上面誰要擺下面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:26.920" id=51:26.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3086">51:26.920</a></div>
        <div class="t">用PIT跑過一次以後,我們就決定了assignment,再從頭去訓練一個network,我們訓練一個全新的network,但是用PIT的assignment當作我們的正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#51:36.780" id=51:36.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=tovg5ZxNgIo&t=3096">51:36.780</a></div>
        <div class="t">我們假設用PIT這種方法,可以透過data-driven的方法告訴我們說怎麼樣擺放才是對的,用PIT這個方法,我們就可以得到一個assignment,得到一種正確答案的擺法,再重新從頭訓練一個network,你可以得到更好的SDR的分數。</div>
    </div>
    
</body>
</html>   