<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>【機器學習2021】元學習 Meta Learning (二) - 萬物皆可 Meta</h2><a href=https://www.youtube.com/watch?v=Q68Eh-wm1Ts><img src=https://i.ytimg.com/vi/Q68Eh-wm1Ts/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AG-B4AC0AWKAgwIABABGGUgXyhXMA8=&rs=AOn4CLCFI4qoeEGgD3zF9aw_cVQRCQR0zg></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=0">00:00.000</a></div>
        <div class="t">好,那我們已經講完了meta learning的基本概念,那接下來就是舉一些實例告訴你說在meta learning裡面,什麼東西是可以被學的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:15.500" id=00:15.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=15">00:15.500</a></div>
        <div class="t">好,那我們一般最常用的learning的algorithm,其實今天就是gradient descent,你知道說在gradient descent裡面,我們就是要有一個network的架構,然後你初始化一下你的參數,我們把這個初始化的參數叫做θ0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:33.500" id=00:33.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=33">00:33.500</a></div>
        <div class="t">然後呢,你要有一些訓練資料,那你通常是從訓練資料裡面sample一個batch出來,對不對?我們第一堂課就跟大家講過batch,sample一個batch出來,計算gradient,然後用這個gradient來update你的參數,所以從θ0變成θπ,然後再重新計算一次gradient,再update參數,然後就反覆這樣下去,直到次數夠多,你滿意為止,那就把最終訓練的結果,最終得到的參數,把它輸出出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:03.000" id=01:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=63">01:03.000</a></div>
        <div class="t">好,那在這整個過程中,哪些東西是可以train的呢?首先,initialized的參數是可以train的,所以θ0是可以train的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:17.000" id=01:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=77">01:17.000</a></div>
        <div class="t">怎麼說呢?一般我們θ0,你就是random initialized的嘛,從某一個固定的distribution裡面sample出來的嘛,但是你也知道說,θ0對結果往往有一定程度的影響,好的初始化參數、不好的初始化參數可以天差地遠,那我們能不能夠透過一些訓練的任務來找出一個對訓練就是特別有幫助的initial的參數呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:45.000" id=01:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=105">01:45.000</a></div>
        <div class="t">可以,這個方法就是我覺得在meta-learning這一系列work裡面可能大家最耳熟能詳的model-agnostic meta-learning,它的縮寫叫memo,它的發音就跟哺乳類動物有點像。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:02.000" id=02:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=122">02:02.000</a></div>
        <div class="t">那有另外一個memo的變形就叫做reptile,那我覺得不知道是不是故意的它把這個名字取成reptile,reptile就是爬蟲類的意思。那這些方法的細節,那因為時間有限的關係,所以我們今天就都不細講,我只是把一些reference列在這個投影片上給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:23.000" id=02:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=143">02:23.000</a></div>
        <div class="t">但是在作業裡面,這個我們會問很多跟meta-learning跟memo有關的問題,所以假設你想知道更多有關memo的細節,你在作業裡面可以學到更多跟memo有關的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:39.000" id=02:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=159">02:39.000</a></div>
        <div class="t">所以有一系列的方法,它就是learning to initialize,它去learn這些initialize的參數,其中最有代表性的就是memo。但是就像我們剛才講說做meta-learning的時候,你也有hyperparameter是你需要調的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:56.000" id=02:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=176">02:56.000</a></div>
        <div class="t">所以做memo的時候,雖然你要去learn一個initialized parameter,但是learn這個initialized parameter的過程中,也是有很多hyperparameter你需要自己決定的。所以實際上,最原版的memo並沒有非常好train。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:13.000" id=03:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=193">03:13.000</a></div>
        <div class="t">有一篇paper叫做How to Train Your Memo,這個也是一個玩意兒梗,有一個動畫叫How to Train Your Dragon,它就把dragon改成memo。所以這篇paper的title叫How to Train Your Memo,它就說它試著train了memo三次,也用不同的random c。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:31.000" id=03:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=211">03:31.000</a></div>
        <div class="t">你知道,train initial parameter這件事,它也需要random c,你也需要做gradient descent。如果你對這些有困惑的話,在作業裡面你可以更詳細的知道memo,train裡面的細節。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:46.000" id=03:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=226">03:46.000</a></div>
        <div class="t">在作業裡面有memo的範例的程式,你看了那些程式以後,可能可以讓你對memo有更進一步的了解。所以train memo也是要調參數的,也是需要random c的,所以它試了三個不同的random c,發現紅色這三條線有時候train得起來,有時候train不起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:07.000" id=04:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=247">04:07.000</a></div>
        <div class="t">所以在這篇paper裡面,它就提出了一個新的方法,叫做memo++,期待說memo++可以做起來。有關更多memo++的細節,大家在自己去讀How to Train Your Memo這篇文章。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:20.000" id=04:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=260">04:20.000</a></div>
        <div class="t">講到memo,講到找一個好的initialization,有沒有讓你想到課程的另外一個主題呢?在課程的另外一個主題講self-supervised learning的時候,我們是不是也有提到好的initialization這件事情呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:38.000" id=04:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=278">04:38.000</a></div>
        <div class="t">在memo裡面,我們有一堆訓練的任務,每個任務裡面有訓練資料跟測試資料,我們有一堆訓練的任務,根據這些訓練的任務找出一個好的initialization,然後用在測試的任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:52.000" id=04:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=292">04:52.000</a></div>
        <div class="t">但是在self-supervised learning裡面,我們是怎麼做的呢?在self-supervised learning裡面,我們就是有一大堆的沒有標記的資料,這些沒有標記的資料我們可以用一些proxy的task去訓練它,比如說在BERT裡面,就是用填空題來訓練你的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:12.000" id=05:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=312">05:12.000</a></div>
        <div class="t">那其實在影像上,你可以做self-supervised learning,你也可以說把影像的其中一塊蓋起來,叫機器必須預測被蓋起來的一塊。那今天在做影像的self-supervised learning的時候,可能這個masking的這種方法,填空的方法不是最常用的,今天比較流行用另外一個系列,我們在這個課程裡面沒有介紹的contrastive learning的方法,那這個有興趣,大家再自己去研究。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:36.000" id=05:36.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=336">05:36.000</a></div>
        <div class="t">那總之講到好的initialization這件事,是不是讓你想到self-supervised learning呢?在self-supervised learning裡面,我們會先拿一大堆的資料去做pre-training,那pre-training的結果,我們也說它是好的initialization,那把這些好的initialization一樣可以用在測試的任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:58.000" id=05:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=358">05:58.000</a></div>
        <div class="t">那這兩者有什麼不同呢?當然如果我們直接比較memo跟今日的self-supervised learning的話,那至少最明顯的不同是memo這些任務是有用到標準資料的,而在self-supervised learning裡面,我們是沒有用到標準資料的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:17.000" id=06:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=377">06:17.000</a></div>
        <div class="t">所以pre-training這一招,self-supervised learning這一招雖然會好,但是你不知道為什麼會好,我們其實今天並沒有非常清楚說為什麼這些proxy的任務對testing的task會有幫助,而對memo而言,它會好似乎是理所當然的,我們在這些訓練任務上找出一組好的initializer參數,在這些訓練任務上都有好的結果,也許它就可以transfer到testing的任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:43.000" id=06:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=403">06:43.000</a></div>
        <div class="t">但是如果你回到幾年前,在還沒有self-supervised learning這個詞彙的時候,你知道self-supervised learning這個詞彙會爆紅起來,也是Yamlack在2019年4月的時候說的,我記得好像是4月30日之類的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:00.000" id=07:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=420">07:00.000</a></div>
        <div class="t">其實在我的YouTube頻道上第一次講memo的時候,其實是4月30日之前的,那個時候我們都還不太清楚self-supervised learning這個詞彙。 self-supervised learning這個詞彙當然在Yamlack講說self-supervised learning很厲害之前,其實也有人用過這個詞彙啦,只是之前如果你隨便發明這些怪怪的詞彙的話,你可能就被別人抨擊嘛,不過大神講說有一個技術叫self-supervised learning,那就有了self-supervised learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:27.000" id=07:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=447">07:27.000</a></div>
        <div class="t">總之,過去在self-supervised learning這個系列還不紅的時候,那個時候pre-training有另外一種想法,比較常見的做法是,你一樣有好幾個任務的資料,你把這些好幾個任務的資料通通都倒在一起,把它當作一個任務進行訓練。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:46.000" id=07:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=466">07:46.000</a></div>
        <div class="t">然後接下來呢,你一樣可以找一組好的initialization,一樣可以把它用在測試的任務上。那像這樣子把好多的任務的資料通通倒在一起,當作一個任務來訓練的做法,這個叫做multitask training。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:01.000" id=08:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=481">08:01.000</a></div>
        <div class="t">那其實今天一般你在做memo的研究的時候,你通常會把這種multitask training的方法來當作meta learning的baseline。為什麼會把這樣的multitask learning當作memo的baseline呢?因為仔細想想你會發現說,這兩個方法他們用的資料都是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:21.000" id=08:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=501">08:21.000</a></div>
        <div class="t">一邊只是我們會把不同的task分開,另外一邊把所有的task的資料倒在一起。那這兩種方法有什麼樣的差別呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:32.000" id=08:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=512">08:32.000</a></div>
        <div class="t">假設你想要知道更多meta learning、memo跟pre-training的差別的話,你可以看一下這個影片。我今天特別要強調這個影片,這樣請大家務必要看,是因為這個影片裡面它是有防不勝防的業配的啦。那我現在要特別業配這個影片,這個就是業配的業配,就是meta業配。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:56.000" id=08:56.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=536">08:56.000</a></div>
        <div class="t">在這一頁投影片,你會發現說我們這邊的訓練的任務跟測試的任務差距並沒有很大。在剛才的舉例裡面,我都說訓練的任務是分類蘋果跟橘子、分類車子跟腳踏車。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:14.000" id=09:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=554">09:14.000</a></div>
        <div class="t">但是在今天這個例子,在這一頁投影片的例子上,我特別舉了一個例子是說,每一個訓練的任務都是要分類貓跟狗。只是現在每一個任務裡面的圖片,它的類型是不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:28.000" id=09:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=568">09:28.000</a></div>
        <div class="t">在任務一裡面是真實的圖片,在任務二裡面是油畫的圖片,在任務三裡面是卡,在測試任務裡面是卡通的圖片。那你可能會說,這個不就是domain adaptation嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:44.000" id=09:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=584">09:44.000</a></div>
        <div class="t">我們在某些任務上面學到的東西,在某一些domain上學到的東西,要被transfer到另外一個domain。沒錯,你也可以說它就是domain adaptation。所以,假設我們今天在做meta learning的時候,我們的不同的任務其實就只是不同的domain而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:05.000" id=10:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=605">10:05.000</a></div>
        <div class="t">但是你也可以說meta learning就是一種domain adaptation的方法。其實在machine learning裡面,這個task跟domain的定義,它們的分野並沒有那麼明確。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:19.000" id=10:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=619">10:19.000</a></div>
        <div class="t">我可以說這個是不同的domain,但我也可以說它們就是不同的任務,其實都是可以的。所以,假設你今天不同的任務其實就是不同的domain上的同樣的分類問題的話,你也可以說meta learning是一種解domain adaptation的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:37.000" id=10:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=637">10:37.000</a></div>
        <div class="t">總之,我覺得在machine learning這個領域裡面,有千千萬萬的新詞彙不斷地被發明出來。我覺得大家在研讀這些文獻的時候,其實也不用太拘泥於這些詞彙。你真正要在意的是,這些詞彙背後所代表的含義是什麼。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:58.000" id=10:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=658">10:58.000</a></div>
        <div class="t">那memo到底為什麼會好呢?有兩個不同的假設。有一個假設是,memo找出來的那個initial的參數,它是一個很厲害的initial的參數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:11.000" id=11:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=671">11:11.000</a></div>
        <div class="t">這個很厲害的initial的參數,它可以讓我們的比如說gradient descent這種learning的algorithm快速地找到每一個任務上好的參數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:21.000" id=11:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=681">11:21.000</a></div>
        <div class="t">那另外一個假設是說,這個initialized的參數,它本來就跟每一個任務上最終好的結果已經非常接近了。那所以,因為它已經跟好的結果非常接近,所以你直接apply gradient descent就可以輕易地找到好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:37.000" id=11:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=697">11:37.000</a></div>
        <div class="t">到底是哪一個呢?有一篇paper它裡面提出來的一個方法叫做,有一篇paper它的title是rapid learning or feature reuse,左邊這個叫做rapid learning,右邊這個叫做feature reuse。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:51.000" id=11:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=711">11:51.000</a></div>
        <div class="t">那到底memo它的好,是好在左邊這個理由還是右邊這個理由呢?那你可以自己去看一下paper,會發現說,在paper裡面得到的結論是feature reuse才是memo好的關鍵。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:06.000" id=12:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=726">12:06.000</a></div>
        <div class="t">那在這一篇paper裡面呢,同時提出來了另外一種memo的變形叫做annual。那在我們的作業裡面,也會問大家一些跟annual相關的問題。annual是almost no inner loop的縮寫,almost no inner loop它的縮寫是annual。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:22.000" id=12:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=742">12:22.000</a></div>
        <div class="t">那meta learning有非常多的變形啦,假設你想要知道更多背後的數學的細節的話,你可以參考這支影片。那memo有一個可以大幅減化運算的變形叫做first-order memo,f-memo,那你可以看這支影片。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:38.000" id=12:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=758">12:38.000</a></div>
        <div class="t">那如果你想知道什麼是reptile的話,你可以看這支影片。那我們上課就不再講,我們把這些內容留在這個作業的選擇題裡面,讓大家慢慢來學習。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:52.000" id=12:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=772">12:52.000</a></div>
        <div class="t">好,剛才講說我們可以學習初始化的參數,那還有什麼東西是可以學習的呢?我們可以學optimizer。你知道在update參數的時候啊,我們需要決定比如說learning rate啊,momentum啊等等參數等等hyperparameter。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:14.000" id=13:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=794">13:14.000</a></div>
        <div class="t">而像learning rate這種hyperparameter,能不能夠用學習的方法把它用meta learning學習出來呢?是可以的。那像這樣子的想法啊,在很早以前就有了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:26.000" id=13:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=806">13:26.000</a></div>
        <div class="t">NIPS 2016就有一篇paper,它的title叫learning to learn by gradient descent。這個不是title啊,它的名字真的就叫做learning to learn by gradient descent。這個大家都是命名大師啊,大家都很會取這個有梗的title。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:44.000" id=13:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=824">13:44.000</a></div>
        <div class="t">而在這篇paper裡面呢,它就直接認了那個optimizer,一般我們的optimizer什麼addon啊,rnsprop啊,是人想出來的。它的optimizer裡面的參數是自動根據訓練的任務學出來的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:00.000" id=14:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=840">14:00.000</a></div>
        <div class="t">那它那邊,它把它的方法呢,就直接叫做LSTM啦,因為它把訓練那個optimizer裡面的這些參數這件事情把它類比到訓練一個LSTM上。那我們這堂課裡面沒有講過LSTM嘛,所以你不知道LSTM是什麼也沒關係,反正這個就是認出來的optimizer。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:19.000" id=14:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=859">14:19.000</a></div>
        <div class="t">那它做的第一組實驗呢,是訓練在adnist上,然後直接測試在adnist上啦,那所以得到的結果呢,當然是挺不錯的。橙色這一個呢,是認出來的optimizer,其他顏色的這個curve呢,是其他的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:35.000" id=14:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=875">14:35.000</a></div>
        <div class="t">但是如果我們是訓練在adnist上,測試在adnist上,而且network架構都一樣,這根本就是cheating嘛,這樣代表你的訓練任務跟測試任務根本就是一模一樣嘛,這樣沒有什麼特別厲害的。但是早在2016年,這篇文章就已經知道說,訓練任務跟測試任務應該要不一樣試試看。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:55.000" id=14:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=895">14:55.000</a></div>
        <div class="t">所以他就試了說,他的訓練任務是一層的network,40個unit,然後呢,結果不錯。那測試任務呢,測試任務改成兩層,看看到底能不能夠做得起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:08.000" id=15:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=908">15:08.000</a></div>
        <div class="t">訓練任務是一層的network啦,他測試的時候測試在兩層的network上,可不可以做得起來?可以。但他發現說呢,改一下那個activation function就不work了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:17.000" id=15:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=917">15:17.000</a></div>
        <div class="t">訓練的時候,如果沒記錯的話,應該是用sigmoid,但是測試的時候,network架構裡面改成relu,哇,這個learn出來的optimizer就壞掉了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:28.000" id=15:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=928">15:28.000</a></div>
        <div class="t">不過這篇文章當時就已經有訓練任務跟測試任務的概念了,只是他的訓練任務其實只有一個而已。好,剛才講了我們可以訓練初始化的參數,可以訓練optimizer。那能不能夠訓練network架構呢?當然可以訓練network架構。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:47.000" id=15:47.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=947">15:47.000</a></div>
        <div class="t">那在訓練network架構這系列的研究呢,就叫做network,其實就是鼎鼎大名的network architecture search,其實就是NAS。我知道很多同學應該都聽過network architecture search這個技術,只是你不太清楚它跟meta learning的關係是什麼而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:04.000" id=16:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=964">16:04.000</a></div>
        <div class="t">如果你今天在meta learning裡面,你認的就是network的架構,fine,你把network的架構當作fine的話,那我們就是在做NAS。好,但是在NAS裡面,我們的fine是network架構,我們要找一個fine去minimize L的fine。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:22.000" id=16:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=982">16:22.000</a></div>
        <div class="t">但既然fine是network架構,顯然做微分就有問題了,顯然算gradient就有問題了,怎麼辦?記得我們這門課裡面反覆強調的,當你遇到optimization的問題沒辦法算微分的時候,reinforcement learning應作也許是一個solution。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:40.000" id=16:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1000">16:40.000</a></div>
        <div class="t">怎麼用reinforcement learning應作呢?你就把fine想成是一個agent的參數,然後這個agent,這個reinforcement learning裡面的agent,它的output是什麼?它的output就是network架構相關的hyperparameter。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:58.000" id=16:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1018">16:58.000</a></div>
        <div class="t">舉例來說,它會output的就是現在第一層,你的比如說filter,它的長是多少,它的寬是多少,它的stripe多少,filter的數目是多少等等,今天你的agent它的output就是network的架構相關的參數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:14.000" id=17:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1034">17:14.000</a></div>
        <div class="t">然後接下來呢,你就是要訓練你的agent,讓它去maximize一個reward,那在這邊我們的reward是什麼呢?我們的reward直接設成l.fine成一個負號,所以我們訓練這個agent去maximize l.fine成一個負號,就等於是minimize l.fine。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:32.000" id=17:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1052">17:32.000</a></div>
        <div class="t">我們用RL的演算法直接去訓練這個fine,去minimize l.fine,那我們就是做了network architecture的search。好,那這邊是有一個從文件上截下來的圖,希望可以讓你更清楚知道說這個typical的NAS是在做什麼的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:48.000" id=17:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1068">17:48.000</a></div>
        <div class="t">就是我們有一個agent,那這個是比較早的work,所以那個時候把agent想成就是一個recurrent的network,那這個recurrent的network每次會輸出一個跟network架構有關的參數,比如說它會先輸出filter的高是多少,然後再輸出filter的寬是多少,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:10.000" id=18:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1090">18:10.000</a></div>
        <div class="t">然後再輸出stride的橫向的stride是多少,再輸出縱向的stride是多少,再輸出要有多少的filter等等,然後第n層輸出完以後,接下來再輸出n加1層,接下來再輸出n加2層,以此類推。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:27.000" id=18:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1107">18:27.000</a></div>
        <div class="t">好,那有了這些參數以後就根據這些參數建出一個network,建完network以後就去train這個network,這個train network的過程其實就是within task的training。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:40.000" id=18:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1120">18:40.000</a></div>
        <div class="t">好,然後接下來就去做reinforcement learning,你可能會把這一個network它在測試資料上面的accuracy當作你的reward,然後來訓練你的agent,那訓練這個agent去maximize reward的過程其實就是across task training。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:59.000" id=18:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1139">18:59.000</a></div>
        <div class="t">那我知道說在network architecture search的文獻上其實不常提到什麼within task training跟across task training這樣子的講法啦,但是其實你想想看network architecture search它可以視為是meta learning的其中一個技術,只是我們現在要learn的是集中在,只是我們現在要學習的目標是network architecture。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:19.000" id=19:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1159">19:19.000</a></div>
        <div class="t">那我知道說比較早的network architecture search那些paper啊,他們往往訓練的任務跟測試的任務就是同一個,比如說你訓練的時候你是要訓練一個agent,他可以找一個network,這個network在cypher 10上做得好,那測試的時候你也是直接跑在cypher 10上,那你的訓練任務跟測試任務是同一個嘛,感覺有點cheating。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:40.000" id=19:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1180">19:40.000</a></div>
        <div class="t">不過近年來有很多network architecture search的文章都已經進步到,都已經有所改變,他們的training的任務跟測試的任務都已經有人嘗試過,可以是不一樣的了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:52.000" id=19:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1192">19:52.000</a></div>
        <div class="t">好,那除了這個reinforcement learning以外,你要用evolutionary的algorithm也是可以的,我們這邊就直接列一些文獻給大家參考。那其實啊,你硬要把network architecture改一下,讓它變得可以微分也是可以的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:11.000" id=20:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1211">20:11.000</a></div>
        <div class="t">有一個經典的做法呢,叫做darts,它的縮寫就是differentiable architecture search,它是differential architecture search的縮寫,這個darts呢,它就是想辦法讓這個問題變得是可以微分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:25.000" id=20:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1225">20:25.000</a></div>
        <div class="t">你就可以直接用gradient descent來minimize這個L0,那至於darts的細節就留給大家自己慢慢研究。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:33.000" id=20:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1233">20:33.000</a></div>
        <div class="t">好,除了network architecture以外,還有什麼可以learn的呢?data processing,也有可能可以learn。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:41.000" id=20:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1241">20:41.000</a></div>
        <div class="t">大家知道說,我們在訓練network的時候,你不是都要做data augmentation嗎?作業三還讓大家自己嘗試各種不同的data augmentation的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:51.000" id=20:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1251">20:51.000</a></div>
        <div class="t">那當然data augmentation的方法,現在你是用trial and error去試出來的,那能不能夠硬去學data augmentation這些事呢?能不能夠讓machine訓練出怎麼自動找data augmentation呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:05.000" id=21:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1265">21:05.000</a></div>
        <div class="t">是可以的,那我們就列一些paper在這邊給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:10.000" id=21:10.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1270">21:10.000</a></div>
        <div class="t">好,那我們知道說現在training的時候,有時候你會需要給不同的sample不同的weight,但是要怎麼給每一筆data不同的權重呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:21.000" id=21:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1281">21:21.000</a></div>
        <div class="t">這邊就有不同的策略,那有的人的策略是說,如果有一些example距離boundary特別近,它是特別難的example,也許就要給它比較大的weight,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:31.000" id=21:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1291">21:31.000</a></div>
        <div class="t">讓network比較focus在看這些比較難的example學習,希望它可以學得比較好。但是你也會看到文獻有相反的結論說,這個比較noisy的這些label應該給它比較小的weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:44.000" id=21:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1304">21:44.000</a></div>
        <div class="t">這些example如果它比較接近boundary,可能代表它比較noisy,代表它比較困難,它的難可能是不合理的,因為代表它的label搞不好根本就標錯了,也許你應該給它比較小的weight。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:55.000" id=21:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1315">21:55.000</a></div>
        <div class="t">那怎麼決定這個sample weight的strategy呢?你可以用learn的把sample weight的strategy直接learn出來,然後讓文獻可以學到說,根據data的特性,自動決定說sample的weight要怎麼設計。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:12.000" id=22:12.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1332">22:12.000</a></div>
        <div class="t">到目前為止,我們看到的這些方法都是基於gradient descent再去做改進,我們剛才看到的所有方法都是learn了gradient descent的其中一個component。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:27.000" id=22:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1347">22:27.000</a></div>
        <div class="t">但是我們有沒有可能完全捨棄掉gradient descent呢?我們有沒有可能直接learn一個network,這個network的參數就是fine,這個network直接吃訓練資料作為輸入,直接輸出訓練好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:42.000" id=22:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1362">22:42.000</a></div>
        <div class="t">如果真的有這樣一個network,它可以吃訓練資料作為輸入,輸出訓練好的network的參數,那我們就可以說我們甚至讓機器發明了新的learning algorithm,我們已經拋棄了gradient descent,機器發明新的learning algorithm。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:00.000" id=23:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1380">23:00.000</a></div>
        <div class="t">有沒有可能做到這件事呢?也不是完全沒有可能的,已經有一些論文往這個方向進展。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:08.000" id=23:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1388">23:08.000</a></div>
        <div class="t">到目前為止,我們還是把訓練跟測試分成兩個階段,我們有一個learning algorithm,它是拿訓練資料進行訓練,然後輸出訓練好的結果,然後把訓練好的結果用在測試資料上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:27.000" id=23:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1407">23:27.000</a></div>
        <div class="t">有沒有可能更進一步,直接把整個episode,也就是一次訓練加一次測試,把整個episode包在一個network裡面呢?這個是有可能的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:41.000" id=23:41.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1421">23:41.000</a></div>
        <div class="t">有一個系列的做法,它就是直接把訓練資料跟測試資料當作network的input,network讀完訓練資料以後,你也不知道裡面發生了什麼事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:52.000" id=23:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1432">23:52.000</a></div>
        <div class="t">也許它就是學出了一個learning algorithm,也許它就是找出一組參數,不知道,不知道它發生了什麼事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:58.000" id=23:58.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1438">23:58.000</a></div>
        <div class="t">它讀完訓練資料以後,再給它測試資料,它直接輸出這些測試資料的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:04.000" id=24:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1444">24:04.000</a></div>
        <div class="t">也就是我們不再有訓練跟測試的分界,一個episode裡面不再分訓練跟測試,而是直接用一個network把訓練跟測試這件事情一次搞定。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:15.000" id=24:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1455">24:15.000</a></div>
        <div class="t">有沒有可能做這樣的事呢?其實這樣的方法今日並不罕見。有一個系列的meta learning的方法叫做learning to compare,它又叫做metric-based的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:28.000" id=24:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1468">24:28.000</a></div>
        <div class="t">這一系列的做法就可以看作是訓練跟測試沒有分界,一個network直接把訓練資料、測試資料都讀進去,而直接輸出測試資料的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:39.000" id=24:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1479">24:39.000</a></div>
        <div class="t">如果你想學更多跟learning to compare有關的東西的話,其實在過去的上課有講過metric-based approach,這邊就把過去上課的錄影貼在這邊給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:50.000" id=24:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1490">24:50.000</a></div>
        <div class="t">最後,也許你會很好奇說meta learning這樣的技術真的有應用嗎?它真的有被用在任何地方嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:01.000" id=25:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1501">25:01.000</a></div>
        <div class="t">meta learning、learn to learn,直接learn一個algorithm,聽起來非常的科幻,它真的有實際的應用嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:09.000" id=25:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1509">25:09.000</a></div>
        <div class="t">今天你在做meta learning的時候,你最常拿來測試meta learning技術的任務叫做viewshot的image classification。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:19.000" id=25:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1519">25:19.000</a></div>
        <div class="t">在viewshot的image classification裡面,你每一個任務都只有幾張圖片,你每一個類別、每一個class都只有幾張圖片。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:31.000" id=25:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1531">25:31.000</a></div>
        <div class="t">比如說你現在分類的任務是有三個class進來一張image,你要把它分成三個類別,每一個類別你都只有兩張圖片,每一個類別你都只有兩張圖片。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:40.000" id=25:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1540">25:40.000</a></div>
        <div class="t">你希望透過這樣一點點的資料就可以訓練出一個模型,給它一張新的圖片,它可以知道這張圖片屬於哪一個類別。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:50.000" id=25:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1550">25:50.000</a></div>
        <div class="t">那在做這種viewshot的classification的時候,最常見的一種classification,你常常會看到一個名詞叫做n-way k-shot的classification。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:01.000" id=26:01.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1561">26:01.000</a></div>
        <div class="t">那n-way k-shot的classification是什麼意思呢?n-way k-shot的classification它的意思就是,在每一個任務裡面,我們有n個class,而每一個class我們只有k個example。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:15.000" id=26:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1575">26:15.000</a></div>
        <div class="t">舉例來說,在上面這個例子裡面,我們有三個class,每一個class只有兩個example,那它就是3-way Q-shot的classification。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:27.000" id=26:27.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1587">26:27.000</a></div>
        <div class="t">那在meta learning裡面,如果我們今天要教machine能夠做n-way k-shot的classification,那意味著說我們需要準備很多的n-way k-shot的classification的task當作訓練的任務,這樣machine才能夠學到n-way k-shot的learning algorithm。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:48.000" id=26:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1608">26:48.000</a></div>
        <div class="t">那要怎麼去找一堆n-way k-shot的任務呢?要怎麼去找一堆n-way k-shot的training的task呢?那在文獻上,最常見的一種做法是使用omega這個corpus當作benchmark corpus。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:05.000" id=27:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1625">27:05.000</a></div>
        <div class="t">你知道這個omega就好像說你今天在做生物實驗的時候,你都用果蠅來做生物實驗嘛,那在meta learning裡面,如果你想要快速做相關實驗的話,最常做的選擇就是使用omega。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:17.000" id=27:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1637">27:17.000</a></div>
        <div class="t">在omega這個corpus裡面有1623個不同的character,那每一個character有20個example,比如說這是某一個character,它就是勾起來,然後點兩點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:33.000" id=27:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1653">27:33.000</a></div>
        <div class="t">那像這個character它就有20個不同的example,就是找20個人,每一個人都去寫一遍這個character,然後把它資料收集起來,所以每一個character有20個example,總共1623個character。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:48.000" id=27:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1668">27:48.000</a></div>
        <div class="t">那有這些character以後呢,你就可以去製造n-way k-shot的classification。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:54.000" id=27:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1674">27:54.000</a></div>
        <div class="t">舉例來說,假設你要製造一個20-way one-shot的classification任務的話,那你要怎麼做呢?你就從omega裡面選出20個character,然後每一個character就只取一個example,那你就得到一個20-way one-shot的classification的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:15.000" id=28:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1695">28:15.000</a></div>
        <div class="t">像這邊這個樣子,這邊呢,每一個圖片就代表某一個character,每一個character這邊只有一個example,而每一個character在n-way k-shot的任務裡面就代表了一個class。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:32.000" id=28:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1712">28:32.000</a></div>
        <div class="t">所以20-way one-shot的classification的任務,它的訓練資料,也就是support set,就長這個樣子。那測試資料呢?測試資料就是你從這20個character裡面,再去omega dataset裡面,找某一個example出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:51.000" id=28:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1731">28:51.000</a></div>
        <div class="t">然後接下來就問你說,誒,這一個testing的example,這一個query set,它是這20個class裡面的哪一個?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:02.000" id=29:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1742">29:02.000</a></div>
        <div class="t">那這個東西到底是哪一個class呢?這個看起來有點像是豌豆射手啦。其實人啊,在做這種fusion classification是非常厲害的,所以這種fusion classification可以難倒機器,但往往難不倒人。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:15.000" id=29:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1755">29:15.000</a></div>
        <div class="t">像這一個,它是屬於哪一個class呢?它是屬於哪一個character呢?我相信你一眼就可以看出它應該是這一個character了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:23.000" id=29:23.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1763">29:23.000</a></div>
        <div class="t">好,那在使用omega的時候呢,你就會把你的那個character分成兩半。一半呢,是拿來製造training task的character,另外一半是拿來製造testing task的character。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:39.000" id=29:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1779">29:39.000</a></div>
        <div class="t">然後這些training的character啊,如果你要去製造一個n-way k-shot的任務,你就是從這些training的character裡面先隨機sample n個character,然後這n個character,每一個character再去sample k個example,集合起來,你就得到一個訓練的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:59.000" id=29:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1799">29:59.000</a></div>
        <div class="t">那測試的任務呢,你就從這些測試的character裡面拿出n個character,然後每一個charactersample k個example,那你就得到一個n-way k-shot的測試任務,那你就可以訓練在一堆訓練任務上,然後測試在測試任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:18.000" id=30:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1818">30:18.000</a></div>
        <div class="t">好,那你可能會問說,這個n-way k-shot的任務做在onigra上面這個有什麼用呢?這個就是沒有什麼用啦,但是meta learning不是只能用在onigra上面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:34.000" id=30:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1834">30:34.000</a></div>
        <div class="t">我這邊呢,這個table上面是列舉了meta learning在語音還有自然語言處理上的應用,那這邊的縱軸啊,是不同meta learning的方法,有learning to initialize,learning to compare,還有其他類型的meta learning的方法,比如說network,architecture search等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:54.000" id=30:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1854">30:54.000</a></div>
        <div class="t">而橫軸啊,就是不同的應用,比如說sound event detection,keyword spotting,text classification,voice conversion,sequence labeling,machine translation,speech recognition等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:06.000" id=31:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1866">31:06.000</a></div>
        <div class="t">像這些語音還有NLP相關的任務,都已經有人嘗試在上面使用meta learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:14.000" id=31:14.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1874">31:14.000</a></div>
        <div class="t">所以meta learning不是只能用非常簡單的任務,今天在學界已經開始把meta learning推向更複雜的任務,那我們可以拭目以待,看看未來meta learning這個技術能不能夠真的用在現實的應用上,它可以走得多遠。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:31.000" id=31:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts&t=1891">31:31.000</a></div>
        <div class="t">好,那這個就是本學期想要跟大家分享的內容啦。</div>
    </div>
    
</body>
</html>   