<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>【機器學習2021】自督導式學習 (Self-supervised Learning) (二) – BERT簡介</h2><a href=https://www.youtube.com/watch?v=gh0hewYkjgo><img src=https://i.ytimg.com/vi/gh0hewYkjgo/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AH-BIAC4AOKAgwIABABGGUgZShlMA8=&rs=AOn4CLBh4uTOnV8AfowqZy98AZaRgEgbCQ></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=0">00:00.000</a></div>
        <div class="t">那我們接下來呢,就直接跟大家介紹BURP這個模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:06.300" id=00:06.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=6">00:06.300</a></div>
        <div class="t">好,我們來講一下什麼是Self-Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:10.580" id=00:10.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=10">00:10.580</a></div>
        <div class="t">那什麼是Self-Supervised Learning呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:13.380" id=00:13.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=13">00:13.380</a></div>
        <div class="t">Supervised Learning,大家都應該非常的熟悉了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:17.620" id=00:17.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=17">00:17.620</a></div>
        <div class="t">作業一二三四五,都是Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:22.260" id=00:22.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=22">00:22.260</a></div>
        <div class="t">在做Supervised Learning的時候,我們就是有一個Model,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:26.020" id=00:26.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=26">00:26.020</a></div>
        <div class="t">這個Model的輸入是X,輸出是Y。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:28.700" id=00:28.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=28">00:28.700</a></div>
        <div class="t">那怎麼讓Model輸出我們想要的Y呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:31.760" id=00:31.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=31">00:31.760</a></div>
        <div class="t">你得要有Label的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:34.400" id=00:34.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=34">00:34.400</a></div>
        <div class="t">所以可以想像說,假設你今天想要做Sentiment Analysis,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:38.800" id=00:38.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=38">00:38.800</a></div>
        <div class="t">就是讓機器看一篇文章,然後決定說這篇文章是正面的還是負面的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:43.240" id=00:43.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=43">00:43.240</a></div>
        <div class="t">那你得先找一大堆文章來,然後把這些文章都給它標註,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:48.180" id=00:48.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=48">00:48.180</a></div>
        <div class="t">標說是正面的還是負面的,這個正面或負面就是所謂的Label。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:52.420" id=00:52.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=52">00:52.420</a></div>
        <div class="t">你要有文章、有Label才能夠訓練Supervised的Model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:56.920" id=00:56.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=56">00:56.920</a></div>
        <div class="t">那什麼叫Self-Supervised呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:59.760" id=00:59.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=59">00:59.760</a></div>
        <div class="t">Self-Supervised就是自己想辦法做Supervised,在沒有Label的情況下。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:06.700" id=01:06.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=66">01:06.700</a></div>
        <div class="t">怎麼說呢?假設我們現在只有一堆文章,沒有標註,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:12.140" id=01:12.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=72">01:12.140</a></div>
        <div class="t">但是想辦法從這些沒有標註的資料裡面,把資料分成兩部分,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:19.180" id=01:19.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=79">01:19.180</a></div>
        <div class="t">讓一部分作為模型的輸入,另外一部分作為模型的標註。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:26.460" id=01:26.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=86">01:26.460</a></div>
        <div class="t">假設你有沒有標註的資料,比如說一篇文章叫做X,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:30.460" id=01:30.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=90">01:30.460</a></div>
        <div class="t">X你把它分成兩部分,一部分叫X',一部分叫X''.</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:35.060" id=01:35.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=95">01:35.060</a></div>
        <div class="t">我知道到目前為止這樣講,你一定覺得非常非常的抽象,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:38.560" id=01:38.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=98">01:38.560</a></div>
        <div class="t">等一下實際上講Bird的時候,你就可以體會什麼叫做Self-Supervised,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:43.740" id=01:43.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=103">01:43.740</a></div>
        <div class="t">怎麼叫怎樣叫做,在明明沒有辦法做Supervised的情況下,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:48.180" id=01:48.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=108">01:48.180</a></div>
        <div class="t">自己想辦法自己做Supervised。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:51.680" id=01:51.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=111">01:51.680</a></div>
        <div class="t">所以現在我們先非常抽象的講一下,把X分成兩部分,X'跟X''.</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:59.260" id=01:59.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=119">01:59.260</a></div>
        <div class="t">然後把X'輸到模型裡面,讓它輸出Y,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:04.860" id=02:04.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=124">02:04.860</a></div>
        <div class="t">然後我們要讓Y跟它的Label,學習的目標,跟它的Label,X'越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:13.440" id=02:13.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=133">02:13.440</a></div>
        <div class="t">這個就是Self-Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:16.980" id=02:16.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=136">02:16.980</a></div>
        <div class="t">Self-Supervised Learning可以看作是一種Unsupervised Learning的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:22.580" id=02:22.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=142">02:22.580</a></div>
        <div class="t">因為什麼叫Unsupervised Learning?有Label叫做Supervised Learning,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:26.980" id=02:26.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=146">02:26.980</a></div>
        <div class="t">沒有Label就是Unsupervised Learning,Supervised的相反就是Unsupervised。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:33.360" id=02:33.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=153">02:33.360</a></div>
        <div class="t">所以Self-Supervised,我們沒有用到Label的資料,所以我們可以說它是Unsupervised Learning的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:41.800" id=02:41.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=161">02:41.800</a></div>
        <div class="t">但是這邊之所以特別稱之為Self-Supervised Learning,是為了讓我們所指涉的方法更為明確。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:48.900" id=02:48.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=168">02:48.900</a></div>
        <div class="t">Self-Supervised Learning這一個詞彙,最早應該是Jan Larkin說的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:53.780" id=02:53.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=173">02:53.780</a></div>
        <div class="t">這個其實不是一個特別舊的詞彙。Jan Larkin是什麼時候說這句話的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:00.180" id=03:00.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=180">03:00.180</a></div>
        <div class="t">在19年4月的Facebook上的貼文說的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:04.420" id=03:04.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=184">03:04.420</a></div>
        <div class="t">他說,他現在把這種方法,就是我現在講的這樣子的方法,叫做Self-Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:12.260" id=03:12.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=192">03:12.260</a></div>
        <div class="t">為什麼不叫做Unsupervised Learning呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:15.260" id=03:15.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=195">03:15.260</a></div>
        <div class="t">因為Unsupervised Learning是一個比較大的Family,裡面有很多不同的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:21.200" id=03:21.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=201">03:21.200</a></div>
        <div class="t">那為了比較明確的說明說現在在做的事情是什麼,所以說現在做的是Self-Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:28.140" id=03:28.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=208">03:28.140</a></div>
        <div class="t">像我們剛才講的Cycle Gap,那也算是Unsupervised Learning的方法,我們也沒有用到Label的成對的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:36.780" id=03:36.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=216">03:36.780</a></div>
        <div class="t">但是它跟Self-Supervised Learning就是不太一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:39.580" id=03:39.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=219">03:39.580</a></div>
        <div class="t">所以Unsupervised Learning下面有很多的方法,其中一種是Self-Supervised Learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:45.660" id=03:45.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=225">03:45.660</a></div>
        <div class="t">那剛才講的非常的抽象,什麼把X分成X'跟X'',自己跟自己學,自己產生Label,實際上到底是怎麼回事呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:57.540" id=03:57.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=237">03:57.540</a></div>
        <div class="t">我們就直接拿BERT這個模型來跟大家說明,實際上是怎麼做的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:04.540" id=04:04.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=244">04:04.540</a></div>
        <div class="t">BERT這個Model,它是一個Transformer的Encoder,那我們已經講過Transformer了嘛,我們也花很多時間介紹了Encoder跟Decoder。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:16.060" id=04:16.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=256">04:16.060</a></div>
        <div class="t">Transformer的Encoder就是BERT,就是BERT的Network架構,就跟Transformer的Encoder一模一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:24.020" id=04:24.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=264">04:24.020</a></div>
        <div class="t">裡面就有很多Self-Attention,有Residual,有Normalization等等,這個就是BERT。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:31.020" id=04:31.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=271">04:31.020</a></div>
        <div class="t">如果你已經忘記Encoder裡面有什麼樣的東西也沒關係,反正你就記得說BERT可以做的事情就是輸入一排向量,輸出另外一排向量,輸入多長就輸出多長。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:45.540" id=04:45.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=285">04:45.540</a></div>
        <div class="t">那BERT的輸入是什麼呢?BERT一般是用在自然語言處理上,用在文字上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:52.780" id=04:52.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=292">04:52.780</a></div>
        <div class="t">所以一般它的輸入就是一排文字,就是一個Sequence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:58.940" id=04:58.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=298">04:58.940</a></div>
        <div class="t">那我們其實在講Self-Attention的時候也有說過說,不是只有文字是一個Sequence,語音也可以看作是一個Sequence,甚至Image也可以看作是一堆的Factor。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:11.260" id=05:11.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=311">05:11.260</a></div>
        <div class="t">所以跟BERT同樣的想法,不是只能用在NLP,用在文字上,它也可以用在語音跟影像上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:19.060" id=05:19.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=319">05:19.060</a></div>
        <div class="t">只是因為BERT最早是用在文字上,所以我們這邊都拿文字作為例子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:24.500" id=05:24.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=324">05:24.500</a></div>
        <div class="t">你完全可以說我把輸入換成語音,把輸入換成影像,也都是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:32.500" id=05:32.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=332">05:32.500</a></div>
        <div class="t">好,那BERT的輸入這邊是一段文字,那接下來我們要做的事情是把輸入的這串文字裡面,其中一些部分把它隨機的蓋住。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:45.900" id=05:45.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=345">05:45.900</a></div>
        <div class="t">哪些部分會被蓋住呢?隨機的,隨便Sample,就是你輸入一百個Token。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:52.860" id=05:52.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=352">05:52.860</a></div>
        <div class="t">Token是什麼?Token就是你在處理一段文字的時候的單位,這個Token的大小是你自己決定的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:59.140" id=05:59.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=359">05:59.140</a></div>
        <div class="t">在中文裡面,我們通常把方塊字當成Token。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:04.060" id=06:04.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=364">06:04.060</a></div>
        <div class="t">所以輸入一個句子,裡面會有一些詞彙,隨機的被蓋住。蓋住哪些?隨機決定,隨便決定。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:12.140" id=06:12.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=372">06:12.140</a></div>
        <div class="t">那怎麼把它蓋住呢?所謂的蓋住,具體而言是什麼樣的意思呢?有兩種做法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:19.260" id=06:19.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=379">06:19.260</a></div>
        <div class="t">第一種做法是把句子裡面的某一個字換成一個特殊的符號,我們用mask來代表特殊的符號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:31.100" id=06:31.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=391">06:31.100</a></div>
        <div class="t">你就想成它是一個新的中文的字,這個中文的字在你的字典裡面從來沒有出現過的。這是一個新的字,它的意思就代表了蓋住。它就代表了mask,代表蓋住。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:43.420" id=06:43.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=403">06:43.420</a></div>
        <div class="t">另外一種做法就是隨機把某一個字換成另外一個字。本來這邊放的是one,那就隨便找一個中文的字把它替換掉,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:52.580" id=06:52.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=412">06:52.580</a></div>
        <div class="t">換成一,換成天,換成大,換成小,隨便換成某一個字。所以有兩種做法,一種是加mask,一種是加隨機的字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:02.980" id=07:02.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=422">07:02.980</a></div>
        <div class="t">那用哪一種呢?兩種都可以用。所以到底用哪一種也是隨機決定的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:08.940" id=07:08.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=428">07:08.940</a></div>
        <div class="t">所以在Bert在訓練的時候,輸入一個句子,先隨機決定哪些中文的字會被蓋起來,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:16.700" id=07:16.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=436">07:16.700</a></div>
        <div class="t">接下來再決定說要怎麼蓋,是要換成這個特殊的代表蓋住的符號,還是隨便從中文的字裡面挑一個出來把它蓋住。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:28.140" id=07:28.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=448">07:28.140</a></div>
        <div class="t">所以這兩種方法都可以用。那蓋住以後呢?蓋住以後你一樣是輸入一個sequence,那Bert的輸出,它對應的輸出就是另外一個sequence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:41.740" id=07:41.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=461">07:41.740</a></div>
        <div class="t">接下來,你把蓋住的部分所對應的輸出,就是蓋住的部分你還是有放東西進去嘛,只是它可能是mask或者是隨機的,蓋住的部分還是有放東西進去,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:53.300" id=07:53.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=473">07:53.300</a></div>
        <div class="t">它一樣輸出一個向量,把這個向量做一個linear transform,所謂做linear transform的意思就是成一個矩陣,然後做softmax,得到一個輸出,輸出一個分布。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:07.340" id=08:07.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=487">08:07.340</a></div>
        <div class="t">那這個輸出的分布是什麼東西呢?輸出的這個分布就跟我們在做translation的時候,在講sequence-to-sequence model,在講transformer的時候是一模一樣的,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:17.980" id=08:17.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=497">08:17.980</a></div>
        <div class="t">它的輸出是一個非常長的向量,這個向量裡面包含了所有你感興趣的、你想要處理、你知道的中文的字,那每一個字都對應到一個分數,它是一個distribution,因為這邊有一個softmax。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:34.380" id=08:34.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=514">08:34.380</a></div>
        <div class="t">那接下來,你要怎麼訓練這個BERT呢?你訓練的時候,它訓練的目標就是,因為我們其實知道被蓋起來的東西原來是哪一個字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:46.460" id=08:46.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=526">08:46.460</a></div>
        <div class="t">BERT本身不知道,我們給BERT的時候它是被蓋起來的,所以BERT不知道這邊應該是彎,但我們自己知道,我們知道說這個被蓋起來的位置本來應該要是彎。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:58.380" id=08:58.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=538">08:58.380</a></div>
        <div class="t">所以BERT學習的目標就是,它要學到說這邊的輸出跟彎這個character、跟彎這個字越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:09.180" id=09:09.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=549">09:09.180</a></div>
        <div class="t">你會把彎表示成一個one-half的vector,然後你會minimize這邊的輸出跟彎這個one-half-vector的cross-entropy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:20.140" id=09:20.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=560">09:20.140</a></div>
        <div class="t">或講得更簡單一點,你其實就是在做一個分類的問題,只是你有多少個類別,我們的類別的數目就跟中文字的數目一樣多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:32.300" id=09:32.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=572">09:32.300</a></div>
        <div class="t">中文字那就看你覺得有幾個,如果有四千個,那就是一個四千個類別的分類的問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:37.660" id=09:37.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=577">09:37.660</a></div>
        <div class="t">那現在BERT要做的事情就是,它必須要成功地預測說這個被蓋起來的地方,它屬於的類別就是屬於彎這個類別。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:48.620" id=09:48.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=588">09:48.620</a></div>
        <div class="t">那在訓練的時候呢,你是BERT加後面這個linear的model,兩者一起訓練。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:56.300" id=09:56.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=596">09:56.300</a></div>
        <div class="t">就是BERT裡面,它是一個transformer的encoder,有一堆的參數,linear的model是一個matrix,它也是有一些參數,但跟BERT比起來非常小杯水車薪。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:08.860" id=10:08.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=608">10:08.860</a></div>
        <div class="t">它們兩個是一起訓練的,要一起努力,然後輸出要去預測說現在被蓋住的詞彙是彎。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:16.540" id=10:16.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=616">10:16.540</a></div>
        <div class="t">就這樣,這個叫做masking。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:20.540" id=10:20.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=620">10:20.540</a></div>
        <div class="t">那其實BERT在訓練的時候除了做masking以外,同時也會做另外一個方法,這個另外的方法叫做next sentence prediction。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:30.380" id=10:30.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=630">10:30.380</a></div>
        <div class="t">next sentence prediction的意思是說,你拿出兩個句子,從你的資料庫裡面,你會收集很多的句子,那個網路上隨便爬一爬就有了,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:40.940" id=10:40.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=640">10:40.940</a></div>
        <div class="t">收集很多的句子,從裡面拿兩個句子出來,在這兩個句子的中間,你會加入一個特殊的符號代表分隔,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:50.460" id=10:50.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=650">10:50.460</a></div>
        <div class="t">這樣BERT才知道說這兩個是不同的句子,這兩個句子中間有個分隔的符號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:56.700" id=10:56.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=656">10:56.700</a></div>
        <div class="t">你還會在這整個sequence的最前面加入一個特別的符號,這邊我們用CLS來表示這個特別的符號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:07.980" id=11:07.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=667">11:07.980</a></div>
        <div class="t">等一下我會知道這個特別的符號有什麼樣的作用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:12.220" id=11:12.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=672">11:12.220</a></div>
        <div class="t">現在我們有一個很長的sequence,它包括兩個句子,中間有一個分隔,還有CLS的符號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:18.460" id=11:18.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=678">11:18.460</a></div>
        <div class="t">整個一股腦把它丟到BERT裡面,然後照理說這邊輸入一個sequence,輸出就會是另外一個sequence,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:27.420" id=11:27.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=687">11:27.420</a></div>
        <div class="t">這個就是encoder可以做的事情嘛,BERT就是transformer encoder,這個就是encoder可以做的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:33.500" id=11:33.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=693">11:33.500</a></div>
        <div class="t">但是我們現在只取CLS所對應的那個輸出,就這邊也有輸出,但不管它,不去看它,我們只看CLS這邊的輸出。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:43.500" id=11:43.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=703">11:43.500</a></div>
        <div class="t">把這個輸出乘上一個linear的transform,然後它要做的是什麼?它要做的是一個二元的分類問題,它要預測的就是yes或no。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:55.900" id=11:55.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=715">11:55.900</a></div>
        <div class="t">這個yes或no指的是什麼呢?這個方法的名字叫next sentence prediction,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:00.380" id=12:00.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=720">12:00.380</a></div>
        <div class="t">所以yes或no就是要預測說,這兩個句子是不是相接的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:05.740" id=12:05.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=725">12:05.740</a></div>
        <div class="t">如果這兩個句子是相接的,BERT就要訓練成,看到兩個相接的句子就輸出yes,看到兩個不是相接的句子就輸出no,就這樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:19.580" id=12:19.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=739">12:19.580</a></div>
        <div class="t">但是後來的研究發現說,next sentence prediction對於接下來BERT所要做的事情其實幫助不大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:28.060" id=12:28.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=748">12:28.060</a></div>
        <div class="t">BERT接下來要做什麼事情,我們馬上就會講到了。總之這一招不太有用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:34.060" id=12:34.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=754">12:34.060</a></div>
        <div class="t">舉例來說,在一篇叫做Robustness-Optimized BERT Approach的paper裡面,它的縮寫是Roberta。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:41.500" id=12:41.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=761">12:41.500</a></div>
        <div class="t">它就明確地指出說,它嘗試了做next sentence prediction這個方法,但是沒有什麼特別的幫助。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:48.860" id=12:48.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=768">12:48.860</a></div>
        <div class="t">這個就是強導眾人推,一個人說沒有用,接下來會有更多文章說沒有用。後來什麼STEMBERT、XLNet通通都說next sentence prediction沒有用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:59.500" id=12:59.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=779">12:59.500</a></div>
        <div class="t">它沒有用的一個可能是,next sentence prediction這個任務可能太簡單了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:04.620" id=13:04.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=784">13:04.620</a></div>
        <div class="t">要知道兩個句子該不該被接在一起,也許不是一個特別難的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:09.740" id=13:09.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=789">13:09.740</a></div>
        <div class="t">因為今天這兩個句子,你通常的做法就是先隨機選一個句子,接下來你選接在它後面的句子,或者是從整個資料庫裡面隨便選一句。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:20.300" id=13:20.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=800">13:20.300</a></div>
        <div class="t">通常隨便選一句,跟你一開始選的這一句一定很不像。所以對BERT來說,它要分辨兩個句子是不是接在一起,可能挺容易的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:29.980" id=13:29.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=809">13:29.980</a></div>
        <div class="t">所以它沒有藉由next sentence prediction這個任務學到太多有用的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:37.820" id=13:37.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=817">13:37.820</a></div>
        <div class="t">後來還有另外一招跟next sentence prediction有點像,但是在文件上看起來是比較有用的,叫做sentence order prediction,它的縮寫是SOP。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:51.900" id=13:51.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=831">13:51.900</a></div>
        <div class="t">這個方法是說,我們找出來的sentence1跟sentence2本來就是接在一起的,只是你可能會把本來放在前面的那個句子當sentence1,放在後面的那個句子當sentence2。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:05.820" id=14:05.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=845">14:05.820</a></div>
        <div class="t">或者是本來放在前面的句子當sentence2,放在後面的句子當sentence1,有這兩種可能。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:11.660" id=14:11.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=851">14:11.660</a></div>
        <div class="t">然後問BERT是哪一種,可能這個問題比較難,所以sentence order prediction,SOP,目前在文件上看起來是有用的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:21.260" id=14:21.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=861">14:21.260</a></div>
        <div class="t">它被用在一個叫做ALBERT,就是BERT的一個進階的版本,叫做ALBERT裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:28.060" id=14:28.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=868">14:28.060</a></div>
        <div class="t">ALBERT就是愛因斯坦,愛因斯坦就叫做ALBERT,所以這邊就翻個愛因斯坦。今天每一個模型都有一個名字,沒有名字就不要說你有提出了一個模型,所以模型都要想辦法取一個名字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:41.980" id=14:41.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=881">14:41.980</a></div>
        <div class="t">那BERT怎麼用呢?我們剛才說我們叫BERT會做的事情是什麼?我們訓練的時候就是叫BERT學兩個任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:50.300" id=14:50.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=890">14:50.300</a></div>
        <div class="t">一個是蓋住一些詞彙,蓋住一些中文的字,它可以把蓋住的部分補回來,它知道怎麼做填空題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:59.020" id=14:59.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=899">14:59.020</a></div>
        <div class="t">另外一個是它可以預測兩個句子是不是應該被接在一起,但我有說這招好像沒有什麼用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:05.260" id=15:05.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=905">15:05.260</a></div>
        <div class="t">所以整體而言,BERT真正學到的是什麼?它就是學到怎麼做填空題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:11.020" id=15:11.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=911">15:11.020</a></div>
        <div class="t">那你說那又怎樣?如果我要解的任務就不是填空題的話,那這個BERT有什麼用呢?它就只會做填空題啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:18.460" id=15:18.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=918">15:18.460</a></div>
        <div class="t">它學來就是做填空題啊,你教它的事情就是做填空題啊,那訓練教會一個模型做填空題以後。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:24.620" id=15:24.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=924">15:24.620</a></div>
        <div class="t">然後呢,接下來就是神奇的地方,它可以被用在其他的任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:33.500" id=15:33.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=933">15:33.500</a></div>
        <div class="t">這些任務跟填空題不一定要有關,甚至是根本就沒有什麼關係,但是BERT可以被用在這些任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:42.540" id=15:42.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=942">15:42.540</a></div>
        <div class="t">那這些任務,BERT真正被使用的任務叫做downstream下游的任務,downstream task。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:49.900" id=15:49.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=949">15:49.900</a></div>
        <div class="t">downstream task,等一下我們會舉幾個具體的例子。所謂downstream task的意思就是那些你實際上真正在意的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:58.940" id=15:58.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=958">15:58.940</a></div>
        <div class="t">但是我們要BERT學會做這些任務的時候,其實我們還是需要有一些標注的資料的,等一下我們會看得更清楚一點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:08.620" id=16:08.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=968">16:08.620</a></div>
        <div class="t">所以總之BERT它只學會做填空題,但接下來它可以被拿來做各式各樣你感興趣的下游的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:20.300" id=16:20.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=980">16:20.300</a></div>
        <div class="t">它有點像是黑胎裡面的幹細胞,它具有各式各樣無限的潛能,雖然現在還沒有發揮它的能力,只會做填空題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:31.100" id=16:31.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=991">16:31.100</a></div>
        <div class="t">但是接下來它有能力去解各式各樣的任務,只要給它一點資料刺激它,黑胎幹細胞就可以分化成各式各樣不同的細胞,心臟細胞、肌肉細胞等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:45.180" id=16:45.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1005">16:45.180</a></div>
        <div class="t">BERT也是一樣,給它一點有標注的資料,它就可以分化成各式各樣的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:53.980" id=16:53.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1013">16:53.980</a></div>
        <div class="t">BERT分化成各式各樣任務這件事情叫做fine-tune,中文你可能會翻成微調。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:01.900" id=17:01.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1021">17:01.900</a></div>
        <div class="t">所以常常聽到有人說fine-tune的那個BERT指的就是,它手上有個BERT,它把這個BERT拿來做微調,讓它可以去做某一種任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:12.540" id=17:12.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1032">17:12.540</a></div>
        <div class="t">相對於fine-tune,在fine-tune之前產生這個BERT的過程就叫做pre-trained。所以產生BERT的這個過程,它是self-supervised learning,但你也可以說它叫做pre-trained。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:26.700" id=17:26.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1046">17:26.700</a></div>
        <div class="t">你會發現說我們在作業裡面其實有反覆說,我們就不使用pre-trained的model。如果你不知道什麼是pre-trained的model,沒有關係,反正你既然不知道它是什麼,你就不會用到它。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:37.980" id=17:37.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1057">17:37.980</a></div>
        <div class="t">如果你知道是什麼的話,這邊的意思就是說,你不要用這種self-supervised learning的方法去別的地方,找一個self-supervised learning的模型直接用在作業上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:47.900" id=17:47.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1067">17:47.900</a></div>
        <div class="t">因為這些方法往往都有不可思議強大的能力,會讓你接下來做的事情變得沒有特別有趣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:54.460" id=17:54.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1074">17:54.460</a></div>
        <div class="t">但是其實接下來有一個BERT的作業,作業7就是用BERT的作業嘛,所以作業7當然就是可以用pre-trained的model的。這是唯一一個可以用pre-trained的model的作業,因為作業7就是要fine-tuneBERT嘛,所以當然你要用pre-trained的BERT來進行fine-tune,所以只有作業7是可以用pre-trained的model的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:15.020" id=18:15.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1095">18:15.020</a></div>
        <div class="t">在講BERT是怎麼fine-tune之前,我們先來看看它的能力。今天你要測試一個self-supervised learning的model的能力,通常你會把它測試在多個任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:29.900" id=18:29.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1109">18:29.900</a></div>
        <div class="t">因為我們剛才說BERT就像是一個黑胎幹細胞,接下來它要分化去做各式各樣的任務,所以我們通常不會只測試它在一個任務上的能力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:40.380" id=18:40.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1120">18:40.380</a></div>
        <div class="t">你是會把這個BERT分化去做多個不同的任務,看看它在每個任務上得到的正確率是多少,再取一個平均值。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:49.820" id=18:49.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1129">18:49.820</a></div>
        <div class="t">在這種任務組合、這樣一個模型去測度的時候,我們就叫做任務集。在任務集裡面最知名的一個標竿就叫做GROUP,它是General Language Understanding Evaluation的縮寫。GROUP裡面總共有九個任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:11.260" id=19:11.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1151">19:11.260</a></div>
        <div class="t">一般你想要知道一個像BERT這樣訓練出來的模型好不好,你就會把它分別微調在九個任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:20.140" id=19:20.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1160">19:20.140</a></div>
        <div class="t">所以你實際上會得到九個模型,分別做在九個任務上,看看這九個任務上正確率的平均是多少,你得到一個數值,這個數值代表了self-supervised model的好壞。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:33.020" id=19:33.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1173">19:33.020</a></div>
        <div class="t">我們來看一下在GROUP上面的表現,有了BERT以後,GROUP的分數,就是那九個任務的平均分數,確實逐年攀升。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:43.980" id=19:43.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1183">19:43.980</a></div>
        <div class="t">在這個圖上,橫軸是不同的模型,這邊有列碼,那你發現說來來去去都是有什麼ELMO、GPT、BERT、BERT、BERT、BERT、一大堆BERT這樣子,各式各樣的BERT。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:59.660" id=19:59.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1199">19:59.660</a></div>
        <div class="t">這個黑色的線代表的是人類在這個任務上得到的正確率,這個當作是1。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:09.260" id=20:09.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1209">20:09.260</a></div>
        <div class="t">這邊每一個點就代表了一個任務。為什麼要跟人類的正確率比呢?人類的正確率是1,然後這些點如果做得比人類好就是大於1,做得比人類差就是小於1。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:20.460" id=20:20.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1220">20:20.460</a></div>
        <div class="t">所以這些任務用的評估標準不見得是正確率,每個任務用的評估標準不一樣,不見得是正確率,所以直接把它的數值放在一起比可能沒什麼意思,所以這邊是看跟人類的差距。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:33.660" id=20:33.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1233">20:33.660</a></div>
        <div class="t">所以你會發現說本來九個任務裡面只有一個機器可以做得比人類好的,後來隨著越來越多技術被提出來,就有另外三個任務可以做得比人類好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:46.860" id=20:46.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1246">20:46.860</a></div>
        <div class="t">而其他本來跟人類相差甚遠的任務也慢慢地追上來了,機器的效能也慢慢追上來了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:54.700" id=20:54.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1254">20:54.700</a></div>
        <div class="t">藍色的虛線是機器的Growth Score的平均,發現說最近一些比較強的模型,比如說Excel內居然還超越了人類。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:04.300" id=21:04.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1264">21:04.300</a></div>
        <div class="t">當然這只是在這一個資料集上面的結果,並不代表說機器in general真的超越了人類,它只是在這個資料集上超越了人類,這顯示的是什麼呢?就是這個資料集被玩壞了,不夠難。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:18.860" id=21:18.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1278">21:18.860</a></div>
        <div class="t">所以接下來在Growth之後就有人做了Super Growth,找更難的自然語言處理的任務來讓機器來記。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:27.820" id=21:27.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1287">21:27.820</a></div>
        <div class="t">那秀這個圖的意思主要是想要告訴你說,有了BERT這樣的技術以後,確實機器在自然語言處理的能力上面又往前邁進了一步。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:39.100" id=21:39.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1299">21:39.100</a></div>
        <div class="t">那BERT到底是怎麼被使用的呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:44.300" id=21:44.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1304">21:44.300</a></div>
        <div class="t">BERT是這樣子用的,我們等一下會舉四個使用BERT的case。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:50.780" id=21:50.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1310">21:50.780</a></div>
        <div class="t">第一個case是這樣子的,第一個case是假設我們downstream的任務是輸入一個sequence輸出一個類別,它是一個分類的問題,只是輸入是一個sequence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:03.900" id=22:03.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1323">22:03.900</a></div>
        <div class="t">什麼樣的任務是輸入一個sequence輸出一個類別呢?比如說sentiment analysis,就給機器一個句子,叫它去判斷說這個句子是正面的還是負面的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:13.820" id=22:13.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1333">22:13.820</a></div>
        <div class="t">那對於BERT而言,它怎麼解sentiment analysis的問題呢?你就給它一個句子,就是你要拿來決定sentiment的那個句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:24.380" id=22:24.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1344">22:24.380</a></div>
        <div class="t">那把這個句子前面放CLS那個token,我剛才說CLS token,我上次提到它的時候是在講next sentence prediction的時候,它前面放CLS的token,丟到BERT裡面,那這四個輸入其實都會對應給它四個輸出,那我們只看CLS的部分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:42.220" id=22:42.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1362">22:42.220</a></div>
        <div class="t">CLS這邊輸出一個向量,把它做一個linear transform,乘上一個矩陣,那這邊把softmax省略掉了,通過softmax決定說輸出的類別是什麼,正面還是負面等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:57.420" id=22:57.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1377">22:57.420</a></div>
        <div class="t">這邊實際上在做的時候,你需要有你下游任務的標注資料,也就是說BERT並沒有辦法憑空去解sentiment analysis的問題,你仍然需要提供BERT一些標注的資料,你需要提供給它大量的句子,跟每一個句子是正面的還是負面的,你才能夠去訓練這個BERT的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:24.940" id=23:24.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1404">23:24.940</a></div>
        <div class="t">在訓練的時候,我們其實是把BERT加上linear transform合起來,說它是一個完整的sentiment classification的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:34.860" id=23:34.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1414">23:34.860</a></div>
        <div class="t">在訓練的時候,linear的部分跟BERT都會用gradient descent去update,只是現在linear的部分,它的參數是隨機初始化的,而BERT的部分,它的初始的參數是從學習了做填空題的那個BERT來的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:57.100" id=23:57.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1437">23:57.100</a></div>
        <div class="t">我們在訓練模型的時候,不是會隨機初始化一個參數嗎?然後用gradient descent去調那個參數,最後去minimize我們的loss。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:07.900" id=24:07.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1447">24:07.900</a></div>
        <div class="t">這邊也是一樣,我們有一個要minimize的loss就是做sentiment classification,但是我們的參數不再是完全隨機初始化了,有了BERT以後,我們有唯一隨機初始化的只有這個地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:22.940" id=24:22.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1462">24:22.940</a></div>
        <div class="t">而BERT這個本體,這邊是一個巨大的transformer encoder,這個network,它的參數不是隨機初始化的,我們是直接把學會了做填空題的BERT的參數拿來填在這個地方,把可以做填空題的BERT的參數拿來填在這個地方,當作初始化的參數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:47.740" id=24:47.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1487">24:47.740</a></div>
        <div class="t">為什麼要這樣做?為什麼要用那個學會做填空題的BERT把它放在這邊呢?最直覺、最簡單的理由當然是比隨機初始化好。當你這邊放了那個會做填空題的BERT的時候,它得到的結果會比隨機初始化好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:05.100" id=25:05.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1505">25:05.100</a></div>
        <div class="t">這邊有一個文獻上的例子,橫軸是訓練的EPOC,縱軸是training的loss。大家現在一定非常熟悉這樣的圖形了。隨著training的過程的進行,training的loss當然會越來越低。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:21.340" id=25:21.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1521">25:21.340</a></div>
        <div class="t">有趣的地方是,圖上有各式各樣的任務,細節是什麼我們就不解釋,這邊就是各種不同的任務。fine-tune代表的就是有pre-training,就是BERT那個部分,ENCODER那個部分,是用學會做填空題的BERT的參數來做初始化的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:43.580" id=25:43.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1543">25:43.580</a></div>
        <div class="t">scratch的意思就是整個model,包括BERT的那個本體,包括ENCODER的部分,都是隨機初始化的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:53.260" id=25:53.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1553">25:53.260</a></div>
        <div class="t">那你會發現說呢,如果是scratch,scratch就是虛線,虛線就是scratch。如果是scratch的話,首先你在訓練的時候,它loss下降比較慢,相較於有用BERT初始化的,有用會做填空題的BERT初始化的參數,它的下降比較慢。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:11.260" id=26:11.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1571">26:11.260</a></div>
        <div class="t">而且就算是最後降下來了,有隨機初始化的參數,它的loss也比有用填空題BERT做初始化的參數,它的loss還要更高。所以這個就是BERT可以在表面上帶給我們的好處。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:31.100" id=26:31.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1591">26:31.100</a></div>
        <div class="t">講到這邊呢,我其實就特意留了一頁投影片,想要停一下,接下來還有其他的內容,但我想在這邊停一下,確定大家了解我所表達的意思。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:42.060" id=26:42.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1602">26:42.060</a></div>
        <div class="t">這邊要聽得懂接下來,你才有辦法繼續聽下去。所以我想要問一下,到這個部分,大家有沒有問題想要問呢?你可以了解PRETRAIN跟FINE-TUNE是怎麼一回事嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:55.580" id=26:55.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1615">26:55.580</a></div>
        <div class="t">剛才其實在下課的時候有同學問到說,像BERT這種做法,它是不是semi-supervised呢?它是semi-supervised還是unsupervised呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:11.980" id=27:11.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1631">27:11.980</a></div>
        <div class="t">都是。就是self-supervised那一階段,學填空題那一階段,是unsupervised的。但接下來你要把BERT用在下游的downstream的這些任務上,用在下游的任務上,下游任務需要有標注的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:29.580" id=27:29.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1649">27:29.580</a></div>
        <div class="t">那你在做self-supervised learning的時候,用了大量沒有標注的資料,但下游任務有少量有標注的資料,所以合起來是semi-supervised。所謂semi-supervised的意思就是,你有大量沒標注的資料,少量有標注的資料,這種狀況就是semi-supervised。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:47.660" id=27:47.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1667">27:47.660</a></div>
        <div class="t">所以整個BERT的使用過程合起來,就是PRETRAIN加FINE-TUNE合起來,它算是一種semi-supervised的方法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#27:57.100" id=27:57.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1677">27:57.100</a></div>
        <div class="t">好,講到這邊,大家有沒有問題想要問的呢?有嗎?沒有嗎?好,如果沒有的話就要繼續下去了,接下來其實跟剛才的case 1都非常非常的像,所以如果你懂case 1在講什麼,接下來就是一法通,萬法通而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:21.340" id=28:21.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1701">28:21.340</a></div>
        <div class="t">接下來還有三個case。好,如果大家沒有問題就繼續下去囉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:27.500" id=28:27.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1707">28:27.500</a></div>
        <div class="t">好,那接下來的三個case是什麼呢?第二個case是輸入一個sequence,輸出另外一個sequence,但輸入跟輸出的長度是一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:40.060" id=28:40.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1720">28:40.060</a></div>
        <div class="t">那我們在講self-attention的時候也舉過類似的例子,什麼樣的任務是輸入跟輸出長度一樣的呢?比如說POS tagging。POS tagging就是詞性標注。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#28:52.700" id=28:52.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1732">28:52.700</a></div>
        <div class="t">你給機器一個句子,它要告訴你說這個句子裡面每一個詞彙,它對應到什麼樣的詞性。有時候就算是同樣的詞彙,也可能有不同的詞性,這個我們在semi-supervised learning的時候有講過了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:05.820" id=29:05.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1745">29:05.820</a></div>
        <div class="t">好,那Bert怎麼處理這種問題呢?你就給Bert輸入一個句子,然後接下來呢,輸入這個句子以後,接下來這個句子裡面的每一個token,如果在中文就是代表每一個字就有一個對應的向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:25.500" id=29:25.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1765">29:25.500</a></div>
        <div class="t">然後接下來再把每一個向量分別做一個linear的transform,乘上一個矩陣,再過softmax,然後再去predict說這邊輸入的每一個詞彙屬於哪一個類別,比如說哪一個詞性,隨著你的任務不同,這邊對應的類別也就會不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#29:46.460" id=29:46.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1786">29:46.460</a></div>
        <div class="t">那接下來呢,接下來就跟case 1完全一樣。也就是說,你需要有一些標註的資料,這仍然是一個一般的分類的問題,只是跟一般分類問題不一樣的地方是,Bert這個部分,這個本體的這個encoder的部分,它的參數不是隨機初始化,它已經在pre-trained的時候找到一組比較好的初始化的參數了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:12.860" id=30:12.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1812">30:12.860</a></div>
        <div class="t">講到這邊,大家有問題想問嗎?沒有的話呢,我們就再繼續看case 3。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:21.180" id=30:21.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1821">30:21.180</a></div>
        <div class="t">那case 3是輸入兩個句子,輸出一個類別。當然我們這邊舉的都是自然語言處理的例子,但你完全可以把這些例子改成比如說語音的例子,或改成影像的例子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:37.980" id=30:37.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1837">30:37.980</a></div>
        <div class="t">對不對?我們在講self-supervised learning的時候有講過說,不管是語音、還是文字、還是圖片,都可以看作是一排向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:49.180" id=30:49.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1849">30:49.180</a></div>
        <div class="t">所以雖然我等一下舉的例子通通都是文字的,但你不要把它想成這個技術只能侷限在文字上,它完全可以用在文字以外的任務上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#30:59.740" id=30:59.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1859">30:59.740</a></div>
        <div class="t">那輸入,第三個case,輸入兩個句子,輸出一個類別。有什麼樣的任務呢?最常見的是natural language inference,它的縮寫是NLI。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:11.740" id=31:11.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1871">31:11.740</a></div>
        <div class="t">natural language inference做的事情是什麼呢?這邊是給機器兩個句子。一個句子叫做premise,就是前提,另外一個句子叫做假設。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:25.580" id=31:25.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1885">31:25.580</a></div>
        <div class="t">機器要做的事情就是從這個前提能不能夠推出這個假設。這個前提跟這個假設是矛盾的嗎?還是不是矛盾的?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:38.380" id=31:38.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1898">31:38.380</a></div>
        <div class="t">在這個例子裡面,我們的前提是有一個人騎著一個馬,然後他跳過了一個壞掉的飛機,聽起來有點怪怪的,但是這個句子真的就是這個樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:49.580" id=31:49.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1909">31:49.580</a></div>
        <div class="t">這是一個Benchmark corpus基礎語料庫裡面的例子,就是有一個人騎著馬跳過了飛機,他在做一個雜耍。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#31:56.940" id=31:56.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1916">31:56.940</a></div>
        <div class="t">這邊的推論是,這個人在一個小餐館裡面,是嗎?不是,所以這個是矛盾的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:14.700" id=32:14.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1934">32:14.700</a></div>
        <div class="t">機器要做的事情就是吃兩個句子,吐出這兩個句子之間的關係。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:21.100" id=32:21.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1941">32:21.100</a></div>
        <div class="t">像這樣子的任務網其實也還蠻常見的,它可以用在什麼地方呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:27.420" id=32:27.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1947">32:27.420</a></div>
        <div class="t">舉例來說,立場分析。給一篇文章,下面有一個人留言,這個留言是贊成這篇文章的立場還是反對這篇文章的立場呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:37.900" id=32:37.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1957">32:37.900</a></div>
        <div class="t">那你就把文章跟留言都丟進模型裡面,模型要預測的就是贊成還是反對。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:45.580" id=32:45.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1965">32:45.580</a></div>
        <div class="t">所以輸入兩個句子,輸出一個類別,也有蠻多的應用的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#32:50.300" id=32:50.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1970">32:50.300</a></div>
        <div class="t">那BERT怎麼解這個問題呢?你就給他兩個句子,我們的模型要輸入兩個句子,兩個句子中間放一個特殊的符號,分隔的符號。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:02.860" id=33:02.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1982">33:02.860</a></div>
        <div class="t">最前面再放CLS這個符號,然後一整串東西丟到BERT裡面,BERT也會給我們另外一整串東西,輸入多長BERT就輸出多長。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:13.340" id=33:13.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=1993">33:13.340</a></div>
        <div class="t">但是我們只取CLS這個部分,丟到linear transform裡面,然後決定說現在輸入這兩個句子,應該輸出什麼樣的類別才是對的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:26.220" id=33:26.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2006">33:26.220</a></div>
        <div class="t">這兩個句子是矛盾的嗎?還是不是矛盾的?如果在NLI裡面,就是要問說這兩個句子是矛盾的,還是不是矛盾的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:35.820" id=33:35.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2015">33:35.820</a></div>
        <div class="t">好,這個是例子三。那一樣,我們需要一些標註的資料才有辦法訓練這個模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:42.780" id=33:42.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2022">33:42.780</a></div>
        <div class="t">一樣,BERT這個部分不再是隨機初始化的,它是用BERT,用Pretrend來初始化的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:48.620" id=33:48.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2028">33:48.620</a></div>
        <div class="t">好,接下來進入第四個case。第四個case其實就是我們在作業的裡面會做的case了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#33:56.300" id=33:56.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2036">33:56.300</a></div>
        <div class="t">如果前面沒聽懂的話,那就算了,第四個case是我們在作業7要做的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:03.260" id=34:03.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2043">34:03.260</a></div>
        <div class="t">作業7要做的是什麼呢?作業7要做的是問答系統,也就是你給機器讀一篇文章,問它一個問題,它真的會給你一個答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:13.980" id=34:13.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2053">34:13.980</a></div>
        <div class="t">但是這邊這個問答不是一般的問答,它是稍微有點限制的問答。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:20.140" id=34:20.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2060">34:20.140</a></div>
        <div class="t">這種問答是extraction-based的QA,也就是我們假設說答案一定出現在文章裡面,答案一定是文章裡面的一個片段。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:32.700" id=34:32.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2072">34:32.700</a></div>
        <div class="t">那怎麼做這種extraction-based的問答系統呢?在這個任務裡面,我們的輸入有文章、有問題,不管是文章還是問題,它都是一個sequence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:47.740" id=34:47.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2087">34:47.740</a></div>
        <div class="t">如果是中文的話,這邊每一個D就代表了一個中文的字,這邊每一個Q就代表了一個中文的字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#34:53.820" id=34:53.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2093">34:53.820</a></div>
        <div class="t">你把D跟Q都丟到QA的模型裡面,它會輸出什麼?我們要它輸出兩個正整數S跟E。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:03.340" id=35:03.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2103">35:03.340</a></div>
        <div class="t">根據這兩個正整數,直接從文章裡面截一個段落出來,就是答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:09.100" id=35:09.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2109">35:09.100</a></div>
        <div class="t">輸入S、輸出E,代表的意思就是說,從這個文章裡面的第S個字到第E個字,串起來就是正確答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:26.220" id=35:26.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2126">35:26.220</a></div>
        <div class="t">這個聽起來非常的狂,但這其實是今天非常標準的做法。我五、六年前第一次聽到說做QA的時候,居然是讀一篇文章,給一個問題輸出兩個正整數,就是答案了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:40.300" id=35:40.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2140">35:40.300</a></div>
        <div class="t">我實在是不可置信,但反正今天這個是一個非常常見的做法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:45.580" id=35:45.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2145">35:45.580</a></div>
        <div class="t">如果你有點聽不懂的話,那講得更具體一點。現在有一篇文章有一個問題,正確答案是gravity。機器怎麼輸出gravity這個正確答案呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#35:58.700" id=35:58.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2158">35:58.700</a></div>
        <div class="t">它要吐出QA的模型,要吐出兩個整數,一個是S等於17,另外一個也是等於17。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:07.900" id=36:07.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2167">36:07.900</a></div>
        <div class="t">gravity它出現在整篇文章裡面的第17個詞彙,S等於17、E等於17,意思就是把第17個詞彙抽出來當作答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:21.020" id=36:21.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2181">36:21.020</a></div>
        <div class="t">或者是舉另外一個例子,今天最後一個問題它的答案是within a cloud,在文章裡面within a cloud是第77到第79個詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:32.300" id=36:32.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2192">36:32.300</a></div>
        <div class="t">那你的模型要做的事情就是輸出77跟79,這兩個正整數,然後這兩個正整數77到79,在文章裡面第77到第79個詞彙,這一段文字就是模型的答案,就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#36:50.060" id=36:50.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2210">36:50.060</a></div>
        <div class="t">這個就是作業7要做的事情。當然我們這邊不是從頭from scratch,就從random initialize的參數來訓練這個QA的模型,我們是有用BERT的pre-trained的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:05.740" id=37:05.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2225">37:05.740</a></div>
        <div class="t">那用BERT的pre-trained怎麼解這種QA的問題呢?這個解法是這個樣子的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:10.780" id=37:10.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2230">37:10.780</a></div>
        <div class="t">BERT這個模型,你要給它看一個問題,給它讀一篇文章,問題跟文章中間有一個特殊的符號,然後前面再放一個CLS的token。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:22.620" id=37:22.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2242">37:22.620</a></div>
        <div class="t">這跟剛才那個natural language inference的case是一模一樣的,只是在natural language inference裡面兩個句子,一個是前提,一個是結論,這邊一個是文章,一個是問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:34.300" id=37:34.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2254">37:34.300</a></div>
        <div class="t">那在這整個任務裡面,你唯一需要從頭開始訓練的東西只有兩個向量,這邊用橙色的向量跟藍色的向量來表示,這兩個向量的長度跟BERT的輸出是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#37:56.780" id=37:56.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2276">37:56.780</a></div>
        <div class="t">假設你BERT的輸出,這邊每個向量是768維的向量,那這兩個向量也就是兩個768維的向量。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:04.940" id=38:04.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2284">38:04.940</a></div>
        <div class="t">那接下來怎麼使用這兩個向量呢?你就把這兩個向量,先把橙色的拿出來,分別跟對應到文章這個部分所輸出的這邊的每一個向量做inner product。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:20.140" id=38:20.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2300">38:20.140</a></div>
        <div class="t">就文章這邊輸入三個token,這邊就輸出三個向量,把這三個向量都去跟橙色的這個向量做inner product,算出三個數值,接下來過softmax得到三個數值。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:36.780" id=38:36.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2316">38:36.780</a></div>
        <div class="t">那這個算inner product這個部分就跟attention有點像,你可以把橙色的部分想成是query,黃色的部分想成是key,那這就是做一個attention。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:48.860" id=38:48.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2328">38:48.860</a></div>
        <div class="t">那接下來看哪裡分數最高,這個地方分數最高嗎?D2所對應的向量乘上橙色的向量以後得到分數最高嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#38:59.740" id=38:59.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2339">38:59.740</a></div>
        <div class="t">那S就等於2,你輸出的起始位置代表起始位置的那個正整數就輸出2。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:09.340" id=39:09.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2349">39:09.340</a></div>
        <div class="t">那藍色的部分也做一模一樣的事情,藍色的部分代表答案結束的位置。我們把藍色的向量跟這邊的每一個黃色的向量跟對應到文章裡面每一個token的黃色的向量做inner product,再做softmax,再看誰的值最大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:29.020" id=39:29.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2369">39:29.020</a></div>
        <div class="t">第三個位置的值最大嗎?那1就等於3,這個時候正確的答案就是D2、D3就結束了。所以你的模型要做的事情其實就是去預測正確答案出現的起始位置,因為答案一定在文章裡面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:44.060" id=39:44.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2384">39:44.060</a></div>
        <div class="t">如果不在文章裡面就不能用這一招,但這邊假設答案一定在文章裡面,所以你要找出正確答案在文章裡面的起始的位置跟結束的位置。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:54.060" id=39:54.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2394">39:54.060</a></div>
        <div class="t">這就是這個QA的模型,這個Question Answering問答系統所要做的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#39:59.740" id=39:59.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2399">39:59.740</a></div>
        <div class="t">當然你需要一些訓練資料才能夠訓練這個模型,那這兩個向量是隨機初始化的,而這個BERT的部分是在pre-trained的時候已經得到它的初始化的參數了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:13.260" id=40:13.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2413">40:13.260</a></div>
        <div class="t">講到這個部分,大家有沒有問題要問呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:16.460" id=40:16.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2416">40:16.460</a></div>
        <div class="t">您說輸入的長度有沒有限制呢?理論上沒有,但實際上有。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:37.260" id=40:37.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2437">40:37.260</a></div>
        <div class="t">理論上,因為BERT的模型是一個transformer的encoder,所以它可以吃很長很長的sequence,你只要能夠做self-attention就行。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:47.980" id=40:47.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2447">40:47.980</a></div>
        <div class="t">但是你知道self-attention的運算量非常的驚人,所以你發現實作上BERT其實沒有辦法吃太長的sequence,你可能最多吃個512就差不多了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#40:57.420" id=40:57.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2457">40:57.420</a></div>
        <div class="t">如果你吃512長的sequence,中間self-attention都已經要產生512x512的attention的metric,那你可能運算就吃不消了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:05.340" id=41:05.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2465">41:05.340</a></div>
        <div class="t">所以實際上它的長度不是無限長的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:09.020" id=41:09.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2469">41:09.020</a></div>
        <div class="t">在助教的程式裡面,已經幫大家處理的這個問題,我們會限制BERT它吃的長度。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:17.580" id=41:17.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2477">41:17.580</a></div>
        <div class="t">而且在訓練的時候,一篇文章很長嘛,那我們會怎麼處理呢?我們把文章結成一小段一小段一小段。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:26.140" id=41:26.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2486">41:26.140</a></div>
        <div class="t">那我們每一次都只會拿一小段出來做訓練,我們不會把整篇文章丟到BERT裡面,因為要的距離太大,訓練起來會有問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#41:57.100" id=41:57.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2517">41:57.100</a></div>
        <div class="t">哇,這個問題太棒了。你就會問說,這個填空題就是填空題啊,那後面不就是要做問答嗎?這兩件事情怎麼會有關係呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:08.940" id=42:08.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2528">42:08.940</a></div>
        <div class="t">這個就是賣個關子,等一下就會試著回答你了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:13.420" id=42:13.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2533">42:13.420</a></div>
        <div class="t">大家還有沒有問題要問?沒有的話,那我們就繼續了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:23.580" id=42:23.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2543">42:23.580</a></div>
        <div class="t">下一頁投影片就告訴你說,BERT這麼知名的模型,這就是全部了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:29.100" id=42:29.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2549">42:29.100</a></div>
        <div class="t">那你可能會覺得說,這個BERT這個pre-train的時候就是做填空題啊,這個我自己應該也有辦法做吧。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:36.860" id=42:36.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2556">42:36.860</a></div>
        <div class="t">我就把那個作業室的程式改一改,也可以讓機器學做填空題啊,那這個厲害在哪裡?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:43.980" id=42:43.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2563">42:43.980</a></div>
        <div class="t">厲害的地方就是,哇,這個你真的是沒辦法自己做了,這個你真的是自己訓練不起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#42:50.300" id=42:50.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2570">42:50.300</a></div>
        <div class="t">首先,當初最早的Google的BERT,它用的資料量也已經非常驚人了,它的資料量有三個billion的詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:00.060" id=43:00.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2580">43:00.060</a></div>
        <div class="t">三個billion的詞彙有多少呢?它是哈利波特全集的三千倍啦,哈利波特全集大概是一百萬個詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:09.020" id=43:09.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2589">43:09.020</a></div>
        <div class="t">那Google在訓練最早的那個BERT的時候,它用的資料量是哈利波特全集的三千倍,所以你處理起來已經有點痛苦了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:19.260" id=43:19.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2599">43:19.260</a></div>
        <div class="t">再來更痛苦的是訓練的過程,為什麼知道訓練的過程很痛苦呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:25.020" id=43:25.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2605">43:25.020</a></div>
        <div class="t">因為我們實驗室有一個同學,他也是一位助教之一,他試圖自己train了一個BERT,看可不可以複現Google的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:34.220" id=43:34.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2614">43:34.220</a></div>
        <div class="t">所以在這個圖上面,縱軸代表的就是Groove的分數,我們剛才講過Groove對不對,有九個任務,九個任務平均起來的分數叫做Groove的分數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:45.980" id=43:45.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2625">43:45.980</a></div>
        <div class="t">這是Google最原始的BERT的Groove的分數,是藍色這一條線。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#43:49.820" id=43:49.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2629">43:49.820</a></div>
        <div class="t">我們的目標其實不是做BERT,而是做ALBERT,ALBERT是一個進階的版本,它是橙色這一條線,藍色這一條線是我們自己訓練的ALBERT。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:01.020" id=44:01.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2641">44:01.020</a></div>
        <div class="t">我們其實訓練的還不是最大的版本,BERT有Base的版本跟Large的版本,Large的版本我們要自己train真的是train不動,所以我們試著train最小的版本,看看能不能夠跟Google得到的結果一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:16.380" id=44:16.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2656">44:16.380</a></div>
        <div class="t">Google這邊,你可能會說三個billion詞彙的data好像很多,其實因為它是unlabeled的資料,所以你從網路上隨便爬一堆文字就有這麼多資料,所以你要爬這個等級的資料並沒有很困難,很難的是訓練的部分。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:35.260" id=44:35.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2675">44:35.260</a></div>
        <div class="t">這個橫軸就是訓練的過程,參數update幾次呢?update一百萬次,那這要花多長的時間呢?用TPU跑了八天啊,所以這個TPU都要跑八天,如果你用colab做的話,這個至少要跑兩百天以上,你跑到明年你都跑不出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#44:55.500" id=44:55.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2695">44:55.500</a></div>
        <div class="t">所以你知道BERT這種模型,你在自己家裡真的是沒有辦法做,還好作業只是要微調它,微調它你就有辦法用colab做,用colab微調BERT的話,大概半個小時到一個小時你可以微調完,但你要從頭開始訓練,訓練它做填空題這件事情,哇,太花時間了,你不可能用colab自己把它做出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:19.820" id=45:19.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2719">45:19.820</a></div>
        <div class="t">那你可能會問說,為什麼我們要自己訓練一個BERT呢?反正Google都已經有訓練出BERT了,而且這些pre-trained model都是公開的,我們自己訓練一個,而且結果跟Google的BERT差不多,到底有什麼意義呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:35.820" id=45:35.820>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2735">45:35.820</a></div>
        <div class="t">那這邊想要做的事情呢,其實是想要建立BERT胚胎學。BERT胚胎學指的是什麼意思呢?我們知道BERT的訓練過程需要耗費非常大的運算資源,所以我們想要知道說有沒有什麼可能去節省這個運算資源,有沒有可能讓它訓練得更快一點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#45:57.740" id=45:57.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2757">45:57.740</a></div>
        <div class="t">那想要知道怎麼讓它訓練得更快一點,也許我們先從觀察它的訓練過程開始做起。過去從來沒有人觀察過BERT的訓練過程,因為對Google的paper而言它就是直接告訴你說我有這個BERT,然後它在各個任務上都做得很好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:14.780" id=46:14.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2774">46:14.780</a></div>
        <div class="t">那實際上,在訓練BERT這個學填空題的過程中,到底BERT學到了什麼事情?這個過程中,它什麼時候學會填動詞?什麼時候學會填名詞?什麼時候學會填代名詞?沒有人去研究過這些事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:30.540" id=46:30.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2790">46:30.540</a></div>
        <div class="t">所以我們自己trained一個BERT以後,我們就可以觀察BERT在什麼時候學會填什麼樣的詞彙,它的填空的能力到底是怎麼增進的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:41.860" id=46:41.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2801">46:41.860</a></div>
        <div class="t">那這個細節就不是這門課的主軸了,所以這邊就不講了,我們就把論文的連結放在這邊給大家參考。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:49.540" id=46:49.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2809">46:49.540</a></div>
        <div class="t">這邊爆雷一下,就是得到的結論跟你直覺想像的是不太一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#46:56.580" id=46:56.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2816">46:56.580</a></div>
        <div class="t">我們還沒有講到為什麼BERT會好,不過我們再補充說明一件事情,就是剛才講的那些任務都沒有包括sequence-to-sequence的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:09.460" id=47:09.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2829">47:09.460</a></div>
        <div class="t">如果我們今天要解的任務是sequence-to-sequence的model,怎麼辦呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:15.100" id=47:15.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2835">47:15.100</a></div>
        <div class="t">BERT只有pre-train encoder,有沒有辦法pre-train sequence-to-sequence的model的decoder呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:21.740" id=47:21.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2841">47:21.740</a></div>
        <div class="t">可以的,那怎麼做?你就說我有一個sequence-to-sequence的model,有一個transformer,還有一個encoder,有一個decoder,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:29.460" id=47:29.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2849">47:29.460</a></div>
        <div class="t">輸入是一串句子,輸出是一串句子,中間用cross-attention連接在一起。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:34.900" id=47:34.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2854">47:34.900</a></div>
        <div class="t">你給這個encoder的輸入,你故意做一些擾動,弄壞,等一下會具體的跟你講說什麼叫做弄壞。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:44.300" id=47:44.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2864">47:44.300</a></div>
        <div class="t">然後decoder是什麼呢?decoder就是我希望輸出的句子,跟弄壞前是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#47:51.940" id=47:51.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2871">47:51.940</a></div>
        <div class="t">encoder看到弄壞的結果,然後decoder要輸出還原弄壞前的結果,train下去就是pre-train一個sequence-to-sequence的model。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:03.580" id=48:03.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2883">48:03.580</a></div>
        <div class="t">那怎麼弄壞呢?就有各種不同的方法,有一篇paper叫做Mask,Mask裡面就說弄壞的方法就跟BERT一樣,就是把一些地方蓋起來就結束了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:16.020" id=48:16.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2896">48:16.020</a></div>
        <div class="t">後來還有各式各樣弄壞的方法,比如說把一些詞彙刪掉,把詞彙的順序弄亂,把詞彙的順序做一個旋轉,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:25.780" id=48:25.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2905">48:25.780</a></div>
        <div class="t">或者是說既插入Mask,又把一些詞彙弄掉,總之有各種不同的方法把輸入的句子弄壞,然後再請sequence-to-sequence的model把它還原回來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:38.780" id=48:38.780>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2918">48:38.780</a></div>
        <div class="t">有一篇paper叫做BERT,他就是把這些方法一股腦地都用上去,發現說都用可能結果是比較好的,可以比Mask還要更好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#48:49.500" id=48:49.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2929">48:49.500</a></div>
        <div class="t">我這邊就想問一個問題,為什麼他不是芝麻街的人物了?你可能會問說,有這麼多弄壞的方法,有這麼多Masking的方法,哪種方法比較好呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:07.360" id=49:07.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2947">49:07.360</a></div>
        <div class="t">也許你想自己做一些實驗來嘗試一下。這邊告訴你說,你已經不用做了,Google都幫你做完了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:13.920" id=49:13.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2953">49:13.920</a></div>
        <div class="t">有一篇paper叫做T5,T5是什麼的縮寫呢?它是transfer-text-to-text-transformer,有五個T,所以叫T5的縮寫。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:24.880" id=49:24.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2964">49:24.880</a></div>
        <div class="t">這個T5裡面,他就是做了各式各樣的嘗試,你可以想得到的組合他都做過了,paper長達67頁,你自己回去再慢慢讀,看看得到什麼樣的結論。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:37.800" id=49:37.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2977">49:37.800</a></div>
        <div class="t">這個T5,他是訓練在一個叫做Colossal Clean Code Corpus上面的data set上。Colossal就是科羅索,Colossal就是非常巨大的意思,合起來叫做C4,所以你用C4訓練T5,而且大家都是命名大師,命名都非常的厲害。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#49:59.120" id=49:59.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=2999">49:59.120</a></div>
        <div class="t">這個C4有多大呢?C4是公開的資料集,你可以載到它,它是公開的。但是它的原始檔案的大小有7T,你載得下來你也不知道放哪裡。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:12.880" id=50:12.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=3012">50:12.880</a></div>
        <div class="t">而且它載下來以後,Google提供那個script去做preprocessing,去做前處理。它有加一個說明說,試出這個Corpus的網站上有加一個說明說,前處理用一張GPU要花355天。你載下來,你要前處理,也是有問題的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#50:32.960" id=50:32.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=gh0hewYkjgo&t=3032">50:32.960</a></div>
        <div class="t">所以你發現說今天做deep learning,用的資料量還有模型真的都非常的驚人。</div>
    </div>
    
</body>
</html>   