<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Tuning Hyperparameters</h2><a href=https://www.youtube.com/watch?v=kyX29rUntjM><img src=https://i.ytimg.com/vi_webp/kyX29rUntjM/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=0">00:00.000</a></div>
        <div class="t">我們來講一下調hyperparameter這件事情。大家都知道說,做deep learning,雖然表面上好像在做一些很潮的事,指導教授以為在解一個optimization function,但是其實你就是在調參數啦,對不對?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:21.000" id=00:21.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=21">00:21.000</a></div>
        <div class="t">因為這個過去啊,大家並不太覺得deep learning work,所以你今天用一個neural network based的方法得到的結果不好,指導教授也不說什麼。但是因為現在呢,在這個時間點,大家都已經被植入了deep learning會work的思想剛毅。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:37.000" id=00:37.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=37">00:37.000</a></div>
        <div class="t">所以大家都相信deep learning是會work的。所以今天指導教授給你一個test,然後呢,你做了一下SVM,嗯,得到一個performance。你做一下deep learning,得到一個比SVM差,指導教授說你做錯了,你回去沒有做出一個比SVM好的結果來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:51.000" id=00:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=51">00:51.000</a></div>
        <div class="t">然後你就會回去努力調參數,反正deep learning有很多參數可以調,你總是可以調到一個贏過SVM的。所以今天在做deep learning的時候,其實你主要就是在調參數啦,不要否認這件事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:07.000" id=01:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=67">01:07.000</a></div>
        <div class="t">那我們知道說deep learning,training其實表面上是用gradient descent,但其實指導教授都是用graduate student descent來train deep network的。叫你把它做出來,然後你就會回去把它做出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:24.000" id=01:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=84">01:24.000</a></div>
        <div class="t">好,那我們來講一下調參數這件事情。那最直覺的調參數的方法叫做research,就假設你現在有兩個參數要調,一個是network有多深,另外一個是network有多寬,那你就把所有的組合都重組出來,那可能有上千上萬種組合,然後一個一個去試,然後用development search決定說哪一個最好,結束。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:50.000" id=01:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=110">01:50.000</a></div>
        <div class="t">那有另外一個方法叫做random search,random search就是說,我們不要循規蹈矩的把每一個可能性都試過,我們用random sample的方式,sample出我們想要測試的test.</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:04.000" id=02:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=124">02:04.000</a></div>
        <div class="t">舉例來說,這邊有五四二十個點,那我們不要五四二十點都做,我們從五四二十個點裡面抽一些點出來試,看哪一個點在validation上的結果最好,就選哪一個點就好了,這個叫做random search。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:18.000" id=02:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=138">02:18.000</a></div>
        <div class="t">那random search表面上聽起來好像怪怪的,好像沒有什麼特別厲害的地方,但是其實在deep learning裡面,random search通常是蠻有效率的,為什麼呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:30.000" id=02:30.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=150">02:30.000</a></div>
        <div class="t">這邊基本的假設是說,不同的方法,它們之間的差距,就是說今天你把所有你要search的方法,通通拿出來在validation上做測試,其實top A的那些方法,它們的performance可能沒有太大的差距。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:52.000" id=02:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=172">02:52.000</a></div>
        <div class="t">因為今天在做deep learning的時候,通常只有某幾個參數對你的結果有特別決定性的影響,有很多參數對你的結果的影響是不大的,所以今天在所有的參數組合裡面,有很多組參數,它的performance其實都是一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:07.000" id=03:07.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=187">03:07.000</a></div>
        <div class="t">你今天performance最好的那幾組的參數組合,它的結果可能都是大同小異的,所以其實沒有必要掃過所有的參數組合,舉最好的那一組出來,你其實只要選前K名的其中一個出來,其實結果應該就夠好了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:25.000" id=03:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=205">03:25.000</a></div>
        <div class="t">這是基本的假設。在這個前提之下,假設我們有K個點,假設我們現在有K個點,我們想要做free search,那我們從K個點裡面隨便選一個點,它落在top K的機率是多少呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:46.000" id=03:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=226">03:46.000</a></div>
        <div class="t">很簡單,就是大K除以N。我們隨便選一個點落在top K裡面的機率就是大K除以N。接下來,我們sample X次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:00.000" id=04:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=240">04:00.000</a></div>
        <div class="t">我們sample X次,在sample的X次裡面,我們有sample到落在top K裡面的機率是多少呢?這個是國中數學。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:18.000" id=04:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=258">04:18.000</a></div>
        <div class="t">我們先計算每一次sample不到top K的機率是E減大K除以N。連續X次都sample不到的機率就是E減大K除以N的X次方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:33.000" id=04:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=273">04:33.000</a></div>
        <div class="t">sample到top K的機率就是E減大K除以N的X次方。我們希望這個機率大於90%,如果給你K跟N,你就可以輕易地把X推出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:50.000" id=04:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=290">04:50.000</a></div>
        <div class="t">舉例來說,如果今天N等於100,你有100個點,你是想要去search的,那現在你希望說只要選到top10,你就心滿意足了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:03.000" id=05:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=303">05:03.000</a></div>
        <div class="t">那X呢,如果你要確保說有超過90%的機率,你一定可以sample到top10的結果,你只需要sample230次,你其實不需要把1000個點統統看過。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:17.000" id=05:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=317">05:17.000</a></div>
        <div class="t">或者是更進一步,假設只要sample top100,你就滿足了,那你sample的次數就可以降到只要sample22次,就可以保證有超過90%的機率,你可以sample到top K的參數組合。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:34.000" id=05:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=334">05:34.000</a></div>
        <div class="t">因為今天E減K除以N,這邊的exponential項,它的下降是非常快的,所以其實你不需要sample太多次,假設你今天只要sample出現在top K裡面的結果,你不需要sample太多次,就可以sample到你想要的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:54.000" id=05:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=354">05:54.000</a></div>
        <div class="t">所以其實做random的search也是一個非常有效率的方式。那有另外一個做法叫做model-based hyperparameter optimization,這個做法就叫做bation的optimization。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:11.000" id=06:11.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=371">06:11.000</a></div>
        <div class="t">那怎麼做呢?這個細節我們今天就不細講,我就只講一下它的概念。假設這個橫軸代表說你要去調的參數,比如說learning rate,那當然這邊只有顯示一維代表你只要調一個參數,但實作上你要調的參數往往有數十個,所以它其實是在一個高維的空間中做bation的optimization。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:35.000" id=06:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=395">06:35.000</a></div>
        <div class="t">假設現在橫軸是learning rate,我們選擇這一個learning rate,然後去跑一下結果,得到一個accuracy。我們再選另外一個learning rate,再跑一下結果,再得到一個accuracy。那現在我們就得到兩個accuracy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:53.000" id=06:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=413">06:53.000</a></div>
        <div class="t">接下來我們就認一個model,至於這個model是什麼你就自己決定。我們認一個model,估測說given,這就是一個regression的problem,認一個model,估測說如果given不同的learning rate,那我們期待的accuracy可以有多大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:13.000" id=07:13.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=433">07:13.000</a></div>
        <div class="t">認一個regression的model,根據這兩筆training data把它認出來。這個regression的model通常會有一個bation的model,bation的model可以告訴我們說,在這些region,那個model的confidence有多大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:26.500" id=07:26.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=446">07:26.500</a></div>
        <div class="t">舉例來說,因為這兩個點是一致的,所以這兩個點的confidence就非常大。這個位置因為沒有sample的點,所以這個位置的confidence就非常小。這個藍色的區域代表今天model在估測的時候覺得可能的區間,藍色的區域越大就代表confidence越小。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:45.500" id=07:45.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=465">07:45.500</a></div>
        <div class="t">接下來我們要根據這個曲線,根據這個estimation的結果,選下一個點。怎麼選呢?取決於兩件事。一個是,我們希望找一組比較好的參數組合,我們希望找一組根據我們的model估測出來,它會得到比較好的結果的參數組合,這是第一個條件。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:09.500" id=08:09.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=489">08:09.500</a></div>
        <div class="t">第二個條件是,假設我們是這麼做,那machine已經知道說,這個點它的正確率最高,那每次選要estimate那個正確率的時候,它就只會選在這個區域,它就只會選在這個區域,這不是我們要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:25.500" id=08:25.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=505">08:25.500</a></div>
        <div class="t">我們也希望machine做一些類似exploration這樣的事情,我們希望machine做一些探查,去做一些搜尋,看看說,在這個參數,在這個hyperparameter的空間裡面,有沒有哪些地方是我們沒有探查到的。那沒有探查到的地方,我們應該要探查看看,看如果設那一組參數組合會得到什麼樣的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:46.500" id=08:46.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=526">08:46.500</a></div>
        <div class="t">所以,今天會同時考慮一件事,兩件事情,一件事情是,根據這個模型估測出來的結果,另外一個是,這個模型它的confidence,那我們希望選一個估測出來正確率高,但是confidence低的地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:01.500" id=09:01.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=541">09:01.500</a></div>
        <div class="t">那根據估測的正確率和confidence,你會訂出一個acquisition的function,就是這邊綠色的這個function,有選綠色的function值最高的地方,比如說在這個點。好,接下來呢,選了這個點,比如說這個learning rate以後,就再去跑一下你的model,再去跑一下你的model,告訴你說,噢,你得到這個accuracy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:22.500" id=09:22.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=562">09:22.500</a></div>
        <div class="t">你現在呢,你就有三筆training data去做你的regression的problem,你再得到一條regression的線,還有得到在每一個區域這個regression的confidence。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:33.500" id=09:33.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=573">09:33.500</a></div>
        <div class="t">然後接下來呢,就反覆那個process,舉例來說,接下來sample在這個地方,你就得到新的點,然後你這個regression的estimate呢,就會越來越準,這個是patient的optimization。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:46.500" id=09:46.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=586">09:46.500</a></div>
        <div class="t">那這個方法到底work不work呢?我有點難告訴你說它是work的,因為這個方法的好壞就取決於你的那個regression的model做得好不好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:56.500" id=09:56.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=596">09:56.500</a></div>
        <div class="t">而那個regression的model,它也是一個假設啊,這也是hyperparameter啊,那這個regression的model,那這個regression的model到底合不合理,你也是要憑著直覺測出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:06.500" id=10:06.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=606">10:06.500</a></div>
        <div class="t">所以這個方法到底好或不好,也是取決於你那個regression的model到底好還是不好。對,然後接下來呢,就進入下一個階段。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:16.500" id=10:16.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=616">10:16.500</a></div>
        <div class="t">剛才呢,呃,試用一個regression的model,也許可以做用更複雜的model,比如說用RNN來決定network的架構。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:25.500" id=10:25.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=625">10:25.500</a></div>
        <div class="t">Google現在很流行呢,用machine呢,來run machine,用network呢,來run network。哦,所以,假設你今天要做一個RNN,怎麼做?呃,假設你要train一個CNN,怎麼做?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:38.500" id=10:38.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=638">10:38.500</a></div>
        <div class="t">你先train一個神奇的RNN,這個RNN它的output就是數字,它的第一個output就代表第一個layer的filter的高,然後接下來output第一個layerfilter的寬,接下來output你的stride要多少,然後output說要有幾個filter,這是第一層,然後接下來output第二層,然後就一直output下去。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:02.500" id=11:02.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=662">11:02.500</a></div>
        <div class="t">把它所有output的數字收集起來,你就得到了一個CNN的架構。那這個RNN,它的架構就跟我們作業2用的那個RNN是一模一樣的,是一模一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:15.500" id=11:15.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=675">11:15.500</a></div>
        <div class="t">就RNN每個time state的輸出,會被當作下一個time state的input,每個time state的輸出,會被當作下一個time state的input。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:23.500" id=11:23.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=683">11:23.500</a></div>
        <div class="t">你有這個RNN,用這個RNN去sample出一排數字,你就得到一個CNN。那這個RNN怎麼來呢?這個RNN是這樣來的,我們得到一個CNN以後,你就拿它去你的training set上train一下,然後在validation set上你就可以得到一個accuracy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:42.500" id=11:42.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=702">11:42.500</a></div>
        <div class="t">然後呢,這個accuracy就是這個RNN的reward,我們用reinforcement learning的方法來應train這個RNN。雖然我們還沒有講過reinforcement learning,但是它的基本概念就是,你就去調這個RNN的參數,希望它得到的reward的期望值越大越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:59.500" id=11:59.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=719">11:59.500</a></div>
        <div class="t">反正reinforcement learning就是你今天可以去調你的RNN的參數,讓它可以得到的期望值越大越好。那你用同樣的方法呢,其實也可以設計LSTM的架構,這個我們之前上課的時候已經講過了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:14.500" id=12:14.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=734">12:14.500</a></div>
        <div class="t">那其實這樣的方法呢,可以被視為是一種meta learning或者是learn-to-learn的方法。好,這邊是設計了CNN跟LSTM的架構,也可以設計activation function,剛才那個switch就是這樣子來的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:31.500" id=12:31.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=751">12:31.500</a></div>
        <div class="t">你先假設說這個activation function有固定的樣子,activation function就是輸入一個值,輸出一個值嘛,那先假設說呢,輸入這個值先把它duplicate三份,然後前面兩個值通過一個unary的function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:47.500" id=12:47.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=767">12:47.500</a></div>
        <div class="t">unary的function有哪些呢?列一大堆出來,有x,有負x,有x的絕對只有平方三方,一大堆,列一大堆。然後通過一個binary的function,binary的function有哪些呢?可以相加,可以相乘,可以相減,可以相除,列一大堆。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:02.500" id=13:02.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=782">13:02.500</a></div>
        <div class="t">再通過一個unary的function,然後第三份也通過unary的function,再一起通過binary的function得到最後的output。那在這每一個block裡面,unary的function跟binary的function要選什麼呢?把它當作RNN的output,讓RNN告訴你說到底要選哪一個unary或者是binary的function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:25.500" id=13:25.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=805">13:25.500</a></div>
        <div class="t">在這邊用的,這個RNN就跟你的作業是一模一樣的,只是在你做作業的時候,你RNN的output是各種不同的詞彙,對不對?是Lexical裡面各種不同的詞彙。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:35.500" id=13:35.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=815">13:35.500</a></div>
        <div class="t">在這邊,在run activation function的時候,RNN的output就是有可能的unary function跟有可能的binary function。然後接下來你就硬圈下去,硬圈下去,RNN先產生一個activation function,然後這個activation function的run下得到accuracy,然後update RNN,再產生新的activation function,再update RNN,就這樣不斷地循環,最後就可以找出一個最好的activation function,就是switch。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:03.500" id=14:03.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=843">14:03.500</a></div>
        <div class="t">在switch那篇paper裡面,他們也有講說,他們找到的最好的八個activation function就列在這邊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:13.500" id=14:13.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=853">14:13.500</a></div>
        <div class="t">這些activation function有什麼特色呢?有一個特色是,他們好像都有直接使用input x。另外一個特色就是,有一些activation function居然是有週期性的,這個也是作者相當自豪的一點,因為正常在設計activation function的時候,你絕對不會設計這種activation function,舉例來說像這個綠色的這樣的activation function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:42.500" id=14:42.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=882">14:42.500</a></div>
        <div class="t">這種activation function有些奇怪的地方絕對不太make sense,因為你input在這個地方,在這個地方,在這個地方,它的output都是一樣的,machine就會分辨不出到底是什麼樣的input,反正用RNN出來就是這個樣子,machine超越人,設計出來的activation function就是這麼回事,就是你沒有辦法想像的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:06.500" id=15:06.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=906">15:06.500</a></div>
        <div class="t">那還可以拿來決定learning rate,我們知道說learning rate有一些決定的strategy,比如說RNN是proper,addon等等,其實這些不同的learning rate的strategy有一個共同的表示是,舉例來說,SGD,我們大家都熟知的SGD,就是input G代表那個gradient,把gradient乘上identity,就是SGD。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:32.500" id=15:32.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=932">15:32.500</a></div>
        <div class="t">那RNN是proper呢?RNN是proper是gradient一樣乘上identity,但是這邊有一個Vhat,Vhat是什麼?Vhat是過去的gradient的平方的estimation,過去的gradient的平方的estimation,就等於是你把過去的gradient的平方和把它平均起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:54.500" id=15:54.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=954">15:54.500</a></div>
        <div class="t">那把這個平方和除成開根號,然後再把G除上這個開根號的結果,就是RNN是proper,對不對?如果你熟悉的話。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:07.500" id=16:07.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=967">16:07.500</a></div>
        <div class="t">那addon呢?addon跟RNN是proper唯一不一樣的地方就是把gradient換成N,這個N就是momentum,momentum其實就是gradient的和,gradient的平均,V是gradient的平方的estimation,N是gradient的estimation,把N除掉V的開根號,就得到addon。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:29.500" id=16:29.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=989">16:29.500</a></div>
        <div class="t">好,那我們怎麼知道說什麼時候要用N,什麼時候要用V,什麼時候要用開根號,什麼時候要做什麼呢?我們不知道,所以怎麼辦?這樣machine來決定要怎麼調learning rate,那怎麼做呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:42.500" id=16:42.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1002">16:42.500</a></div>
        <div class="t">這邊一樣認一個RNN,它的第一個輸出就代表了第一個operand,那operand有什麼呢?有gradient,有gradient平方,有三方,有momentum,有平方的estimation,還有各種奇怪的東西,你也可以用addon跟RNN是proper的open。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:59.500" id=16:59.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1019">16:59.500</a></div>
        <div class="t">再輸出第二個operand,再輸出第一個unary的function,這邊有各種unary的function,再輸出第二個unary的function,然後輸出binary的function,這邊有各種不同binary的function,你就可以製造一個新的learning的strategy,新版的addon,新版的RNN是proper。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:19.500" id=17:19.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1039">17:19.500</a></div>
        <div class="t">那最後得到什麼結果呢?最後得到一個新的learning的strategy,叫做powersign,而且它那個結果疑似,其實它沒有做很完整的實驗,但看起來疑似可以transfer到new的新的text上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:34.500" id=17:34.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1054">17:34.500</a></div>
        <div class="t">它做reinforced learning的時候,machine是train在image的text上,但是design出來的learning strategy好像可以apply在其他,比如說translation,language model,text上面,好像也可以得到不錯的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:52.500" id=17:52.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1072">17:52.500</a></div>
        <div class="t">好,然後它這邊是舉其中一個實驗,這個實驗是試在這個月牙型的loss function上面,而它是一個對gradient descent來說經典的難題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:05.500" id=18:05.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1085">18:05.500</a></div>
        <div class="t">這邊試了不同的方法,包括SGD、momentum、addon跟RNN是proper,發現說SGD、addon還有RNN是proper其實都沒有辦法從開始的地方走到終點,這個地方是終點,這三個方法都走不到,那momentum可以走到。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:20.500" id=18:20.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1100">18:20.500</a></div>
        <div class="t">那powersign跟momentum一樣強,它其實走了一個很崎嶇的路徑,但是它最後也走到了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:26.500" id=18:26.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1106">18:26.500</a></div>
        <div class="t">而且很好奇說powersign長什麼樣子,它其實也沒有很複雜,它長這樣,它還蠻單純的,我們把gradient前面乘上exponential的gradient的sign跟momentum的sign。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:41.500" id=18:41.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1121">18:41.500</a></div>
        <div class="t">這次聽起來蠻直覺的,如果gradient跟momentum同向,那exponential的指數項就是正,那你的gradient就會乘上一個正的值,就一個比較大的learning rate。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:53.500" id=18:53.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1133">18:53.500</a></div>
        <div class="t">如果你今天你的gradient跟momentum反向,那指數項就是負的,exponential負的就是一個小於1的值,所以你的learning rate就會減小,所以這個聽起來蠻直觀的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:05.500" id=19:05.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1145">19:05.500</a></div>
        <div class="t">這些方法雖然聽起來很潮,但是好孩子也沒辦法學就是了,你在家裡也沒辦法自己嘗試,你可能會想說,我現在在作業2,還有一點點時間看要不要自己發明一些新的RNN的結構,我看你還是洗洗睡了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:21.500" id=19:21.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=kyX29rUntjM&t=1161">19:21.500</a></div>
        <div class="t">其實你如果看產生SVM的架構單元paper,它說它用了800張GPU,你這個實在是好孩子沒辦法學的一個task。</div>
    </div>
    
</body>
</html>   