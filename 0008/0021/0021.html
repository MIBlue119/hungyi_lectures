<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>Video Generation by GAN</h2><a href=https://www.youtube.com/watch?v=TN8cJiomk_k><img src=https://i.ytimg.com/vi_webp/TN8cJiomk_k/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=0">00:00.000</a></div>
        <div class="t">有沒有用GetLiveGenerateVideo的。然後回想一下,我發現其實是有的。這是那個ICLR2016的paper。你知道ICLR2016那不是去年的事嗎?現在覺得去年的東西就好像很舊很舊很舊的樣子,想不太起來啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:17.000" id=00:17.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=17">00:17.000</a></div>
        <div class="t">所以是有的。那怎麼做呢?它的概念其實就是conditional game的概念。你就弄一個generator,那這個generator它先吃一段video的前幾個fret,然後它會generate接下來的fret。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:34.000" id=00:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=34">00:34.000</a></div>
        <div class="t">那discriminator呢?discriminator就是吃一段video,然後判斷說這一段video裡面的最後一個fret是generated的還是real的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:46.000" id=00:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=46">00:46.000</a></div>
        <div class="t">就是它input這一段video前面的fret都是真的,只有最後一個fret可能是fake的或者是real的。只有最後一個fret可能是fake的或者是real的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:04.000" id=01:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=64">01:04.000</a></div>
        <div class="t">generator就會把它的input跟它的output丟給discriminator,然後希望它可以騙過discriminator,希望generator的input和output合起來可以讓discriminator給一個比較高的分數。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:20.000" id=01:20.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=80">01:20.000</a></div>
        <div class="t">我現在講已經有點confuse了,因為剛才在energy base game裡面d的分數是real的,但是通常在w game裡面高的分數是好的,所以這邊真的是有點confuse,但大家知道我的意思就好了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:35.000" id=01:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=95">01:35.000</a></div>
        <div class="t">那另外一方面還要有另外一個criterion,就是讓generator output的image跟ground truth,因為你有ground truth嘛,因為你收集了很多video,所以你知道說這四個fret後面接的第五個fret是什麼,所以你會希望說generator output跟ground truth越接近越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:51.000" id=01:51.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=111">01:51.000</a></div>
        <div class="t">至於什麼叫最接近,你可以用不同的方法來evaluate什麼叫做最接近。那這跟我們講conditional game的時候是一模一樣的,是非常非常像的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:04.000" id=02:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=124">02:04.000</a></div>
        <div class="t">然後為什麼需要用game來產生video呢?這邊有一個例子。為什麼用game來產生video呢?因為你可以想像說今天給同一段video,比如說一個人直直的走過來,接下來他可以往左轉也可以往右轉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:28.000" id=02:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=148">02:28.000</a></div>
        <div class="t">對一般的training來說,如果你只是直接根據training data認一個generator,那對generator來說,往左轉是對的,往右轉也是對的,他最後就會產生一個video是往左轉的影像跟往右轉的影像合起來,結果就會壞掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:48.000" id=02:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=168">02:48.000</a></div>
        <div class="t">如果你用game的話,就可以避免這種情形。你可以往左轉也可以往右轉都是對的,但你只能選一個,兩個合起來結果就是差的。我把這個video的link放在投影片的第一頁,是一個GitHub的code,你可以直接載下來就可以玩。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:06.000" id=03:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=186">03:06.000</a></div>
        <div class="t">這個GitHub的code做的事情是train小精靈,generate小精靈的電丸,接下來會發生什麼事。這個結果是沒有用game的。如果你有simulator的話,你要sample多少video就可以sample多少video。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:26.000" id=03:26.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=206">03:26.000</a></div>
        <div class="t">但是現在呢,他可以往左走也可以往右走,這兩件事情是同時發生的,你就可以產生這種殘影。所以如果你沒有用game的話,你就容易產生殘影。所以你可以了解說,如果你要產生真正realistic的video的話,你是需要game。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:46.000" id=03:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=226">03:46.000</a></div>
        <div class="t">以下是GitHub的code所附的一些video。第一個column是光train,第二個column是用game train,第三個column是沒有用game train。仔細看,如果沒有用game train的話,你就很容易出現殘影,比如說這個地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:06.000" id=04:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=246">04:06.000</a></div>
        <div class="t">他就會很容易走一走就分解了。如果用game的話,就比較不會發生這種情況。雖然有些地方還是會壞掉,但是比如說遠看,有一些小精靈走一走就會憑空不見了,有一些怪走一走就會憑空不見了,不過至少不會出現太多的殘影。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:32.000" id=04:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=272">04:32.000</a></div>
        <div class="t">其實大家應該非常非常熟悉吧,每一個game的talk都有這張圖。這個圖就是做super resolution,你就給machine一張比較low resolution的image當作generator的input,generator output就是high resolution的image,你就用game train一下就行了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:54.000" id=04:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=294">04:54.000</a></div>
        <div class="t">這篇paper裡面,如果我沒有記錯的話,他不是conditional game,也就是說discriminator只有看generator output的image,他沒有看fake的image,他只看generator的output而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:08.000" id=05:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=308">05:08.000</a></div>
        <div class="t">不只可以產生video image,也可以產生語音,也可以做語音合成。這樣相關的研究現在也是很多了。我在今年三月的icast看到兩篇,我相信馬上就會滿坑滿谷。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:28.000" id=05:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=328">05:28.000</a></div>
        <div class="t">在這些語音合成的paper裡面,他們其實都不是直接核語音。我覺得直接用game核語音可能還有難度,你直接run一個generator,input文字,output就是語音合成的結果,有點難。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:43.000" id=05:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=343">05:43.000</a></div>
        <div class="t">他們的做法其實都是拿一個現成的語音合成器。現成的語音合成model現在遇到最大的問題就是,語音合成出來的聲音都比較平板。你會發現現成的語音合成器,他合成出來的聲音都比較糊、比較平板。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:59.000" id=05:59.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=TN8cJiomk_k&t=359">05:59.000</a></div>
        <div class="t">這就跟我們剛才看到的小精靈的例子一樣,你沒有game,你直接train下去,output東西就很容易糊掉,所以在語音上也是一樣。所以他們的做法就是有一個現成的generator,但是多加一個game的discriminator去finetune現成的generator,就可以得到更生動的聲音。</div>
    </div>
    
</body>
</html>   