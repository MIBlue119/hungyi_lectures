<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>ML Lecture 9-2: Keras Demo 2</h2><a href=https://www.youtube.com/watch?v=Ky1ku1miDow><img src=https://i.ytimg.com/vi_webp/Ky1ku1miDow/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=0">00:00.000</a></div>
        <div class="t">好,那這個是我們上一次做失敗的code,這樣子。我們要做手寫數字辨識,那我們疊的network呢,它的這個hidden layer的size就是689,然後用sigmoid function。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:28.000" id=00:28.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=28">00:28.000</a></div>
        <div class="t">我本來有疊十層,疊十層其實也不work,就把它註解掉。好,那用的loss function呢,是NSE,然後用了SGD,等等等等。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:39.600" id=00:39.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=39">00:39.600</a></div>
        <div class="t">好,那結果是差的,怎麼辦?你自己在train network的時候常常會遇到這個問題,doge network train下去,結果是差的。這時候你就會去問老師說該怎麼辦。每次有人問我這個問題的時候,我第一個會問你的就是,你在training set上得到多少的performance?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:57.600" id=00:57.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=57">00:57.600</a></div>
        <div class="t">你可能會說,怎麼不是問testing set上得到多少performance,而是問training set上得到多少performance呢?因為如果你有看錄影的話,你會知道說,今天deep learning在training的時候,你其實非常容易train壞掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:13.960" id=01:13.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=73">01:13.960</a></div>
        <div class="t">它跟其他方法不一樣,它跟SVM不一樣,SVM是解一個combat optimization problem,所以你每次找的時候,它都可以找到一個optimal solution,也就是當你用SVM的時候,SVM會竭盡全力給你它可以得到最好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:29.200" id=01:29.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=89">01:29.200</a></div>
        <div class="t">但deep learning不是這樣的方法,它雖然很powerful,但它其實就跟噴火龍一樣,你不見得能夠叫得動它。所以,你需要看一下你的training set,來看看說你到底有沒有把它的能力做起來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:44.440" id=01:44.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=104">01:44.440</a></div>
        <div class="t">你可能會想說,它在training set上performance好,可能只是overfitting。沒錯,它可能只是overfitting,但是如果連在training set上overfitting都做不到,你更遑論去做在testing set上能夠舉一反三了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:59.740" id=01:59.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=119">01:59.740</a></div>
        <div class="t">所以,我們先讓它至少在training set上得到好的結果。那training set上得到好的結果,有可能可以舉一反三到testing set上,也有可能overfitting,我們不知道。但是,如果你在training set上都沒有好的結果,那你在testing set上可以得到好的結果的機會是微乎其微的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:18.300" id=02:18.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=138">02:18.300</a></div>
        <div class="t">所以,如果你在testing set上的結果不好,你應該先看看你的training set結果是怎麼樣,然後才看說現在是不是overfitting。所以,我們來看一下在training set上的結果吧。其實,K華神在訓練的過程中就已經會告訴你它在training set上得到performance,不過我們今天特別再把training set的結果print出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:37.560" id=02:37.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=157">02:37.560</a></div>
        <div class="t">我們來print一下training set的結果,只要把x-test改成x-train,y改成y-train就好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:54.240" id=02:54.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=174">02:54.240</a></div>
        <div class="t">好,那我們實際上來跑一下。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:59.240" id=02:59.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=179">02:59.240</a></div>
        <div class="t">其實,在training的過程中,K華神就會告訴你說它現在算出來的accuracy是多少。在每一個epa後面,它都會告訴你說,在這個epa結束的時候,它算出來的accuracy是多少。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:19.240" id=03:19.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=199">03:19.240</a></div>
        <div class="t">你看這個實驗結果,你就會發現說,其實,我這邊忘了把test改成train,不過大家知道我的意思就好,上面這個accuracy是training set上的accuracy,下面這個accuracy是testing set上的accuracy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:34.240" id=03:34.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=214">03:34.240</a></div>
        <div class="t">如果你只有看testing上的accuracy,你並不知道你現在是不是overfitting。有人看到testing上的accuracy就會說,看testing上的accuracy,發現performance很差,就會胡亂得到一個結論說,所以deep learning很容易overfitting,所以deep learning很work。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:48.120" id=03:48.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=228">03:48.120</a></div>
        <div class="t">但其實不是這樣。今天在這個test裡面,如果我們看training set的accuracy的話,你會發現training set的accuracy也是差的。這告訴我們什麼?這告訴我們,Neo在train的時候,它就沒train好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:00.440" id=04:00.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=240">04:00.440</a></div>
        <div class="t">它可能卡在一個local minima,它可能卡在一個很差的settle point,總之,它在training set上performance就沒做好。所以這個時候,你遇到的問題並不是overfitting,而是training沒有train好,你要想個辦法先在training set上得到比較好的performance。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:14.740" id=04:14.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=254">04:14.740</a></div>
        <div class="t">我應該把這個test改成train。那這邊到底少了什麼東西呢?其實這邊少的是loss function設的不對。其實我們已經有跟大家解釋過說,其實用mean square error在分類的問題,你其實不會得到好的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:35.540" id=04:35.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=275">04:35.540</a></div>
        <div class="t">我們在講logistic regression的時候已經講過這件事了,我們現在實際來示範一下。我們就只是單純地把mean square error換成cross entropy,在Keras裡面,categorical的cross entropy就是我們上課講的cross entropy。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:57.400" id=04:57.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=297">04:57.400</a></div>
        <div class="t">那從mean square error換成cross entropy,這個你可能不會覺得有什麼特別厲害的地方,paper也不會跟你emphasize這件事,但是我們看看它有什麼樣的差別。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:07.400" id=05:07.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=307">05:07.400</a></div>
        <div class="t">當我們換成cross entropy以後,在training set上的accuracy就起飛了。現在training set就得到87%的正確率。這其實只是巧合,我沒有辦法特別設計出這個結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:35.140" id=05:35.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=335">05:35.140</a></div>
        <div class="t">它training set上得到85%的正確率,所以現在就比較有trend起來了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:40.580" id=05:40.580>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=340">05:40.580</a></div>
        <div class="t">我們先試一下batch size會對結果造成的影響。我們現在把batch size改成一萬,再跑跑看。剛才我們可以得到training set上87%、testing set上85%的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:07.040" id=06:07.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=367">06:07.040</a></div>
        <div class="t">你看,batch size設一萬,跑超快,因為你是用GPU平行運算,所以在GPU可以平行運算的能力可以承受的前提之下,你batch size開越大其實跑得越快。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:18.340" id=06:18.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=378">06:18.340</a></div>
        <div class="t">但是batch size一開大,開太大的時候performance就壞掉了。至於為什麼,我們上課有解釋過了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:26.020" id=06:26.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=386">06:26.020</a></div>
        <div class="t">所以發現說,一樣的network架構,batch size一開大,結果就壞掉了。我們試著把batch size弄小一點。剛才是從100改到一萬,現在改回1,改成1,你會發現怎麼樣呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:40.420" id=06:40.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=400">06:40.420</a></div>
        <div class="t">今天如果batch size只有1的時候,GPU就沒有辦法發揮它平行運算的效能,就會發現說變得很慢。所以有人不知道說,你要能夠用GPU加速,前提是你在training的時候你必須要batch開大一點,GPU才能夠真的加速。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:59.840" id=06:59.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=419">06:59.840</a></div>
        <div class="t">如果你今天batch size設1,也就是做stochastic gradient descent,GPU可以對你帶來的幫助其實就不會很大。所以你看,現在跑得變得非常非常慢,每一個A排要二十秒。我相信大家應該不會有興趣看我把它跑完,所以我們就把它停下來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:15.040" id=07:15.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=435">07:15.040</a></div>
        <div class="t">所以有些人可能會想說,那就應該要用dip了吧,再加10層。現在改成用10層,我們看一下training的accuracy,你會發現說,沒做起來,卡住了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:45.000" id=07:45.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=465">07:45.000</a></div>
        <div class="t">我們在錄影裡面有解釋說為什麼會這樣。我們疊10層的時候,會有gradient bandage的問題,所以卡住了。所以你看,testing set的performance大概是11%的正確率。如果你沒有training deep learning的概念,你可能會說,嗯,所以10層overfitting performance這麼差。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:03.000" id=08:03.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=483">08:03.000</a></div>
        <div class="t">但是如果仔細看一下training set,它的performance其實也是差的,所以這個不是overfitting,這個是沒train起來。那現在要怎麼辦呢?我們來改一下activation function,我們把sigmoid都改成IOU,再train一次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:33.000" id=08:33.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=513">08:33.000</a></div>
        <div class="t">你會發現說,現在training的accuracy就爬起來了。現在已經跑到98、99了。你會發現說,現在training的accuracy已經將近100%的testing,可以得到95.6%的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:58.100" id=08:58.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=538">08:58.100</a></div>
        <div class="t">好,那這邊有一個有趣的地方也許可以跟大家分享一下。現在我們的image是有normalize的。有normalize的意思是說,每一個pixel我們用一個0到1之間的值來表示它。1代表最黑,0代表沒有塗黑。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:21.100" id=09:21.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=561">09:21.100</a></div>
        <div class="t">那其實你剛拿到一個image的時候,通常我們是用灰階來表示它的,也就是每一個pixel它的值是用0到255來表示它。所以我這邊特別除上255,做normalize這件事。如果今天我們把255拿掉,會發生什麼事呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:38.200" id=09:38.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=578">09:38.200</a></div>
        <div class="t">你會發現說,你又做不起來了。所以這種小小的地方,只是有沒有做normalization的地方,其實對你的結果會有關鍵的影響,而這些事情是很多人都忽略的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:59.900" id=09:59.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=599">09:59.900</a></div>
        <div class="t">現在我知道說,因為AI非常吵,現在多數人的心力都集中在AI會不會統治世界這件事情上面,或講一些奇奇怪怪、不符合實際的話。像這種小小的normalization聽起來一點都不吵、不會統治世界的東西,但是對結果其實有非常大的影響。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:30.900" id=10:30.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=630">10:30.900</a></div>
        <div class="t">我們把這個時辰註解起來,然後我們再跑一次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:42.040" id=10:42.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=642">10:42.040</a></div>
        <div class="t">你會發現說,今天在training的時候,大概在第一個epoch的時候得到77%的正確率,在第二個epoch的時候得到90%的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:02.860" id=11:02.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=662">11:02.860</a></div>
        <div class="t">那我們現在換一下training的gradient descent的strategy,把它從SGD改成addend。我們上次有講過addend,把它改成addend。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:15.300" id=11:15.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=675">11:15.300</a></div>
        <div class="t">好,然後再跑一次。你會發現說,當我們用addend的時候,它可能最後收斂的地方差不多,但是你會發現它上升的速度是變快的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:34.080" id=11:34.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=694">11:34.080</a></div>
        <div class="t">我們剛才在還沒有addend的時候的第一個epoch,它的正確率是七開頭。如果現在用addend的話,在第一個epoch它的正確率就有85%,第二個epoch就有90%。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:53.420" id=11:53.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=713">11:53.420</a></div>
        <div class="t">但今天在這個task,因為一個epoch跑得非常快,所以你可能沒有什麼特別的感覺。但是如果今天一個epoch要跑一天,你就會覺得說有addend還真是好這樣子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:05.140" id=12:05.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=725">12:05.140</a></div>
        <div class="t">我在testing set上故意加上random的noise,然後我們實際來操作一下,看看結果會掉多少。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:25.140" id=12:25.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=745">12:25.140</a></div>
        <div class="t">好,我們本來在testing set上可以得到96%的正確率,但現在training和testing是不match的,所以一做下去結果就爛掉了。現在testing只有不到50%的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:46.120" id=12:46.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=766">12:46.120</a></div>
        <div class="t">那怎麼辦呢?我們來試一下抓爆可以帶給我們什麼樣的結果。我們來加一下抓爆。怎麼加抓爆呢?你就打model add抓爆,然後你要設一個抓爆rate。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:01.120" id=13:01.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=781">13:01.120</a></div>
        <div class="t">抓爆rate其實是你自己設的,它就像是network的hidden layer size一樣,你要設多少是你自己決定的,常見的是設0.5。不過因為今天在這個task裡面,training和testing非常的mismatch,所以我覺得抓爆rate可以設大一點,比如說我設0.7試試看。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:18.720" id=13:18.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=798">13:18.720</a></div>
        <div class="t">好,抓爆就是加在每一個hidden layer後面。那這邊有一件事情大家要注意的就是說,今天當你加了抓爆以後,其實training上的performance是會變差的,這個很合理嘛。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:39.140" id=13:39.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=819">13:39.140</a></div>
        <div class="t">因為加抓爆就是去綁住network的手腳,所以training的時候它的performance會變差的。所以,如果今天你的performance不好是來自於在training上performance不好,你不要再加抓爆了,你只會越弄越差而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:50.160" id=13:50.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=830">13:50.160</a></div>
        <div class="t">是你今天在training上已經跑得太好,它overfitting,你才加上抓爆。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:54.760" id=13:54.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=834">13:54.760</a></div>
        <div class="t">所以我們看一下,其實剛才我們的正確率都可以做到100%的正確率,看到沒有?100%的正確率,這個才是真正的overfitting。所以,我們現在加了抓爆以後,應該就跑不到100%的正確率了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:10.720" id=14:10.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=850">14:10.720</a></div>
        <div class="t">你看看剛才在training的時候,在最後幾個APA的正確率都已經是100%,現在加上抓爆,你就會發現說network就train不到那個performance了。在training的時候就等於是綁住network的手腳,你會發現說它現在就有點被卡住了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:27.700" id=14:27.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=867">14:27.700</a></div>
        <div class="t">在training的時候,它的正確率現在在94、95中間徘徊。今天在testing training data的時候,其實就不會加上抓爆了,所以你會發現說,在用training data testing的時候,它的performance遠比training的時候所呈現的performance要好得多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:47.220" id=14:47.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=887">14:47.220</a></div>
        <div class="t">有加抓爆的時候,network在training的時候會綁住手腳,所以它的performance差一點。但是,你會發現說,在testing的時候,剛才正確率連50%都不到,但是加了抓爆以後,現在就有60%的正確率了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:01.600" id=15:01.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=Ky1ku1miDow&t=901">15:01.600</a></div>
        <div class="t">那這邊就是實際示範一下,如果我們把上課教的總統tips真的拿來實奏在amnesty的時候,會有什麼樣的不同。其實還有很多東西沒有講的,你可以自己回去試試看,或者在作業三的時候試試看,不同的tips對network會有什麼樣的影響。</div>
    </div>
    
</body>
</html>   