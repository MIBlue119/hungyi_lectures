<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>【生成式AI】大模型 + 大資料 = 神奇結果？(2/3)：到底要多少資料才夠</h2><a href=https://www.youtube.com/watch?v=qycxA-xX_OY><img src=https://i.ytimg.com/vi_webp/qycxA-xX_OY/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=0">00:00.000</a></div>
        <div class="t">剛才主要是講模型的重要性啦,那接下來呢,來講一下資料的重要性。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:09.000" id=00:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=9">00:09.000</a></div>
        <div class="t">當然資料也是非常重要的,那有一篇文章叫做《When do you need billions worth of retraining data?》</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:19.000" id=00:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=19">00:19.000</a></div>
        <div class="t">就是想要來回答這個問題,到底用多少資料可以讓機器學到什麼樣的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:25.000" id=00:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=25">00:25.000</a></div>
        <div class="t">我們今天知道一個語言模型要正確回答你的問題,其實它需要兩個能力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:32.000" id=00:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=32">00:32.000</a></div>
        <div class="t">一個能力其實是對於這個語言本身的文法和用詞的理解,這邊我們可以稱之為語言知識。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:42.000" id=00:42.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=42">00:42.000</a></div>
        <div class="t">但是它還有另外一層能力,這另外一層的能力,這邊稱之為世界知識,就是它要對我們這個世界的common sense或者是物理的規則有正確的認識。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:55.000" id=00:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=55">00:55.000</a></div>
        <div class="t">舉例來說,假設有一個句子是,我被這塊冰塊燙了手,那這聽起來是一個符合文法的句子,但是它是不符合這個世界常識還有物理規則的句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:08.000" id=01:08.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=68">01:08.000</a></div>
        <div class="t">所以今天機器要能夠正確回答問題要有兩個能力,一個是對這個語言的文法用詞本身的能力,另外一個是對這個世界的理解。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:19.000" id=01:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=79">01:19.000</a></div>
        <div class="t">這篇論文裡面就有這麼一個圖,橫軸是訓練的資料量,1N、10N、100N、1B、30B,這邊的單位指的是token的數目。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:32.000" id=01:32.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=92">01:32.000</a></div>
        <div class="t">我們先來看藍色這條線,藍色這條線就是把這個模型用在一些跟文法相關的任務上面的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:43.000" id=01:43.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=103">01:43.000</a></div>
        <div class="t">你會發現說大概一個billion左右的token,基本上機器就可以學會英文的文法了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:52.000" id=01:52.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=112">01:52.000</a></div>
        <div class="t">這些讓我們知道說,要讓機器學會某一個語言的文法,也許資料不用太多,一個billion的token也許就足夠了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:02.000" id=02:02.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=122">02:02.000</a></div>
        <div class="t">藍色這條線指的是這個機器的common sense,就在一些量測模型有沒有common sense的問題上,去看現在你的模型的正確率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:15.000" id=02:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=135">02:15.000</a></div>
        <div class="t">你會發現說,如果只有一個billion的token,不足以讓機器具有常識。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:22.000" id=02:22.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=142">02:22.000</a></div>
        <div class="t">你需要有更多的資料量,至少30個billion以上的token,機器才會對這個世界有正確的認識。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:31.000" id=02:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=151">02:31.000</a></div>
        <div class="t">所以這告訴我們說,資料量要夠多,不足夠的資料只能夠讓機器學會語言的文法規則。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:39.000" id=02:39.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=159">02:39.000</a></div>
        <div class="t">今天你要讓機器具備人類世界、物理世界的常識,那我們真的需要更大量的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:48.000" id=02:48.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=168">02:48.000</a></div>
        <div class="t">資料本身的前處理其實也是非常重要的,當然我們這門課裡面不會講太多,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:57.000" id=02:57.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=177">02:57.000</a></div>
        <div class="t">不過我這邊引用Gopher,Gopher是DeepMind所訓練的一個大型的language model,引用Gopher這篇paper的內容,來給你看一下別人是怎麼做資料的前處理的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:09.000" id=03:09.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=189">03:09.000</a></div>
        <div class="t">那Gopher是什麼呢?我就直接把它輸入mejourney,畫出來的圖長得是這個樣子,看起來是一種蝙蝠類動物,我不知道為什麼DeepMind要把他們的模型取做Gopher。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:24.000" id=03:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=204">03:24.000</a></div>
        <div class="t">那在Gopher這篇paper裡面就講了說,他們是怎麼對他們所收集到的資料做前處理的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:31.000" id=03:31.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=211">03:31.000</a></div>
        <div class="t">他們從網路上爬了很多資料以後,接下來第一步是要先濾除有害的內容,色情暴力的內容,這當然一定要先濾掉,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:40.000" id=03:40.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=220">03:40.000</a></div>
        <div class="t">讓機器沒有看過這些色情暴力的內容,免得它說出奇怪的話。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:44.000" id=03:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=224">03:44.000</a></div>
        <div class="t">那它裡面有特別講說,他們不是用那種關鍵字,就不是去看有沒有出現某個關鍵字,就代表說這個文章我們不要用,它就是用Google的安全搜尋。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:54.000" id=03:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=234">03:54.000</a></div>
        <div class="t">Google不是有一個安全搜尋嗎?它會告訴你說有些網頁是有害的,他們就是看那個安全搜尋的結果,過不了那個安全搜尋檢測的就當作是有害的網頁,那我們就不能用它。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:04.000" id=04:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=244">04:04.000</a></div>
        <div class="t">接下來要把網頁中的文字抽出來,你知道這個網頁裡面有很多東西是跟文字內容無關的,它是HTML的tag,你要把它拿掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:15.000" id=04:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=255">04:15.000</a></div>
        <div class="t">但其實他們也保留了部分HTML的tag,舉例來說換行或者是項目的符號,因為這些是有用的,你保留這些tag之後,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:25.000" id=04:25.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=265">04:25.000</a></div>
        <div class="t">你的模型可能可以自動學會在該換行的地方換行,或者是學會在某些時候它可以出現項目符號,它可以做條列式的回答。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:34.000" id=04:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=274">04:34.000</a></div>
        <div class="t">這邊有一個quality的filtering,他們是用一些規則去除低品質的資料,在論文裡面有列了詳細的規則,我們這邊就不細講。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:44.000" id=04:44.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=284">04:44.000</a></div>
        <div class="t">為什麼要去除低品質的資料呢?你知道網路上有很多奇奇怪怪的東西,尤其是有一些網頁為了讓搜尋引擎可以搜尋到它,它可能會藏很多人看不到的文字。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:55.000" id=04:55.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=295">04:55.000</a></div>
        <div class="t">而那些文字可能是沒什麼意義的,單純只是一些為了讓搜尋引擎更容易搜尋這個網頁的詞彙而已,那些東西都應該要被拿掉。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:05.000" id=05:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=305">05:05.000</a></div>
        <div class="t">接下來有一個步驟是去除重複的資料。網路上有非常多重複的資料,有人發一篇農場文,這個農場文就會不斷地被轉發。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:15.000" id=05:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=315">05:15.000</a></div>
        <div class="t">網路上太多重複的資料了,應該去除重複的資料。最後一個有趣的事情是,它做了test set filtering,這是為了實驗的嚴謹。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:24.000" id=05:24.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=324">05:24.000</a></div>
        <div class="t">我們這些大型語言模型,最後你要拿來測試,測試的時候是測試在某一些資料集上,那些資料集當然不能在訓練的時候看過,在訓練的時候看過感覺有點不太公平。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:34.000" id=05:34.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=334">05:34.000</a></div>
        <div class="t">之前GPT-3在訓練的時候就犯過這個錯誤,你看GPT-3那篇論文裡面就講說,train完模型以後才發現資料裡面有一些測試的時候會用到的資料,怎麼辦呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:46.000" id=05:46.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=346">05:46.000</a></div>
        <div class="t">沒救了這樣子,因為GPT-3太大了,不能夠再訓練一次,沒有人想訓練一次,只好就這樣子吧。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:53.000" id=05:53.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=353">05:53.000</a></div>
        <div class="t">應該對結果不會有太大的影響吧,你看GPT-3的論文,它說不小心發現訓練資料裡面混到一些測試資料,但是沒救,也只好這樣子了,沒辦法訓練這麼大的模型第二次。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:05.000" id=06:05.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=365">06:05.000</a></div>
        <div class="t">這邊講一下去掉重複資料的重要性,有一篇paper叫做《Deduplicate training data makes language model better》,從它的標題就可以告訴我們說,去掉重複的資料是有一些幫助的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:19.000" id=06:19.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=379">06:19.000</a></div>
        <div class="t">這篇論文裡面是講說,有一個大家蠻常用的從網路上爬來的資料叫做C4,其實是網路上爬來的資料在經過一些清理以後由Google釋出的,它已經經過一些清理了,但是它裡面有非常非常多重複的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:38.000" id=06:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=398">06:38.000</a></div>
        <div class="t">舉例來說,這一段文章在整個corpus裡面反覆出現,出現了六萬次這麼多。我想說,哇,這是什麼樣的一段文字居然出現了六萬次這麼多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:50.000" id=06:50.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=410">06:50.000</a></div>
        <div class="t">它有點眉頭眉尾的,好像是說有人提出來了很多fantastic的idea,然後C說,你只要把這些fantastic的idea用在你婚禮的設計裡面,大家就會說你很棒,感覺是某一個廣告詞。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:04.000" id=07:04.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=424">07:04.000</a></div>
        <div class="t">我把這段話也丟到mejourney讓它生個圖,它生出來的圖是這個樣子,看到什麼奇奇怪怪的話都丟到mejourney裡面,就知道這句話是跟婚禮有關的,然後有各式各樣fantastic的設計。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:18.000" id=07:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=438">07:18.000</a></div>
        <div class="t">這篇文章做的事情就很單純,就是拿掉那些duplicate的東西以後結果會怎樣。它是做了兩個不同層級的remove,因為你知道所謂的重複還是有幾個字一樣就算重複,還是要完全一樣就算重複,所以它是有兩個不同層級的清理。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:38.000" id=07:38.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=458">07:38.000</a></div>
        <div class="t">這邊這個數字是什麼呢?這個數字是你的language model記得訓練資料裡面的data的比例,就是說它訓練完模型以後就讓模型隨便說一句話,然後再把這句話拿去它的資料庫裡面,看它之前的訓練資料有沒有非常類似的句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:00.000" id=08:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=480">08:00.000</a></div>
        <div class="t">重疊度超過某一個比例,就當作今天機器硬背了訓練資料裡面的某一個句子。發現說如果用原來的資料不去除重複的東西的話,會有1%到2%你的機器說出來的話,訓練資料裡面有一模一樣的句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:18.000" id=08:18.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=498">08:18.000</a></div>
        <div class="t">這些句子真的出現太多次了,比如說六萬次,那機器就很容易說出那些訓練資料裡面常常出現的句子。如果你可以做一些適當的清理,你就可以把機器硬背訓練資料裡面句子的這件事情降到0.1%的比例。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:35.000" id=08:35.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=515">08:35.000</a></div>
        <div class="t">所以這個是告訴我們說de-duplication雖然看起來是個不起眼的小動作,對結果也是有幫助的。接下來問的另外一個問題是,假設今天你只有固定的運算資源,到底是模型比較重要還是資料比較重要?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:54.000" id=08:54.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=534">08:54.000</a></div>
        <div class="t">假設你今天有額外的運算資源,你應該把你的模型變大,還是固定模型的參數把你的資料量變多呢?這邊問的問題就是,在固定運算資源的情況下,我到底應該選小的模型大的資料,還是大的模型小的資料呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:15.000" id=09:15.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=555">09:15.000</a></div>
        <div class="t">有人可能會問說,我不能選大模型大資料嗎?你不可以說我全都要,因為我們這邊的設定就是,你只有固定的運算資源。假設你有無限的運算資源,那選大模型多資料當然結果最好啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:30.560" id=09:30.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=570">09:30.560</a></div>
        <div class="t">但這邊,運算資源在固定的前提之下,我到底應該把比較多的資源放在模型上,還是比較多的資源放在資料上?當然你可能說,也許我們要的就是中模型中資料,中間有一個平衡,但這個平衡點到底在哪裡呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:47.440" id=09:47.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=587">09:47.440</a></div>
        <div class="t">如果你的模型大,因為你的模型大,它占用的運算資源就多,在固定運算資源的情況下,你就不能讓你的模型看過太多的資料。小的模型占用的運算資源少,那同樣的運算資源下,就可以看比較多的資料。這兩件事的平衡點到底在哪裡呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:06.000" id=10:06.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=606">10:06.000</a></div>
        <div class="t">如果你看最近的發展趨勢,你會發現說,過去的模型看起來趨勢是越搞越大。GPT-3,1775個筆點看起來已經很大了,但是後來什麼Gopher、NTNLG都搞了更大的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:24.440" id=10:24.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=624">10:24.440</a></div>
        <div class="t">但是訓練資料呢?看起來大家不覺得訓練資料要用更多,大家把額外的運算資源投注在搞出一個更大的模型上面,那這是不是一個明智的抉擇呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:39.960" id=10:39.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=639">10:39.960</a></div>
        <div class="t">這邊以下的結論出自DeepMind在去年三月發表的一篇論文。他們決定要來探究這個問題,他們要探究說,假設我只有固定運算資源的情況下,到底應該投注多少在資料上,投注多少在模型上。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:59.440" id=10:59.440>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=659">10:59.440</a></div>
        <div class="t">他們就做了一個異常暴力的實驗。在這個圖上,每一條虛線代表固定的運算資源。從小到大,這一條線就代表說你的運算資源是最少的,這一條線代表你的運算資源是最多的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:22.680" id=11:22.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=682">11:22.680</a></div>
        <div class="t">縱軸是你的模型在做文字接龍的時候預測的程度,越小就代表你的模型在做文字接龍的時候預測得越好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:35.640" id=11:35.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=695">11:35.640</a></div>
        <div class="t">橫軸代表的是參數的量,就是你的模型的大小,所以往右邊就是大模型小資料,往左邊就是小模型大資料。模型大就好像機器有一個很大的腦,但是它學習的東西就很少,它真的就是思而不學。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:55.740" id=11:55.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=715">11:55.740</a></div>
        <div class="t">小模型大資料就是它看了很多的書,但是它自己不太會思考,這個就是學而不思。從這個實驗結果,當然你可以很明顯地看出來說,學而不思則忘,思而不學則散。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:10.680" id=12:10.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=730">12:10.680</a></div>
        <div class="t">這兩件事情,學跟思應該要是平衡的,所以你會發現說這邊的每一條虛線都是U字形的,在中間的某一個平衡點,你得到的結果是最好的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:24.720" id=12:24.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=744">12:24.720</a></div>
        <div class="t">就是你一味地把模型衝大,結果會變差,就變成只有思考不學習,這樣是會比較差的。一味地把資料衝大,會變成說只有學習而不思考,結果也是變差的。兩者間要取得某種平衡,但這個平衡點在哪裡呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:43.660" id=12:43.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=763">12:43.660</a></div>
        <div class="t">接下來,這篇paper做的事情就是把每一個U型曲線的最低點標出來,把每一個U型曲線的最低點標出來以後畫在另外一張圖上,這些點就是剛才U型曲線的點。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:01.400" id=13:01.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=781">13:01.400</a></div>
        <div class="t">從這邊我們當然可以看到說,當我們的運算資源越來越多的時候,參數量應該要隨之增加。當我們的運算資源越來越多的時候,我們的訓練資料量也應該隨之增加。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:16.960" id=13:16.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=796">13:16.960</a></div>
        <div class="t">這個圖告訴了我們一個最佳的比例。接下來丁邁要做的事情就是,假設我的運算資源在這邊,之所以定在這邊是因為這個是他們之前的另外一個大模型,叫做Gopher,比GB3還要大一點,這是Gopher所用的算力。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:35.920" id=13:35.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=815">13:35.920</a></div>
        <div class="t">他們估算一下發現說,如果是用Gopher的算力的話,那你的參數量設在63個Billion左右是最好的。如果是Gopher的算力的話,你的資料量設在1.4T左右是最好的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:53.340" id=13:53.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=833">13:53.340</a></div>
        <div class="t">你會發現說這個結論跟Gopher所採取的策略非常不一樣,Gopher用了280個Billion的參數、300個Billion的訓練資料。而根據這個圖上給我們的結果,你有跟訓練Gopher一樣大的算力的話,你的參數量應該設成這樣,你的資料量應該設成這樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:16.480" id=14:16.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=856">14:16.480</a></div>
        <div class="t">但我知道說這個結論有100個你可以吐槽的點,就是這個是個外差啊,你怎麼確定這一條線一定是直的呢?會不會到這邊這個線就彎過來啊或彎過來呢?不知道。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:30.400" id=14:30.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=870">14:30.400</a></div>
        <div class="t">而且啊,剛才的結論是來自於預訓練,也就是預測下一個Token的正確率。搞不好你今天用在某一個你關心的任務上,結論也不是這樣子啊。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:43.040" id=14:43.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=883">14:43.040</a></div>
        <div class="t">所以我知道說這個結論有100個可以吐槽的點,所以DeepMind為了要驗證這個結論,反正就是直接Check看看結果怎麼樣,大家就沒有話說了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:53.920" id=14:53.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=893">14:53.920</a></div>
        <div class="t">所以根據這條線給我們的結論,他們有一個新的模型叫做Chinchilla,然後這個模型就給他70個Billion的參數跟1.4個Trillion的Token,然後看看訓練出來結果怎樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:11.360" id=15:11.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=911">15:11.360</a></div>
        <div class="t">Chinchilla是什麼呢?我搜尋也把Chinchilla丟到MeJeremy裡面,看起來也是某種鳥屎類動物。我就不知道為什麼DeepMind這麼喜歡鳥屎類動物就是了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:23.520" id=15:23.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=923">15:23.520</a></div>
        <div class="t">Chinchilla的表現怎麼樣呢?接下來就是同樣算力的情況下,小模型大資料跟大模型小資料的對決,就是Chinchilla跟Gopher的對決。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:33.920" id=15:33.920>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=933">15:33.920</a></div>
        <div class="t">對決的結果就是Chinchilla是完勝的,在這麼多不同的當區的任務下,看起來Chinchilla都是贏Gopher的,Chinchilla只有在四個任務上面輸Gopher。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:45.600" id=15:45.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=945">15:45.600</a></div>
        <div class="t">這就告訴我們說,在同樣的算力下,Chinchilla用小模型大資料所採取的路線是可以得到比較好的結果的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:56.480" id=15:56.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=956">15:56.480</a></div>
        <div class="t">小是一個相對的概念,小模型對你來說都是大模型,這也是你沒有辦法train的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:06.880" id=16:06.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=966">16:06.880</a></div>
        <div class="t">所以這邊又有另外一個表格,他們剛才已經說,如果這邊1是以Gopher的算力作為單位,假設你有1Gopher的算力,那你就應該有67Billion的參數跟1.5Trillion的Token。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:23.280" id=16:23.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=983">16:23.280</a></div>
        <div class="t">那如果你今天有175Billion的參數,那最好的訓練資料的量落在哪裡呢?落在3.7Trillion的Token。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:34.800" id=16:34.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=994">16:34.800</a></div>
        <div class="t">所以這意味著說,其實GPT-3用的訓練資料太少了,GPT-3還有之後更大的PALM,他們用的資料量也許都是不夠的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:46.640" id=16:46.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1006">16:46.640</a></div>
        <div class="t">所以這邊就顛覆了人們的想法,過去覺得要搞個大模型,現在人們開始覺得說,也許我們真正需要的都不是那麼大的模型,模型已經夠大了,現在要的是餵給他更多的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:05.040" id=17:05.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1025">17:05.040</a></div>
        <div class="t">這確實就是現在發展的趨勢,比如說你看Meta最近才釋出的Language Model叫做Lama,Lama就沒有在搞一個更大的模型了。Lama的Paper一開頭就引用了DeepMind那篇Paper的結論說,在搞更大的模型是沒有意義的,我們需要的是更多的資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:25.200" id=17:25.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1045">17:25.200</a></div>
        <div class="t">所以他也採取了跟Chinchilla非常像的策略,它是一個65Billion大小的模型,它有1.4個Trillion的Token,如果你最近看Lama、Paper的話,會知道說它是比GPT-3還要好的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:38.960" id=17:38.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1058">17:38.960</a></div>
        <div class="t">所以這是一個新的趨勢,我們不一定要更大的模型,在我們的算力還沒有跟上之前,也許我們需要的是更多的訓練資料。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:49.680" id=17:49.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1069">17:49.680</a></div>
        <div class="t">還有其他的方法,其實可以快速地讓你的模型變強,你只需要少量的資料、少量的算力,就讓你的模型得到充足的提升。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:03.520" id=18:03.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1083">18:03.520</a></div>
        <div class="t">這個方法就是我們上次講過的Instruction Tuning,因為我們真正在意的其實也不是做Language Model的時候文字接龍的正確率。我剛才講說,你真正在意的是最後你要做的那些任務,文字接龍的正確率這個指標,雖然前面的論文都是看這個指標,但是它不一定跟我們最終要解的任務有關係。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:27.680" id=18:27.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1107">18:27.680</a></div>
        <div class="t">如果我們真正要機器解的就是某一些我們關心的任務,也許直接做Instruction Tuning,讓機器在這些我們想要它解的自然語言處理的任務上面直接做學習,也許是比較有效。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:43.040" id=18:43.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1123">18:43.040</a></div>
        <div class="t">後來Google就有一篇paper叫Skilling Instruction Fine Tuning Language Model,我們之前已經講過Instruction Tuning,講過FLAM這個Model,後來有一個FLAM系列的模型,它的訓練的任務有1.8K、1800個任務,它用1800個任務去微調大型的Language Model,看看在解其他任務的時候會不會結果就起飛了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:11.200" id=19:11.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1151">19:11.200</a></div>
        <div class="t">在論文裡面有特別強調說,Instruction Tuning其實是一件非常lightweight的事情。對於大型Language Model來說,Instruction Tuning雖然你聽到1800個任務覺得好像很耗費運算資源,其實在1800個任務上做Instruction Tuning所需要的運算資源只是pre-training的0.2%而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:36.560" id=19:36.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1176">19:36.560</a></div>
        <div class="t">但是光是做這件事情,模型在你關心的這些downstream task、下游任務上面就有很顯著的不同。左邊這個圖,橫軸是模型的參數量,縱軸是在某些任務上面的正確率。如果你完全沒有做Fine Tuning,你得到的是黑色這條線。隨著Fine Tuning的任務越來越多,線的顏色越來越深,你的模型可以有一個非常顯著的提升。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:03.760" id=20:03.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1203">20:03.760</a></div>
        <div class="t">右邊這個圖,意思也是一樣,有三個不同大小的模型,隨著任務越來越多,在自然語言處理任務上的正確率就會越來越高。而讓模型從這裡提升到這裡,你需要的運算資源是非常少的,只需要pre-training的0.2%,所以與其追求一個更大的模型、更大的資料,也許找一些自然語言處理的任務來直接教機器也是一個非常有效的做法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:34.720" id=20:34.720>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1234">20:34.720</a></div>
        <div class="t">這一頁投影片,其實之前大家已經看過很類似的概念了。為什麼機器在自然語言處理的任務上沒有做Instruction Fine Tuning,直接拿一個Language Model在各種任務上做得不好呢?就是因為它根本不知道你要它回答問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:50.080" id=20:50.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1250">20:50.080</a></div>
        <div class="t">舉例來說,像這邊,它出了一個數學題,你給機器出一個數學題。那PALM如果不做Instruction Fine Tuning的話,它會以為你要更多的數學題,它就幫你出更多的數學題。但你要做Instruction Fine Tuning,它才能夠直接給你答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:08.320" id=21:08.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1268">21:08.320</a></div>
        <div class="t">我們已經知道說,像這一種做完pre-training以後,再根據額外的Label Data,再去做Fine Tuning這件事情,就是確GPT成功的一個關鍵。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:22.160" id=21:22.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1282">21:22.160</a></div>
        <div class="t">如果你看過去OpenAI的論文的話,先做Supervised Fine Tuning,然後接下來再做Reinforcement Learning,是一個固定的套路了。不只確GPT這樣做,Instruction GPT也這樣做,另外一邊做Summarization Paper也這樣做,你會發現這些圖大概都有個87%像,基本上就是一個熟悉的套路。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:45.200" id=21:45.200>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1305">21:45.200</a></div>
        <div class="t">那在pre-training之後,再做Fine Tuning或再做Reinforcement Learning到底有多有效呢?我們來看一下Instruction GPT這篇Paper裡面的實驗結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:56.480" id=21:56.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1316">21:56.480</a></div>
        <div class="t">在這篇Paper裡面,橫軸是模型的大小,從1.3B、6B到175B的參數。縱軸是把你的模型去跟一個775B的GPT直接面對面做對決的時候。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:18.400" id=22:18.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1338">22:18.400</a></div>
        <div class="t">這邊的對決應該就是把兩個模型都伸出結果,然後給使用者看,看使用者比較喜歡哪一個的時候,哪贏的機率。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:27.760" id=22:27.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1347">22:27.760</a></div>
        <div class="t">所以如果今天是175B的模型經過Fine Tuning以後,自己跟自己比,勝率就算是50%。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:38.080" id=22:38.080>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1358">22:38.080</a></div>
        <div class="t">最底下這條線是原始的GPT,這個GPT Pumping這件事就是GPT加In Context Learning,這個我們是上週講過的東西。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:48.320" id=22:48.320>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1368">22:48.320</a></div>
        <div class="t">SFT就是有做Fine Tuning,根據Instruct GPT收集到的一些人類老師提供的資料做Fine Tuning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:56.640" id=22:56.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1376">22:56.640</a></div>
        <div class="t">PPO這邊是試了兩個有點不一樣的演算法,PPO就是做Reinforcement Learning的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:04.640" id=23:04.640>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1384">23:04.640</a></div>
        <div class="t">這邊有哪些看點呢?第一個看點是,你可以比較6B的模型經過Fine Tuning的結果,跟175B的模型沒有Fine Tuning的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:15.040" id=23:15.040>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1395">23:15.040</a></div>
        <div class="t">你會發現說6B的模型這麼小,但是有做一下Fine Tuning是可以打爆一個大模型的,小模型經過人類老師的訓練是可以打爆沒有訓練的大模型的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:26.560" id=23:26.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1406">23:26.560</a></div>
        <div class="t">當然如果大模型有訓練以後還是比小模型更好啦。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:29.600" id=23:29.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1409">23:29.600</a></div>
        <div class="t">另外一個看點是說,今天如果是一個大模型只有做Supervised Learning,跟一個最小的模型,這個模型真的很小,1.3B的模型你應該有機會自己訓練。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:42.880" id=23:42.880>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1422">23:42.880</a></div>
        <div class="t">1.3B的模型做完人類老師的Supervised Learning,再做更多的Reinforcement Learning,做完Reinforcement Learning以後是可以打爆巨大模型沒有做Reinforcement Learning的結果的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:57.680" id=23:57.680>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1437">23:57.680</a></div>
        <div class="t">所以這就是顯示說,就算你的模型沒有非常的巨大,如果你如果有使用者的feedback,你可以做人類老師給的回饋,你可以做Reinforcement Learning,你其實有機會讓小模型可以跟大模型一搏的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:15.760" id=24:15.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1455">24:15.760</a></div>
        <div class="t">那另外一個實驗結果放在Instruction GDP那篇paper裡面的結果是這樣子的,他這邊比較了幾個不同的模型,這邊縱軸是直接把這個模型輸出的結果給人類看,然後人類勾選個喜歡的程度,然後這個分數越高就代表人類越喜歡這個答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:34.960" id=24:34.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1474">24:34.960</a></div>
        <div class="t">這邊試了GPT加InContext Learning,還有GPT做Supervised Learning,然後還有Instruct GPT做Reinforcement Learning,他的結果是最好的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:47.760" id=24:47.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1487">24:47.760</a></div>
        <div class="t">那你發現Instruct GPT做Reinforcement Learning以後,他其實是完勝Flame跟T0的,Flame是什麼?Flame就是有拿很多的任務去對模型做Instruction fine tuning的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:03.120" id=25:03.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1503">25:03.120</a></div>
        <div class="t">你會發現Instruct GPT是透過人類真正的feedback,使用者真正的feedback來做微調的,跟從一些NLP的任務得到的資料來做Instruction fine tuning的結果其實是非常不一樣的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:18.480" id=25:18.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1518">25:18.480</a></div>
        <div class="t">這邊也許可以給我們的一個啟示就是,其實資料對真的非常重要。對Flame來說,他裡面給模型的指示通常是長這個樣子的,這種指示你不覺得其實也蠻不自然的嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:34.160" id=25:34.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1534">25:34.160</a></div>
        <div class="t">今天你在用Chair GPT的時候,你真的會輸入這樣的句子嗎?或甚至你在做Chair GPT的時候,這是一個NLI的任務,是Natural Language Inference的任務,你是給兩個句子問Chair GPT說你覺得這兩個句子有沒有矛盾,你真的沒事會去問Chair GPT這個問題嗎?很少對不對?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#25:51.760" id=25:51.760>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1551">25:51.760</a></div>
        <div class="t">所以我覺得這就是為什麼Chair GPT相較於其他的大型的Language Model可以這麼成功的原因。因為你想想看過去的歷史,Open AI雖然有open這個字,但是其實他們現在其實是傾向close的對不對?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:06.800" id=26:06.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1566">26:06.800</a></div>
        <div class="t">因為GPT-3根本就沒有釋出它的模型,它是一個線上的API,大家是不斷地去玩GPT-3這個模型。GPT-32020年的時候上線,從2020年到今天兩年多的時間內,無數的人在玩這個線上的模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:24.160" id=26:24.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1584">26:24.160</a></div>
        <div class="t">所以Open AI完全知道人類面對一個大型的Language Model的時候,你會問什麼問題。你大概不會做NLI,因為這個問題太奇怪、太不自然了。我覺得大家最常做的可能都是一上線先說個你好,然後接下來說請說個笑話,對不對?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:39.840" id=26:39.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1599">26:39.840</a></div>
        <div class="t">你都是問這種問題啊,你不會問這種NLI的問題啊,這種NLI的問題太不自然了。所以這就是為什麼Chair GPT我覺得會成功的一個關鍵,因為只有它知道人類會怎麼玩這個模型,而連Google都不知道人類會怎麼玩這個模型。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#26:58.160" id=26:58.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=qycxA-xX_OY&t=1618">26:58.160</a></div>
        <div class="t">從Instruct GPT裡面我們就已經可以看到說,這個模型在給人類玩一玩,做reinforcement learning以後,就是可以屌打其他的模型,是人類會覺得這樣子的模型結果是最好的。</div>
    </div>
    
</body>
</html>   