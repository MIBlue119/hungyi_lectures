<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Hung-yi Lee's Lectures(台大李宏毅老師系列課程)</title>
    <style>
        body {
            font-family: sans-serif;
            font-size: 18px;
            color: #111;
            padding: 0 0 1em 0;
        }
        .l {
          color: #050;
        }
        .s {
            display: inline-block;
        }
        .e {
            display: inline-block;
        }
        .t {
            display: inline-block;
        }
    </style>
  </head>
  <body>
    <a href="../../index.html">back to index</a>
    <h2>【生成式AI】Finetuning vs. Prompting：對於大型語言模型的不同期待所衍生的兩類使用方式 (2/3)</h2><a href=https://www.youtube.com/watch?v=aZ_jXZvxyVg><img src=https://i.ytimg.com/vi_webp/aZ_jXZvxyVg/hqdefault.webp></a><br>
    
    <div class="c">
        <a class="l" href="#00:00.000" id=00:00.000>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=0">00:00.000</a></div>
        <div class="t">接下來要講的就是,怎麼讓機器進一步成為一個通才呢?那怎麼希望機器能夠閱讀我們要它做的任務的敘述,並且我們提供一些範例,它根據我們要它解的題目或者是任務的敘述跟範例,就要做我們想做的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:22.400" id=00:22.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=22">00:22.400</a></div>
        <div class="t">那這樣機器的行為就更像是人類了。大家在考英文指考的時候,是不是都會看到像這樣子的題目的敘述,然後看到像這樣子的題目的範例,給你一個敘述,給你一個範例,希望你就知道接下來要怎麼作答。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:40.400" id=00:40.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=40">00:40.400</a></div>
        <div class="t">那這種對機器而言,這種給題目敘述就要能夠回答叫做instruction learning,那給範例就要能夠回答叫做in-context learning,那這個就是ChairGPT系列想要達成的目標。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#00:58.160" id=00:58.160>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=58">00:58.160</a></div>
        <div class="t">那其實OpenAI並不是這幾年才突然想做這件事,它們一直都想做這件事。比如說2021年的機器學習的上課錄影,就已經有一個很像的投影片告訴你說,GPT它想要做的事情就是讓機器讀題目的敘述,然後再看範例,就能夠回答問題。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:19.280" id=01:19.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=79">01:19.280</a></div>
        <div class="t">不過在2021年那個時候會覺得這個想法太狂了,大概二三十年後才會看到結果吧,沒有想到這麼快就可以看到結果了。當初在這個影片的標題上還許說這叫GPT的野望,代表說這個應該是很難達成的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:37.600" id=01:37.600>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=97">01:37.600</a></div>
        <div class="t">那有人常常問一個問題,GPT系列能不能夠成為一個專才,跟Bert一樣針對不同的任務去做微調呢?其實是可以的,一定是可以的。但是為什麼GPT系列沒有選擇跟Bert一樣去微調參數呢?我其實沒有很好的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#01:59.280" id=01:59.280>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=119">01:59.280</a></div>
        <div class="t">以下是想了兩個可能。第一個是,一開始OpenAI對於人工智慧的技術就有比較高的期待,讓機器成為專才這件事就是它不屑做的,它一開始就想開發能夠當作通才的模型,可以看得懂人類的指令。我不知道OpenAI是不是一開始就有這麼刀砧遠矚的想法。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:24.240" id=02:24.240>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=144">02:24.240</a></div>
        <div class="t">另外一個可能就是,Bert都已經把微調那個路線做得差不多了,也就是專才那個路線已經被Bert封死做得差不多了,GPT再去做微調,你也不過只能跟Bert做得差不多啊,有什麼樣特別厲害的地方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#02:38.800" id=02:38.800>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=158">02:38.800</a></div>
        <div class="t">所以一定要另闢蹊徑,微調這條路已經被佔去了,所以GPT系列也只好另闢蹊徑,走一條不一樣的路。我覺得不管是哪一個理由,其實都蠻能夠編成故事的。我相信未來一定有人可以編各式各樣的故事,比如說OpenAI的研究人員一開始也是想要微調的,但是發現Bert已經被微調了,所以他決定要另闢蹊徑。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:03.560" id=03:03.560>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=183">03:03.560</a></div>
        <div class="t">他的主管就不斷地壓迫他,說你就跟Bert一樣做微調就好了,然後他就不肯。GPT系列是2018年就開始有了,GPT-1是2018年就開發出來了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:14.220" id=03:14.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=194">03:14.220</a></div>
        <div class="t">從GPT-1到GPT-3,這2018年到2020年三年間,這個模型都是個廢物。就算是GPT-3如此巨大,在解各種任務都跟Bert不在同一個量級上啊,那train這麼大的模型到底有什麼用呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:29.380" id=03:29.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=209">03:29.380</a></div>
        <div class="t">我相信搞不好OpenAI內部的研究人員受到金主爸爸很大的壓力,然後金主爸爸就壓著他們脖子說,你給我就跟Bert做一樣的東西就好了,這個聽起來比較實際。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:40.700" id=03:40.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=220">03:40.700</a></div>
        <div class="t">但是他們就是抵住了各種壓力,抵死不退,然後才有今天的Train GPT。以上的故事是我隨便亂編的,但是我覺得搞不好真的就是這個樣子,這可以成為一個很不錯的勵志的故事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#03:54.840" id=03:54.840>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=234">03:54.840</a></div>
        <div class="t">好,那我們就先來看一下機器怎麼根據範例來做學習。根據範例來做學習這件事情叫做in-context learning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:05.400" id=04:05.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=245">04:05.400</a></div>
        <div class="t">假設我們要語言模型做某一個任務,比如說我們現在要它做情感分析,也就是給它一個句子,它要說這個句子是正面的還是負面的,你直接給它句子是沒有用的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:17.020" id=04:17.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=257">04:17.020</a></div>
        <div class="t">因為就算它有情感分析的能力,你直接給它一個句子,它也不知道要幹嘛,是要做翻譯嗎?是要做摘要嗎?它不知道要幹嘛,所以你得告訴它說現在要做情感分析。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:28.520" id=04:28.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=268">04:28.520</a></div>
        <div class="t">那怎麼告訴它現在要做情感分析呢?提供給它一些例子,就告訴機器說,今天天氣很好,是正面的,今天運氣很差,是負面的,這朵花很美,正面我真的是累了,負面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#04:41.100" id=04:41.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=281">04:41.100</a></div>
        <div class="t">把這些句子通通串起來,再加上我感到非常高興這個句子,通通丟到語言模型裡面,當作是一個文字接龍,這些句子也是文字接龍的一部分,然後讓語言模型輸出接下來應該輸出哪一個詞彙,希望它就會輸出正面,希望它可以領悟到說,根據這些例子,領悟到說現在就是要做情感分析,所以給你這個句子,你應該輸出正面。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:08.940" id=05:08.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=308">05:08.940</a></div>
        <div class="t">那講到這邊,大家可能會非常的困惑,機器真的能夠從例子中學習嗎?如果你沒有什麼機器學習的概念,你可能會覺得說,啊,這個不就跟人一樣,看一些例子本來就可以學會啊,但是如果你有機器學習的概念,你可能會非常懷疑說,這可不是跑Gradient Descent,如果你說你把這些例子拿去跑Gradient Descent去微調語言模型,機器可以學會一點東西,當然可以,但是這個不是跑Gradient Descent,它只是input而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:37.980" id=05:37.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=337">05:37.980</a></div>
        <div class="t">機器真的能從這些input做類似學習的事情得到正確的答案嗎?所以有人就很懷疑,這篇文章叫做Rethinking the Role of Demonstration,What Makes In-Context Learning Work,有人就很懷疑說,機器真的能從這些例子裡面學到東西嗎?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#05:57.180" id=05:57.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=357">05:57.180</a></div>
        <div class="t">所以在這篇文章裡面就做了一個神秘的實驗,他故意給機器錯的答案,一樣給他例子,但是這些例子的標註是錯的,然後看看機器會有什麼樣的反應。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:11.500" id=06:11.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=371">06:11.500</a></div>
        <div class="t">我們就來看一下實驗結果吧,這邊上面是一堆分類任務的正確率的平均,下面是一堆多選題的任務的正確率的平均,每一塊就是不同的模型,從小的,比如說GPT-2一直到GPT-3。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:28.700" id=06:28.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=388">06:28.700</a></div>
        <div class="t">藍色是沒有給範例,沒有給範例機器表現當然很差,這沒有什麼問題,黃色是給了範例,然後範例裡面的標註是正確的,紅色是給了範例,然後範例裡面的標註是錯的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#06:44.540" id=06:44.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=404">06:44.540</a></div>
        <div class="t">所以有趣的地方是,你把範例給了錯誤的標註以後,其實正確率並沒有真的下降很多,從這個實驗看起來還是有一點點的下降啦,但是神奇的事情是沒有下降很多,看來給機器這一些範例,他從範例裡面似乎並沒有做真正的學習。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:08.380" id=07:08.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=428">07:08.380</a></div>
        <div class="t">接下來這個作者又做了另外一個實驗是,如果我們給機器一些句子,但這些句子的domain跟我們現在要測試的domain非常的不一樣。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:20.860" id=07:20.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=440">07:20.860</a></div>
        <div class="t">假設我們現在要做的是情感分析,有很多情感分析的benchmark corpus,但是我們這邊的這些句子不是從情感分析的benchmark corpus拿出來的,而是比如說從Wikipedia上面隨便sample來的句子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:35.180" id=07:35.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=455">07:35.180</a></div>
        <div class="t">如果我們給機器這些奇奇怪怪的句子,那結果會怎麼樣呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:41.260" id=07:41.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=461">07:41.260</a></div>
        <div class="t">這個是實驗的結果,黃色的就是給正確的答案,紅色的是給錯誤的答案,紫色這一條是給無關的句子,藍色這一條是完全沒有給例子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#07:57.260" id=07:57.260>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=477">07:57.260</a></div>
        <div class="t">所以你發現說,如果你給機器的例子,他裡面的句子跟你現在要解的任務是來自於不同的domain,他們的內容差異非常的大,那你發現說根據範例來學習就會沒有效。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:11.980" id=08:11.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=491">08:11.980</a></div>
        <div class="t">所以看起來,給機器的那一些demonstration、給機器的那一些範例,他的domain是很重要的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:19.740" id=08:19.740>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=499">08:19.740</a></div>
        <div class="t">這篇文章裡面的作者就給了一個推測,就是這些語言模型本來就會做情感分析,你給他這個句子,他本來就知道它是正面的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:31.180" id=08:31.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=511">08:31.180</a></div>
        <div class="t">他需要的是什麼?他其實不需要這些例子來做學習,他不需要你教他說這叫正面、這叫負面,他早就會了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:37.980" id=08:37.980>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=517">08:37.980</a></div>
        <div class="t">那這些例子有什麼用?這些例子是啟動他,讓他知道說現在要做情感分析,而不是做其他的事情,比如說翻譯或摘要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:48.060" id=08:48.060>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=528">08:48.060</a></div>
        <div class="t">那有另外一個額外的旁證是說,像這一種in-context learning的方法,其實你這邊例子給得多了,也沒什麼用。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#08:56.540" id=08:56.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=536">08:56.540</a></div>
        <div class="t">因為in-context learning的這一些例子,它最重要的目標並不是讓機器根據這些例子做學習,而是要喚醒機器,告訴他說現在要執行什麼樣的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:08.940" id=09:08.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=548">09:08.940</a></div>
        <div class="t">而語言模型本來就有執行這些任務的能力了,我們需要的只是透過這些例子喚醒他,讓他知道現在要解什麼樣的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:17.420" id=09:17.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=557">09:17.420</a></div>
        <div class="t">所以在文獻上你會發現說,其實in-context learning你給的範例的數目沒有那麼的重要。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:24.380" id=09:24.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=564">09:24.380</a></div>
        <div class="t">那這邊的縱軸是在不同任務上面的表現,這邊的橫軸是給不同的範例的數目,0個、4個、8個、16個跟32個。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:34.380" id=09:34.380>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=574">09:34.380</a></div>
        <div class="t">那一般在做一般的supervised learning,比如說微調模型參數的時候,你給這麼少的例子,就從4增加到32,這個對機器來說差別非常大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:45.100" id=09:45.100>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=585">09:45.100</a></div>
        <div class="t">所以如果你今天是從4、8、16到32,如果你今天做的是微調整個模型的參數,你的例子從4、8、16增加到32,照理說你的正確率會上升非常多。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#09:56.460" id=09:56.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=596">09:56.460</a></div>
        <div class="t">但是對於in-context learning這種方法,你會發現說很快就收斂了,到4個、8個例子的時候,其實機器就不能夠再做得更好了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:05.900" id=10:05.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=605">10:05.900</a></div>
        <div class="t">它並不是透過這些例子來進行學習,這些例子主要是喚醒它的記憶,告訴它說現在要做什麼樣的事情。所以例子給多了,可能幫助也不大。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:18.220" id=10:18.220>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=618">10:18.220</a></div>
        <div class="t">但是其實也有不一樣的聲音。剛才那篇paper告訴你說in-context learning就沒有learn到什麼,只是要喚醒機器的記憶而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:27.020" id=10:27.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=627">10:27.020</a></div>
        <div class="t">但是也有另外一個系列的論文,我把這個reference列在這邊,告訴你說其實in-context learning也是有機會讓機器做到learning這件事情的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:39.660" id=10:39.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=639">10:39.660</a></div>
        <div class="t">那你可以自己再詳細讀這篇論文,看看它們是怎麼說的,怎麼說in-context learning也可以達成類似gradient descent的效果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:49.420" id=10:49.420>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=649">10:49.420</a></div>
        <div class="t">在前天有一篇文章被放到archive上,我昨天在兩個不同的場合都有人跟我提到這篇文章。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#10:58.140" id=10:58.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=658">10:58.140</a></div>
        <div class="t">這篇文章是這樣說的,它也是想要深入研究in-context learning,但它得到的結論跟我們剛才看到的前一篇rethinking那篇文章得到的結論是略有不同的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:11.500" id=11:11.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=671">11:11.500</a></div>
        <div class="t">所以我昨天聽到這篇文章以後就趕快做了投影片來跟大家分享。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:16.460" id=11:16.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=676">11:16.460</a></div>
        <div class="t">這篇文章是怎麼說的呢?它說它做了很多不同的任務,試了很多不同的模型,在這個圖上,顏色越深代表那個模型越大,所以由上到下是模型,由大到小。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:35.660" id=11:35.660>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=695">11:35.660</a></div>
        <div class="t">橫軸是什麼?橫軸是我們今天在做in-context learning的時候,給機器的例子裡面有百分之多少是錯的,從25%到100%,有百分之多少是錯的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#11:49.900" id=11:49.900>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=709">11:49.900</a></div>
        <div class="t">你會發現,從這個圖上看來,有很多模型都是給它越多錯的例子,它做的結果就越差。你會發現說,尤其是大型的模型,顏色最深的就是大型的模型,最大的那些模型受到錯誤的例子的影響是最大的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:12.540" id=12:12.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=732">12:12.540</a></div>
        <div class="t">所以從這篇文章看起來,機器還是有從那些例子裡面學到東西的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:20.700" id=12:20.700>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=740">12:20.700</a></div>
        <div class="t">這篇文章是Google的paper,它並不是想要告訴你說前面的文章的結論是錯的。這篇paper又有提到前面rethinking the role of in-context learning那篇文章。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:33.020" id=12:33.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=753">12:33.020</a></div>
        <div class="t">它是說,in-context learning這件事情,機器要從範例學習這件事情,可能要是非常大的模型才會發生。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#12:43.340" id=12:43.340>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=763">12:43.340</a></div>
        <div class="t">比如說這邊PALM,它是540個billion的參數哦,它可是GPB3的再又三倍大。這種巨大的模型,它確實就會受到這個例子很大的影響,但如果是小的模型,受到錯誤的例子的影響就比較小。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:01.180" id=13:01.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=781">13:01.180</a></div>
        <div class="t">所以過去的論文之所以會得到結論說in-context learning裡面資料是不是對的沒什麼用,那是因為過去看的是小的模型。如果看大的模型,機器真的可以從範例中進行學習。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:14.620" id=13:14.620>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=794">13:14.620</a></div>
        <div class="t">那另外一個機器可以從範例中進行學習的例子是這樣,你看這個灰色這個虛線,灰色這個虛線代表什麼?灰色這個虛線代表的是random的結果,就是今天你隨便亂猜是50%。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:28.860" id=13:28.860>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=808">13:28.860</a></div>
        <div class="t">今天如果是有100%的錯誤率,本來正面的文章通通被改成負面,本來負面的文章通通都改成正面。如果今天在這個例子裡面,機器得到的正確率其實是低於50%,是不是代表它不只沒有亂猜,它還從錯誤的資料中進行學習?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#13:52.540" id=13:52.540>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=832">13:52.540</a></div>
        <div class="t">本來有一個正面的句子,它知道你要我把正面的句子都標成負面,雖然這個只是很奇怪,跟它之前在做pretrend的時候可能學的都不一樣,但沒關係,你既然給它這樣的例子,它就照著給你學下來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:05.300" id=14:05.300>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=845">14:05.300</a></div>
        <div class="t">所以正面的句子它會標負面,負面的句子它會標正面。所以你看到這些特別大的模型,在100%錯誤的標註的時候,它的正確率是低於50%的,意味著它可以從錯誤的資料中進行學習。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:20.500" id=14:20.500>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=860">14:20.500</a></div>
        <div class="t">它知道你給它正面的句子,其實要標負面,你給它負面的句子,其實要標正面。這是另外一個機器有從incontext learning學到東西的例子。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:31.460" id=14:31.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=871">14:31.460</a></div>
        <div class="t">在這篇文章裡面還做了一個更瘋狂的事情,直接拿這個大型語言模型來做分類的問題。怎麼做?直接給機器一些feature,這個是某一筆資料的feature,這是某一筆資料的label,有兩種label,bar跟負。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#14:50.460" id=14:50.460>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=890">14:50.460</a></div>
        <div class="t">這個是什麼並不重要,反正你就當作是class1跟class2,這是class1的example的feature,這是class2的example的feature。給機器一堆例子,它大概給了十幾個例子,然後再給機器一個input,給它一個feature,看看能不能得一些正確的答案出來。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:09.180" id=15:09.180>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=909">15:09.180</a></div>
        <div class="t">能不能夠直接把當中像PyTorch或TensorFlow一樣的framework,直接就來訓練一個分類的模型。這個語言模型的參數都沒有改哦,這個語言模型就是一個現成的語言模型,你只是給它讀了這一些句子,看看它能不能夠自動的變成一個分類器。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:28.020" id=15:28.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=928">15:28.020</a></div>
        <div class="t">結果還真的是可以啊,太神秘了。這邊的橫軸是那個問題的難度,就是你的輸入從一個dimension的feature,一直到六十四個dimension的feature。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:40.480" id=15:40.480>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=940">15:40.480</a></div>
        <div class="t">PALM只有做一到八是因為說,如果feature越長,那你input就越長,然後PALM它可以輸入的東西的長度是有限的,所以它只做到八個feature而已。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#15:52.400" id=15:52.400>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=952">15:52.400</a></div>
        <div class="t">但是你可以發現說,這些模型它學到的正確率是高過於隨機亂猜的。如果你跑SVM,當然SVM還是比這些大型語言模型更強啦,這些大型語言模型它本來就不擅長做分類,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:07.120" id=16:07.120>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=967">16:07.120</a></div>
        <div class="t">但是這邊想要表達的意思是說,你看,在某一些狀況下,它跟SVM的performance居然只差了一點點啊,它自己就是一個分類的演算法,它自己就學了一個分類的演算法,自動可以拿來做分類,就是這麼神奇。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:24.020" id=16:24.020>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=984">16:24.020</a></div>
        <div class="t">所以這就是一個大型語言模型神秘的in-context learning的能力。當然你可能會說,我們今天在做pre-train的時候,你從來沒有教機器說,看到這些例子,你就要按照這些例子來做我們想做的事情啊,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:40.360" id=16:40.360>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1000">16:40.360</a></div>
        <div class="t">所以in-context learning結果不怎麼好也是可以想像的。所以你可以讓機器去學習怎麼做in-context learning。這個部分的做法其實就比較直覺,你可以告訴機器說,給你一些例子,然後再給你一個句子,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#16:54.960" id=16:54.960>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1014">16:54.960</a></div>
        <div class="t">那你根據這些例子,你就要知道做翻譯,給你一些範例,給你一個問題,你知道根據這些範例,你就要做問答,然後期待今天給你不一樣任務的範例,機器知道說這個不一樣任務的範例,是要告訴它做NLI,Natural Language Inference。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:12.520" id=17:12.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1032">17:12.520</a></div>
        <div class="t">所以你可以讓機器去學習做in-context learning這件事情,當然讓機器有學習做in-context learning,會比完全沒有學做in-context learning還要好得多。我剛才講的例子,是機器並沒有去學著做in-context learning這件事。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:28.940" id=17:28.940>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1048">17:28.940</a></div>
        <div class="t">一個大型語言模型只學了文字接龍,直接拿出來以後,就有神秘的in-context learning的能力。剛才我們講的是看透過範例來學習,更進一步我們要講機器怎麼透過題目的敘述來學習。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#17:47.520" id=17:47.520>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1067">17:47.520</a></div>
        <div class="t">其實透過範例來學習,對人類來說還是沒有那麼的自然。你今天要操控機器,你還得去找一些範例,感覺有點麻煩。能不能更進一步讓機器透過敘述,叫你做翻譯就做翻譯,叫你做摘要就做摘要呢?能不能夠讓機器直接閱讀任務的敘述,就知道我們要它幹嘛呢?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:10.140" id=18:10.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1090">18:10.140</a></div>
        <div class="t">如果今天要讓機器可以看到任務的指示就做對應的事情,其實直接使用一個預訓練的模型是不夠的。直接使用一個文字接龍的模型,現在看起來效果是很差的,所以文字接龍的模型還是需要經過一些微調,叫做instruction tuning以後,才能夠看得懂人類的指令。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#18:35.140" id=18:35.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1115">18:35.140</a></div>
        <div class="t">那什麼是instruction tuning呢?就是在訓練的時候,你給機器不同的指令,比如說請做翻譯,然後再告訴它我說請做翻譯的時候,這是正確答案,再告訴它說請做摘要的時候,這是正確答案,期待在測試的時候給一個前所未有的指令,機器自動知道這個指令是什麼意思,然後給出合理的回應,這個就是instruction tuning的概念。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:01.140" id=19:01.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1141">19:01.140</a></div>
        <div class="t">那這樣的概念其實也不是全新的點子,很多人都試過這個概念的一個知名的模型,叫做T0。這個T0,你看這個文章是21年的文章,是兩年前的文章,兩年前就已經有很多人在做instruction tuning了,不是只有OpenAI在做instruction tuning,這個T0是Hackingface的favorite,也有其他人在做instruction tuning。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:27.140" id=19:27.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1167">19:27.140</a></div>
        <div class="t">那T0做的事情是什麼呢?跟我前面那一張投影片講的是一樣的,就是你今天在訓練的時候,你給機器做摘要的指令,叫它做摘要。你給機器做情感分析的指令,叫它做情感分析。你給機器問答的指令,叫它做問答。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#19:45.140" id=19:45.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1185">19:45.140</a></div>
        <div class="t">期待在測試的時候,你直接叫它做natural language inference,中文翻譯應該是自然語言推論,你直接叫它做推論,期待它也可以給你正確的答案,這個就是T0。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:00.140" id=20:00.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1200">20:00.140</a></div>
        <div class="t">另外一個知名的模型叫做Flame,這個應該是Google的paper,也是差不多在21年的年底的時候所發表的論文,所以在21年那個時候有很多人在嘗試做instruction tuning這件事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:16.140" id=20:16.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1216">20:16.140</a></div>
        <div class="t">那如果你要做instruction tuning,做像Flame或者像T0這種事情,那起手式通常是什麼呢?起手式就是先去收集一大堆自然語言處理的任務。所以這個是從Flame的paper截出來的,它就收集了各式各樣自然語言處理的任務。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:36.140" id=20:36.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1236">20:36.140</a></div>
        <div class="t">比如說幫翻譯就有8個不同的data set,然後摘要有11個data set等等,收集各式各樣自然語言處理的任務,還有標註的資料集。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:48.140" id=20:48.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1248">20:48.140</a></div>
        <div class="t">接下來,你需要把這些任務改寫成指令,什麼意思呢?假設現在我們要做的任務是推論natural language inference,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#20:59.140" id=20:59.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1259">20:59.140</a></div>
        <div class="t">那在natural language inference裡面,機器要給它一個前提,然後給它一個假設,然後它回答說這個前提跟假設它們有沒有矛盾。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:12.140" id=21:12.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1272">21:12.140</a></div>
        <div class="t">如果在一般的模型,不是instruction-based的模型,那你就是給它讀這兩個句子,期待它可以得到正確的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:20.140" id=21:20.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1280">21:20.140</a></div>
        <div class="t">但是我們現在要叫機器做的事情是看懂人類下的指令。所以這邊要問的問題就是,當人類想要叫機器做natural language inference的時候,你會怎麼跟機器說話?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:35.140" id=21:35.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1295">21:35.140</a></div>
        <div class="t">接下來就有各種不同的說法。在Flame這篇paper裡面,每一個NLP的任務,它們都想了十個不同的描述方式。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:45.140" id=21:45.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1305">21:45.140</a></div>
        <div class="t">比如說,第三個描述的方式就是,如果我今天要叫機器做natural language inference,那我可能就會說,請讀下面的文章,</div>
    </div>
    
    <div class="c">
        <a class="l" href="#21:55.140" id=21:55.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1315">21:55.140</a></div>
        <div class="t">然後你要決定一下這個假設是否可以推導出前提,假設冒號是什麼,選項是什麼,期待機器可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:10.140" id=22:10.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1330">22:10.140</a></div>
        <div class="t">當然你也可以有別的問法,比如說你可以說,我現在的問法就是,我把前提先寫出來,然後接下來就說,基於上述的文句,我們能不能夠得到結論?</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:23.140" id=22:23.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1343">22:23.140</a></div>
        <div class="t">就是把那個假設的句子放在這邊,然後期待機器可以得到正確的答案。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:27.140" id=22:27.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1347">22:27.140</a></div>
        <div class="t">簡單來說,就是你要想辦法把natural language inference這個任務,用人類的語言把它描述出來,然後變成一個data set,然後去教你的機器,看看大型語言模型可不可以自動學到,看這些指令就做它該做的事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:45.140" id=22:45.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1365">22:45.140</a></div>
        <div class="t">結果怎麼樣呢?結果還真的是可以的,這個是Fair那篇paper的結果。他們做了三種不同的測試任務,包括natural language inference, reading comprehension,還有postbook QA。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#22:59.140" id=22:59.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1379">22:59.140</a></div>
        <div class="t">這邊要強調一下,當它的測試任務是natural language inference的時候,訓練資料裡面就沒有natural language inference。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:08.140" id=23:08.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1388">23:08.140</a></div>
        <div class="t">讓大家了解吧,就是說如果訓練資料裡面已經有natural language inference的任務,那你在測試的時候也有natural language inference的任務,機器可以看懂你要叫它做推論的指令,這聽起來沒什麼稀奇的。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:18.140" id=23:18.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1398">23:18.140</a></div>
        <div class="t">所以這邊是,如果測試的時候是natural language inference的任務,訓練的時候就沒有natural language inference的任務,然後看看機器能不能在它從來沒有看過的指令的情況下,自動知道說人要叫它做什麼事情。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:34.140" id=23:34.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1414">23:34.140</a></div>
        <div class="t">來看一下這個表現,這個數值就是越高越好。黃色的這個是GPT-3,GPT-3這邊應該是只有給它指令得到這樣的結果。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:45.140" id=23:45.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1425">23:45.140</a></div>
        <div class="t">GPT-3加Fusion,就是有給它指令,也做in-context learning,得到的結果是紅色這個方。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#23:52.140" id=23:52.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1432">23:52.140</a></div>
        <div class="t">Flame是有做instruction tuning,所以你有拿一堆訓練的任務,教機器說看到人給這樣的指示的時候你要做什麼。雖然這些測試任務的指示沒有看過,但機器在訓練的時候已經看過各式各樣不同的指示了。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:08.140" id=24:08.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1448">24:08.140</a></div>
        <div class="t">GPT-3是沒有看過這些指示的,但是Flame有看過。那有學過怎麼根據人的指示來做合理的回應,可以得到的結果是比GPT-3Fusion做in-context learning,還有GPT-3Fusion根本沒做instruction tuning的結果還要好。</div>
    </div>
    
    <div class="c">
        <a class="l" href="#24:24.140" id=24:24.140>link</a> |
        <div class="s"><a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg&t=1464">24:24.140</a></div>
        <div class="t">所以看起來機器是有機會學會根據人下給它的指令做事情,然後它學到的東西可以generalize到沒有看過的指令上面,這個是instruction tuning。</div>
    </div>
    
</body>
</html>   